# Data Science Projects

**Informaion:**
> * [United Network for Organ Sharing (UNOS)](https://github.com/SirErikPak/Profolio/tree/main/UNOS)
   > * On going Reesearch Project
   
> * [AutoEncode & Decoder OpenCV](https://github.com/SirErikPak/Profolio/tree/main/Encoder_Decoder)

> * [Lane Detection](https://github.com/SirErikPak/Profolio/tree/main/Lane_Detection)

> * [HR Attrition](https://github.com/SirErikPak/Profolio/tree/main/HR_Attrition)

> * [Movie Recommender](https://github.com/SirErikPak/Profolio/tree/main/Movie_Recommender) 

> *[Gesture Recognition](https://github.com/SirErikPak/Portfolio/tree/main/Gesture_Recognition)


> * [Sentiment analysis with tweets](https://github.com/Erik1120/Profolio/blob/main/Notebook/Sentiment_Data.ipynb)
    > * [Kaggle](https://www.kaggle.com/kazanova/sentiment140)
       > * This exercise is the tweet sentiment dataset which contains 1.6 million tweets. The tweets are labeled with (0 = negative, 4 = positive). In this exercise, the data ONLY contains a positive and negative sentiment, a classic balanced binary classification exercise.
        - Lancaster Stemmer
        - Count Vectorizer & Tfidf Vectorizer
        - Logistic Regression
        - Light GBM Classifier with Bayesian Optimization
        - Keras & MLP Classifier with Keras tunning

    A. Sentiment Analysis
    - > * [Wrangling](https://github.com/Erik1120/Profolio/blob/main/Notebook/SentimentAnalysis_wrangling.ipynb)
    a) Applied Regular expression operations to remove noise from the tweets. Also, Lancaster Stemmer was used to determining the common root form and from nltk.corpus to generate stopwords removal for our sentiment analysis data.
    b) All the features except target and text were remove from our analysis.
    
    B. Algorithm Performance
    - > * [Performance Log](https://github.com/Erik1120/Profolio/blob/main/Notebook/image/log_styled.pdf)    

4. **Fraud Analysis**
- There are problems where a class imbalance in a dataset like our current fraudulent transactions dataset. For example, the vast majority will be in the "Non-Fraud" class, and a tiny minority will be in the "Fraud" class. The Paysim dataset is based on a sample of actual transactions extracted from one month of financial logs from a mobile money service implemented in an African country. This dataset contains 6,362,620 rows by 11 columns with 8,213 labeled as a "Fraud."

- **Data Source**
> * [Kaggle](https://www.kaggle.com/ealaxi/paysim1)
> * [Data Cleaning](https://github.com/Erik1120/Profolio/blob/main/Notebook/Fraud/Data_WranglingEDA.ipynb)
> * [EDA](https://github.com/Erik1120/Profolio/blob/main/Notebook/Fraud/Data_Engineering_Fraud.ipynb)
> * [Machine Learning Performance](https://github.com/Erik1120/Profolio/blob/main/Notebook/Fraud/MachineLearning.ipynb)

5. > * [IBM Attrition](https://github.com/Erik1120/Profolio/blob/main/Notebook/HR_Attrition.ipynb)
    - Data Visualization
    - Principle Component Analysis
        - Standardized & Normalized
    - Random under-sampling (Normalized and Standardized Dataset)
    - Over Sampling (Synthetic Minority Oversampling Technique)
    - Multicollinearity Analysis (variance_inflation_factor)
    - SHAP Plots (SHapley Additive exPlanations)
    - Logistic Regression
    - Random Forest
    - XG Boost Classifier
    - Light GBM Classifier
    
6. > * [Introduction to Time Series & Modeling Binary Classfication](https://github.com/Erik1120/Profolio/blob/main/Notebook/Exercise/ultimate_final.ipynb)
    - Logistic Regression
    - Random Forest
    - Adaboost
    
    > * [Times Series](https://github.com/Erik1120/Profolio/blob/main/Notebook/TimeSeriesDatacamp.ipynb)
        - ARIMA
        - ARMA
        - adfuller, plot_acf, plot_pacf

7. > * [World Happiness Analysis](https://github.com/Erik1120/Profolio/blob/main/Notebook/Happy/Story.ipynb)
    - Principle Component Analysis
    - Visualization 

- **A/B testing**
> * [A/B testing](https://github.com/Erik1120/Sample/blob/main/Notebook/Exercise/A_B_Testing_Datacamp.ipynb)

- **Bayes**
> * [Bayes](https://github.com/Erik1120/Sample/blob/main/Notebook/Exercise/Bayes_exercise.ipynb)

- **Case Study - London Housing**
> * [London Housing](https://github.com/Erik1120/Sample/blob/main/Notebook/Exercise/Case_Study-London_Housing.ipynb)

- **Cosine Similarity Calculations**
> * [Cosine Similarity](https://github.com/Erik1120/Sample/blob/main/Notebook/Exercise/Cosine_Similarity_Case_Study.ipynb)

- **Factor Analysis Exercise**
> * [Factor Analysis](https://github.com/Erik1120/Sample/blob/main/Notebook/Exercise/FactorAnalysis.ipynb)


- **Pandas:**
> * [Pandas Data Manipulation](https://github.com/Erik1120/Profolio/blob/main/Pandas/DataManipulationPandas.ipynb)

> * [Pandas Joining Data 1](https://github.com/Erik1120/Profolio/blob/main/Pandas/JoiningDataWithPandas.ipynb)

> * [Pandas Joining Data 2](https://github.com/Erik1120/Profolio/blob/main/Pandas/PandasJoinsForSpreadsheetUsers.ipynb)

> * [Reshaping data](https://github.com/Erik1120/Profolio/blob/main/Pandas/ReshapingDataUsingPandas.ipynb)

> * [List/Tuple/Set](https://github.com/Erik1120/Profolio/blob/main/Notebook/ist_Set_Tuple_Dict.ipynb.ipynb)