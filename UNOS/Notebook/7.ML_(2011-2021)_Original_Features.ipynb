{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6243a05-1cfb-4594-8a4b-6df72b4cd11c",
   "metadata": {},
   "source": [
    "# Note:\n",
    "- The 3-year survival binary classification for candidate and donor with scaled features, excluding any Max Gini Impurity < 5% on every feature after all encoding.\n",
    "- Remove NaNs from numerical features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6c117a-eab8-4942-a23f-b8b79b2476c8",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f99fda-5915-4661-a6e2-551a06873533",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to user functions\n",
    "import sys  \n",
    "sys.path.append('../Src/')\n",
    "\n",
    "from platform import python_version\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import importlib \n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "# import user functions\n",
    "import UserUtilityFunctions as uf\n",
    "import UserStatisticalFunctions as usf\n",
    "import UserVisualization as uv\n",
    "import UserMetricsFunctions as umf\n",
    "import UserFeatureSelection as ufs\n",
    "import HyperParameters as parms\n",
    "\n",
    "# set seaborn theme\n",
    "sns.set_theme()\n",
    "\n",
    "# initializing variables\n",
    "RANDOM_STATE = 1776\n",
    "\n",
    "# print versions\n",
    "print(\"Numpy Version: \" + np.__version__)\n",
    "print(\"Pandas Version: \" + pd.__version__)\n",
    "print(\"Seaborn Version: \" + sns.__version__)\n",
    "print(\"Matplotlib Version: \" + plt.matplotlib.__version__)\n",
    "print(\"Python Version: \" + python_version())\n",
    "\n",
    "# adjust pandas display options to max\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "# adjust pandas display options to ensure full display of content\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724c5864-4bb0-4538-869c-573df18561a8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871f8544-3712-4c4e-9e09-13eb1438fe5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "df = pd.read_pickle(\"../Data/6Clean_ML_Heart_Orig.pkl\")\n",
    "df_can = pd.read_pickle(\"../Data/6Clean_ML_CAN_Orig.pkl\")\n",
    "df_don = pd.read_pickle(\"../Data/6Clean_ML_DON_Orig.pkl\")\n",
    "df_both = pd.read_pickle(\"../Data/6Clean_ML_BOTH_Orig.pkl\")\n",
    "df_ordinal = pd.read_pickle(\"../Data/6Clean_ML_ordinal_Orig.pkl\")\n",
    "df_nominal = pd.read_pickle(\"../Data/6Clean_ML_nominal_Orig.pkl\")\n",
    "df_numeric = pd.read_pickle(\"../Data/6Clean_ML_numeric_Orig.pkl\")\n",
    "df_label = pd.read_pickle(\"../Data/6Clean_ML_label_Orig.pkl\")\n",
    "# print shape\n",
    "print(f\"Heart Dataset Rows: {df.shape[0]:,} & Columns: {df.shape[1]:,}\")\n",
    "print(f\"Candidate Features: {df_can.shape[0]:,}\")\n",
    "print(f\"Donor Features: {df_don.shape[0]:,}\")\n",
    "print(f\"Both Features: {df_both.shape[0]:,}\")\n",
    "print(f\"Ordinal Features: {df_ordinal.shape[0]:,}\")\n",
    "print(f\"Nominal Features: {df_nominal.shape[0]:,}\")\n",
    "print(f\"Numeric Features: {df_numeric.shape[0]:,}\")\n",
    "print(f\"Label Features: {df_label.shape[0]:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ccd5279-6d71-4303-9591-09cc6f1670e0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Sanity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8bba380-6a45-4027-9299-58b6ad434b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine two lists\n",
    "allCat = df_ordinal.column.to_list() + df_nominal.column.to_list() + df_numeric.column.to_list()\n",
    "\n",
    "# insanity check\n",
    "uf.symmetric_difference(set(allCat), set(df.columns.to_list()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60f3115-a699-49cd-8816-3b21fb358d2c",
   "metadata": {},
   "source": [
    "## Remove Unwanted Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5cd1b7b-3930-4dcf-a692-b48329f4f1a0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### User Function(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15d2abf-6a2b-48f2-b1eb-44e7d87d8a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def HouseKeeping(data, removeColLst, dataOrdinal, dataNominal, dataCan, dataDon, dataBoth, dataNumeric, display=True):\n",
    "    \"\"\"\n",
    "    Run helper fuction for house keeping\n",
    "    \"\"\"\n",
    "    # remove DataFrame data (house keeping)\n",
    "    dataOrdinal = uf.remove_row_using_mask(dataOrdinal, removeColLst, colstr='column',  string='df_ordinal', display=display)\n",
    "    dataNominal = uf.remove_row_using_mask(dataNominal, removeColLst, colstr='column', string='df_nominal',  display=display)\n",
    "    dataNumeric = uf.remove_row_using_mask(dataNumeric, removeColLst, colstr='column', string='df_numeric',  display=display)\n",
    "    dataCan = uf.remove_row_using_mask(dataCan, removeColLst, colstr='column', string='df_can',  display=display)\n",
    "    dataDon = uf.remove_row_using_mask(dataDon, removeColLst, colstr='column', string='df_don',  display=display)\n",
    "    dataBoth = uf.remove_row_using_mask(dataNominal, removeColLst, colstr='column', string='df_both',  display=display)\n",
    "    \n",
    "    # remove features\n",
    "    data = uf.remove_column(data, removeColLst, display=display)\n",
    "\n",
    "    return data, dataOrdinal, dataNominal, dataCan, dataDon, dataBoth, dataNumeric\n",
    "\n",
    "\n",
    "def find_feature(string, column_list):\n",
    "    # initialize list\n",
    "    lst = []\n",
    "    # iterate\n",
    "    for col in column_list:\n",
    "        if string in col:\n",
    "            lst.append(col)\n",
    "    return lst"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32adb221-6988-43d9-9e23-ca87ac3ca356",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Copy DataFrame \n",
    "- `df_copy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3417d45-15b0-4758-b153-c1b3da333886",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep original DataFrame\n",
    "df_copy = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104c669b-5236-4b00-810e-ff5ced737f40",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Label Plot: Survival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e665f87a-d5dd-48cd-a2f9-66d07cd5da75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove NaN\n",
    "df = df.dropna()\n",
    "df = uf.remove_cat_zero_count(df).copy()\n",
    "# print\n",
    "print(f\"Heart Dataset Rows: {df.shape[0]:,} & Columns: {df.shape[1]:,}\")\n",
    "\n",
    "# plot\n",
    "uv.plot_count(df, ['Survival'], fig_size=(10, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9058f5-8fcd-4679-894a-4deb04c99e7b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Unwanted Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20fbf849-b1bc-48f9-9206-0be3e1aa7a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove unwanted labels\n",
    "removeCols = df_label.column.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41887199-baf3-4f33-adbf-53a1781dba1b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Ordinal Plots & Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a6a01a-d42d-4614-b5f9-6632efea0699",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Ordinal: Heapmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971b376c-594c-4967-b292-7ee54ed07143",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the correlation matrix\n",
    "corr_matrix = df[df_ordinal.column.to_list()].corr(method='spearman')\n",
    "# create a mask for the UPPER triangle  \n",
    "mask = np.triu(np.ones_like(corr_matrix, dtype=bool))  \n",
    "\n",
    "# display options\n",
    "plt.figure(figsize=(40,40))\n",
    "plt.title(\"Ordinal Correlation Bottom Half Heatmap\", fontsize=30)\n",
    "plt.xticks(fontsize=20)  # font size for x-ticks\n",
    "plt.yticks(fontsize=20)  # font size for y-ticks\n",
    "# plot the BOTTOM half (lower triangle + diagonal)  \n",
    "sns.heatmap(corr_matrix,  \n",
    "            mask=mask,  # hide the upper triangle  \n",
    "            annot=True,  \n",
    "            cmap='coolwarm',  \n",
    "            vmin=-1, vmax=1,  \n",
    "            linewidths=0.5, fmt=\".2f\", cbar=False)  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5382aff-9532-4569-9341-75a4888bf69a",
   "metadata": {},
   "source": [
    "### Ordinal Display\n",
    "- The ordinal features with Spearman correlation below indicate strong to very moderatly strong positive monotonic relationships between the respective variable pairs \n",
    "    - Very Strong Associations (|r| ≥ 0.7)\n",
    "    - Moderate-Strong Associations (0.5 ≤ |r| < 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c3fd1a-862b-4c54-aed1-a7e5fe8cd7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# threshold value\n",
    "threshold = 0.5\n",
    "# identify upper triangle of correlation matrix\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "\n",
    "# find feature columns with correlation greater than 0.7\n",
    "to_drop = [column for column in upper.columns if any(np.abs(upper[column]) > threshold)]\n",
    "\n",
    "# display\n",
    "print(f\"Strong correlation: {sorted(to_drop)}\\n\")\n",
    "# ordinal correlation: re-check\n",
    "print(f\"Ordinal Correlation Re-Check with Threshold of {threshold * 100}% or greater:\")\n",
    "usf.correlation_with_threshold(df[df_ordinal.column.to_list()], method='spearman', threshold=threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef47a4da-bf0c-4a8b-ac6a-542d58bfb026",
   "metadata": {},
   "source": [
    "### Engineer: MismatchLevel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75f0cd5-0db8-4161-8880-fc3d0d1adca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = uf.get_feature_list(df, 'MismatchLevel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b2906c-9dfc-44c8-832b-4b174e75c74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ordinal correlation\n",
    "usf.correlation_with_threshold(df[features], method='spearman', threshold=threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9472a250-19a7-45b1-b04c-22a14b6ad8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# append to removeCols\n",
    "removeCols.extend(features)\n",
    "\n",
    "# combine\n",
    "df['MismatchLevel_Addition'] = df[features].sum(axis=1)\n",
    "\n",
    "# update DataFrame\n",
    "df_ordinal = uf.insert_into_dataframe(df_ordinal, ['MismatchLevel_Addition'])\n",
    "df_both = uf.insert_into_dataframe(df_both, ['MismatchLevel_Addition'])\n",
    "# display\n",
    "uf.category_contingency_survival(df, 'MismatchLevel_Addition')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be824dcf-066a-4e58-af6a-d0bb7a32e6d3",
   "metadata": {},
   "source": [
    "### Engineer: Inotropes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6cbe445-e114-4b4c-83bb-05598d41e0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = uf.get_feature_list(df, 'Inotropes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e61ddf4-bf32-446a-853c-335d57f1ce08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ordinal correlation\n",
    "usf.correlation_with_threshold(df[features], method='spearman', threshold=threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3051e83-4ac3-4dee-a29a-dee405dab791",
   "metadata": {},
   "outputs": [],
   "source": [
    "# append to removeCols\n",
    "removeCols.extend(features)\n",
    "\n",
    "# combine\n",
    "df['Inotropes_Yes_Count_Addition_CAN'] = df[features].sum(axis=1)\n",
    "\n",
    "# update DataFrame\n",
    "df_ordinal = uf.insert_into_dataframe(df_ordinal, ['Inotropes_Yes_Count_Addition_CAN'])\n",
    "df_can = uf.insert_into_dataframe(df_can, ['Inotropes_Yes_Count_Addition_CAN'])\n",
    "# display\n",
    "uf.category_contingency_survival(df, 'Inotropes_Yes_Count_Addition_CAN')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "263eb02c-bcef-42f9-9c45-35d02fb47092",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Ordinal Remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3688839f-6cbd-4494-96b3-21a71cbb6b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add to removeCols\n",
    "removeCols.extend(['PreviousTransplantNumber_CAN','FunctionalStatusTransplant_CAN'])\n",
    "#remove features\n",
    "df, df_ordinal, df_nominal, df_can, df_don, df_both, df_numeric = HouseKeeping(df, removeCols, df_ordinal, df_nominal, df_can, df_don, df_both, df_numeric, display=True)\n",
    "# initialize removeCols\n",
    "removeCols = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb13ed9f-87fb-44b6-95d0-87fdf48f09ae",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Ordinal Association Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d078664-a859-45d6-b6c5-bc9461b81a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Ordinal Correlation Re-Check with Threshold of {threshold * 100}% or greater:\")\n",
    "usf.correlation_with_threshold(df[df_ordinal.column.to_list()], method='spearman', threshold=threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2eac06d-7281-4130-8e25-f32da7f40673",
   "metadata": {},
   "outputs": [],
   "source": [
    "mwutDF = usf.mannwhitneyu_combinations(df, df_ordinal.column.to_list())\n",
    "\n",
    "# display p_value >= 0.05\n",
    "mwutDF[(mwutDF.p_value >= 0.05)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7f9b90-0b70-4667-811f-444b0b324012",
   "metadata": {},
   "source": [
    "##### There are associations, but they are different features representing something different."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144a9c72-894d-4720-aa75-2bbd03c069cd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Ordinal Datatype Update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6469fc72-706b-4ba3-a14e-92e03cbe4c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change datatype to category\n",
    "df = uf.convert_to_category(df, df_ordinal.column.to_list(), ordered=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83bd69cd-c48b-4c86-9c47-72405132ff48",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Nominal Plots & Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffbcd866-e38f-4a9d-8735-c08ae2578306",
   "metadata": {},
   "source": [
    "### Nominal Chi2 Test & Cramer V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebad75f1-025f-4b3c-9f16-47d8b6c33b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hypothesis testing\n",
    "nominalDF = usf.multi_independence_category(df, df_nominal.column.to_list())\n",
    "# display\n",
    "nominalDF[(nominalDF.p_value <= 0.05) & (nominalDF.cramer_v > .5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8a9ae7-c03d-4b70-920c-8720c129543c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display\n",
    "features = uf.get_feature_list(df, 'NonHeartBeating_DON|CardiacArrest_DON')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77acb3d-5195-4828-a772-6fe4852d54a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in features:\n",
    "    print(f\"{uf.category_contingency_survival(df, feature).to_string()} \\t{feature}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c6fa2c5-5e33-49ef-b5f9-79d1d681cd04",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Nominal Remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bbce169-1a07-47e9-be8c-d773ac1542d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add to removeCols\n",
    "removeCols.extend(['NonHeartBeating_DON']) # mostly No\n",
    "#remove features\n",
    "df, df_ordinal, df_nominal, df_can, df_don, df_both, df_numeric = HouseKeeping(df, removeCols, df_ordinal, df_nominal, df_can, df_don, df_both, df_numeric, display=True)\n",
    "# initialize removeCols\n",
    "removeCols = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7d1bad-909e-463f-839c-c8496dfec0f1",
   "metadata": {},
   "source": [
    "### Nominal Datatype Update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f330eb67-e89b-4273-9a65-3e4aa1664361",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change datatype to category\n",
    "df = uf.convert_to_category(df, df_nominal.column.to_list())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d1f375-1f3e-4791-b66e-378de6c37fec",
   "metadata": {},
   "source": [
    "### Numeric Plot & Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6141d605-23e1-4e08-9358-a3286d1a41a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation\n",
    "usf.correlation_with_threshold(df[df_numeric.column.to_list()], method='pearson', threshold=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f4e1cb-1c7c-4207-ae0f-a3074da56d8e",
   "metadata": {},
   "source": [
    "#### Engineer: HeightCm_Addition & WeightKg_Addition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0064435-88c6-4f9b-9cd2-73714b9e3148",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = uf.get_feature_list(df, 'HeightCm|WeightKg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f09ebca-673c-4a47-a463-7ad219f36f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# append to removeCols\n",
    "removeCols.extend(features)\n",
    "\n",
    "# combine\n",
    "df['Total_Mass'] = df[features].sum(axis=1)\n",
    "\n",
    "# update DataFrame\n",
    "df_numeric = uf.insert_into_dataframe(df_numeric, ['Total_Mass'])\n",
    "df_both = uf.insert_into_dataframe(df_both, ['Total_Mass'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b92819-be2a-4eba-86bb-fb34fedb83c0",
   "metadata": {},
   "source": [
    "#### Numeric Remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985fd040-3af5-4893-a74e-e7069518a6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# append to removeCols\n",
    "removeCols.extend(['DistanceFromDonorHospitaltoTXCenter']) # distance dependent on IschemicTimeHour_DON\n",
    "#remove features\n",
    "df, df_ordinal, df_nominal, df_can, df_don, df_both, df_numeric = HouseKeeping(df, removeCols, df_ordinal, df_nominal, df_can, df_don, df_both, df_numeric, display=True)\n",
    "# initialize removeCols\n",
    "removeCols = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0894f1-ae65-4873-a3d6-4f68bbc1ae41",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Numeric Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8208abd-66b8-4d86-b708-9cc59949b1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the correlation matrix\n",
    "corr_matrix = df[df_numeric.column.to_list()].corr(method='pearson')\n",
    "# create a mask for the UPPER triangle  \n",
    "mask = np.triu(np.ones_like(corr_matrix, dtype=bool))  \n",
    "\n",
    "# display options\n",
    "plt.figure(figsize=(40,40))\n",
    "plt.title(\"Correlation Bottom Half Heatmap\", fontsize=30)\n",
    "plt.xticks(fontsize=20)  # font size for x-ticks\n",
    "plt.yticks(fontsize=20)  # font size for y-ticks\n",
    "# plot the BOTTOM half (lower triangle + diagonal)  \n",
    "sns.heatmap(corr_matrix,  \n",
    "            mask=mask,  # hide the upper triangle  \n",
    "            annot=True,  \n",
    "            cmap='coolwarm',  \n",
    "            vmin=-1, vmax=1,  \n",
    "            linewidths=0.5, fmt=\".2f\", cbar=False)  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83220419-45d1-4e68-b030-316a96e1a985",
   "metadata": {},
   "source": [
    "### Dummy Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1309daf7-20a8-468e-80f9-caca0a038186",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape\n",
    "print(f\"Shape before encoding: {df.shape}\")\n",
    "# encode\n",
    "df_dummy = pd.get_dummies(df, columns=df_nominal.column.to_list(), drop_first=True)\n",
    "# print shape\n",
    "print(f\"Shape after encoding: {df_dummy.shape}\")\n",
    "# add columns to list\n",
    "dummyCols = df_dummy.columns.tolist()\n",
    "# remove label\n",
    "dummyCols.remove('Survival')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58941063-d1d2-4faa-b20d-f952e4d133fe",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Display GINI Information: Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3a02d3-ff9a-4ac2-9070-9c82fab76a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove features with GiniPercent\n",
    "percent = 5\n",
    "holdDF = ufs.compute_entropy_gini_impurity(df_dummy[dummyCols])\n",
    "removeCols = holdDF.ColumnName[holdDF.GiniPercent < percent].to_list()\n",
    "print(f\"Number of Features to be removed: {len(removeCols)}\")\n",
    "holdDF.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79bf9bff-3c3a-4d86-bdd9-e1c849e14656",
   "metadata": {},
   "outputs": [],
   "source": [
    "# features to be removed\n",
    "holdDF[holdDF.ColumnName.isin(removeCols)].sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b561173-2045-42dc-bce6-55cfccfea057",
   "metadata": {},
   "source": [
    "## Split Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9002851b-c217-4912-aecb-a3ed4773989e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# encoded DataFrame\n",
    "df_dummy = df_dummy.drop(columns=removeCols)\n",
    "# print shape\n",
    "print(f\"Encode & Remove Features with GINI: Heart Dataset Rows: {df_dummy.shape[0]:,} & Columns: {df_dummy.shape[1]:,}\")\n",
    "\n",
    "# house keeping\n",
    "ordinalNumericCols = list((set(df_ordinal.column.to_list()) | set(df_numeric.column.to_list())) - set(removeCols))\n",
    "\n",
    "# split X & y\n",
    "X = df_dummy.drop(columns = 'Survival')\n",
    "y = df_dummy.Survival\n",
    "\n",
    "# mapping values\n",
    "y = y.map({'Dead': True, 'Living': False}).astype(int)\n",
    "# print\n",
    "print(f\"Dead: {True} & Living: {False}\")\n",
    "\n",
    "# split the dataset into 80% training and 20% testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RANDOM_STATE, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dec793b-7ffb-4e4d-bfb5-c7436de81d0e",
   "metadata": {},
   "source": [
    "## Scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9584f6c7-ee47-426f-9127-8f4a71b3e9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# initialize MinMaxScaler\n",
    "scale = MinMaxScaler()\n",
    "\n",
    "# fit\n",
    "fitScale = scale.fit(X_train[ordinalNumericCols])\n",
    "\n",
    "# transform\n",
    "X_train[ordinalNumericCols] = fitScale.transform(X_train[ordinalNumericCols])\n",
    "X_test[ordinalNumericCols] = fitScale.transform(X_test[ordinalNumericCols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330b897e-8a7a-4a18-8be3-4d417f4ccb35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# message for dataframe\n",
    "msg = f\"2011-2016: Orginal Features: Grid Search & CV Scoring F1 - Features where Max Gini Impurity < {percent}% removed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25c75b8-e125-4dbf-9227-3ae95a131101",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import matthews_corrcoef, make_scorer\n",
    "\n",
    "# define MCC scorer\n",
    "mcc_scorer = make_scorer(matthews_corrcoef)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d5f5170-2e64-49c1-bd28-0086e243bb6b",
   "metadata": {},
   "source": [
    "## Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b658c1e-8967-48e8-89d5-fe241d6ef6c1",
   "metadata": {},
   "source": [
    "### RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98a2f43-227a-410b-96cb-3ea90a760dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# function from sklearn.utils.class_weight computes the weights for each class to handle imbalanced datasets\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# the 'balanced' mode adjusts weights inversely proportional to class frequencies in the input data for Random Forest\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "class_weight_dict = dict(zip(np.unique(y_train), class_weights))\n",
    "\n",
    "# grid search Hyperparameters Random Forest Classfiier\n",
    "parameters = parms.rfc_parms(class_weight_dict)\n",
    "\n",
    "# initialize Model with class weights\n",
    "rfc_param = {'random_state': RANDOM_STATE}\n",
    "\n",
    "# instantiate Random Forest Classifier\n",
    "Model = RandomForestClassifier(**rfc_param)\n",
    "\n",
    "# CV with grid search for Hyper-Parameter tuning\n",
    "rfc_fit = umf.stratified_grid(Model, parameters, X_train, y_train, seed=RANDOM_STATE, n_jobs=-1, n_split=5, score = 'f1')\n",
    "\n",
    "# best model\n",
    "Model = rfc_fit.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e13351-a1bc-4a79-b65b-b94dd14bf442",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b730d447-114c-49d1-a8a0-9a007c590043",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b76e6b3-8381-4521-bb07-fe5bfb47a89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize variables\n",
    "algorithm = 'RandomForestClassifier'\n",
    "desc = f'{algorithm} - {msg}'\n",
    "model = 'rfc_fit'\n",
    "data_type = 'Training'\n",
    "\n",
    "# display\n",
    "df_classfication, threshold = umf.classification_main(algorithm, model, desc, Model, X_train, y_train, data_type, metric_df=None, train_threshold=None)\n",
    "df_classfication"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a166fb6-5e00-4af2-98f1-ecb5f3eb8c7f",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90bfc210-638a-4117-8544-cda4dd568225",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize variable\n",
    "data_type = 'Validation/Test'\n",
    "\n",
    "# display\n",
    "df_classfication, _ = umf.classification_main(algorithm, model, desc, Model, X_test, y_test, data_type,  metric_df=df_classfication, train_threshold=None)\n",
    "df_classfication"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0971da9a-f3dd-4b04-81de-04091a314360",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d06a3e-62ee-46de-ba59-114c2b46e7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rfc = umf.plot_feature_importance(Model, pd.DataFrame(X_train, columns=X_train.columns.to_list()),figsize=(20,50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb1db3b-0a08-47db-b1a3-122164a85a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rfc.sort_values(by='Feature Importance Score', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c94fe88c-5e4a-475d-85ad-3f38ac9e2d17",
   "metadata": {},
   "source": [
    "### LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89060c7c-f2ed-44a1-bae8-294851bef97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import library\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# define the hyperparameter grid to search\n",
    "parameters = parms.lrc_parms(class_weight_dict)\n",
    "\n",
    "# Base Model\n",
    "lrc_param = {'max_iter':10000, 'random_state': RANDOM_STATE, 'solver': 'saga', 'penalty': 'elasticnet'}\n",
    "\n",
    "# instantiate LogisticRegression Classifier\n",
    "Model = LogisticRegression(**lrc_param)\n",
    "\n",
    "# CV with grid search for Hyper-Parameter tuning\n",
    "lrc_fit = umf.stratified_grid(Model, parameters, X_train, y_train, seed=RANDOM_STATE, n_jobs=-1, n_split=5, score='f1')\n",
    "\n",
    "# best model\n",
    "Model = lrc_fit.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287621c1-18c4-4ce4-b200-07056b9e7fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ffa95aa-5e9b-47b5-9dc1-a81472b465ee",
   "metadata": {},
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc81770b-8de7-4d34-80dc-ca8f8811ba0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize variables\n",
    "algorithm = 'LogisticRegression'\n",
    "desc = f'{algorithm} - {msg}'\n",
    "model = 'lrc_fit'\n",
    "data_type = 'Training'\n",
    "\n",
    "# display\n",
    "df_classfication, threshold = umf.classification_main(algorithm, model, desc, Model, X_train, y_train, data_type, metric_df=df_classfication, train_threshold=None)\n",
    "df_classfication"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0896a4-31fb-4438-ab29-ccf80a85d224",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b178221-d361-428e-a8b3-27fa355db0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize variable\n",
    "data_type = 'Validation/Test'\n",
    "\n",
    "# display\n",
    "df_classfication, _ = umf.classification_main(algorithm, model, desc, Model, X_test, y_test, data_type, metric_df=df_classfication, train_threshold=None)\n",
    "df_classfication"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b44141-be1c-42b5-8d81-0f5b3f108faf",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc9f804-41a0-44a2-aba0-74d1c1c56524",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lrc = umf.logistic_feature_importance(Model, figsize=(30,30), fontsize=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe45d37e-7df3-46dd-bc26-b3a514a61018",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lrc.sort_values(by='Coefficient', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0861be-44b2-4be1-be17-e2d5fdb8d725",
   "metadata": {},
   "source": [
    "### XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5eba33-9fb7-4ac7-96c4-15666cdfbb28",
   "metadata": {},
   "source": [
    "#### Explanation of the Gamma Parameter\n",
    "- In XGBoost, the regularization term that controls the minimum loss reduction required to make a split at a node is known as the \"gamma\" parameter. This parameter plays a crucial role in the decision-making process of the algorithm during the tree construction phase.\n",
    "- Definition: The gamma parameter specifies the minimum loss reduction required to make a further partition on a leaf node of the tree. If the reduction in loss from making a split is less than gamma, then that split will not be made.\n",
    "- Purpose: By setting a higher value for gamma, you can prevent overfitting by making the model more conservative. It effectively controls how complex the model can become by limiting the number of splits. A lower gamma allows more splits and can lead to a more complex model.\n",
    "- Impact on Model Complexity:\n",
    "    - High Gamma Value: Results in fewer splits, leading to simpler trees that may underfit the data.\n",
    "    - Low Gamma Value: Allows more splits, potentially leading to more complex trees that may overfit the training data.\n",
    "\n",
    "The gamma parameter is essential for controlling the complexity of models built using XGBoost by regulating how much improvement in loss is necessary for splitting nodes. Adjusting this parameter can help balance between bias and variance, thus improving model performance on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7345893f-f2f0-4083-8700-44784d345b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import library\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# calculate the scale_pos_weight to adjust for class imbalance\n",
    "# helps to counteract the imbalance by giving more weight to the minority class (usually the positive class in binary classification).\n",
    "scale_pos_weight = np.sum(y_train == 0) / np.sum(y_train == 1)\n",
    "\n",
    "# define the hyperparameter grid to search\n",
    "parameters = parameters = parms.xgbc_parms(scale_pos_weight)\n",
    "\n",
    "# Base Model\n",
    "xgb_param = {'random_state': RANDOM_STATE, 'tree_method':'hist', early_stopping_rounds=50}\n",
    "\n",
    "# instantiate XGB Classifier\n",
    "Model = XGBClassifier(**xgb_param)\n",
    "\n",
    "# CV with grid search for Hyper-Parameter tuning\n",
    "xgb_fit = umf.stratified_grid(Model, parameters, X_train, y_train,  seed=RANDOM_STATE, n_jobs=-1, n_split=5, score='f1')\n",
    "\n",
    "# best model\n",
    "Model = xgb_fit.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f9206e-a032-47f6-9dc0-4a317499b403",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734ecbca-3556-4cf8-8238-0fe4d3d33e9a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44228e0-6a5f-46e2-a889-8f324a8ee1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize variables\n",
    "algorithm = 'XGBClassifier'\n",
    "desc = f'{algorithm} - {msg}'\n",
    "model = 'xgb_fit'\n",
    "data_type = 'Training'\n",
    "\n",
    "# display\n",
    "df_classfication, threshold = umf.classification_main(algorithm, model, desc, Model, X_train, y_train, data_type, metric_df=df_classfication, train_threshold=None)\n",
    "df_classfication"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d3d0ba-f32f-48da-a191-b3668bbbe44e",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca61cf2-3cfe-44c6-84c4-76f41a3db490",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize variable\n",
    "data_type = 'Validation/Test'\n",
    "\n",
    "# display\n",
    "df_classfication, _ = umf.classification_main(algorithm, model, desc, Model, X_test, y_test, data_type, metric_df=df_classfication, train_threshold=None)\n",
    "df_classfication"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15a7f0b-0a10-4e08-ad33-b44ac1955b8d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f104b6a3-46f9-47d5-a342-9dc64a4cea73",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_xgb = umf.plot_feature_importance(Model, pd.DataFrame(X_train, columns=X_train.columns.to_list()),figsize=(20,50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994d8395-ebcb-4df9-81ec-3934c3a7bf64",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_xgb.sort_values(by = 'Feature Importance Score', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f57bed-1a3b-42b8-8df3-23bc27cb223e",
   "metadata": {},
   "source": [
    "### KNN\n",
    "- `K-Nearest Neighbors (KNN)`\n",
    "    - Type: Instance-based learning (lazy learning)\n",
    "    - Mechanism: Classifies a data point based on the majority class among its k-nearest neighbors.\n",
    "    - Pros: Simple, intuitive, no training phase.\n",
    "    - Cons: Computationally expensive during prediction, sensitive to irrelevant features and the choice of k."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40c7bc2-9193-456b-9fae-9c3f8faa73a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import library\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# define the parameter grid for GridSearchCV\n",
    "parameters = parameters = parms.knn_parms()\n",
    "\n",
    "# create a KNN model\n",
    "Model = KNeighborsClassifier(n_jobs=-1)\n",
    "\n",
    "# CV with grid search for Hyper-Parameter tuning\n",
    "knn_fit = umf.stratified_grid(Model, parameters, X_train, y_train, seed=RANDOM_STATE, n_jobs=-1, n_split=5, score='f1')\n",
    "\n",
    "# best model\n",
    "Model = knn_fit.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6915310e-c1eb-42d4-9a4d-41c7ad88e757",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd44b9f-a92e-481b-ae09-ab4b7e2d0996",
   "metadata": {},
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1fd445-2a17-456c-880c-f3ad23d34f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize variables\n",
    "algorithm = 'KNN'\n",
    "desc = f'{algorithm} - {msg}'\n",
    "model = 'knn_fit'\n",
    "data_type = 'Training'\n",
    "\n",
    "# display\n",
    "df_classfication, threshold = umf.classification_main(algorithm, model, desc, Model, X_train, y_train, data_type, metric_df=df_classfication, train_threshold=None)\n",
    "df_classfication"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc5452c-fba2-4686-b037-147a40f7a3f3",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b0e04e-870b-4015-a11d-daa6c8cdaeef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize variable\n",
    "data_type = 'Validation/Test'\n",
    "\n",
    "# display\n",
    "df_classfication, _ = umf.classification_main(algorithm, model, desc, Model, X_test, y_test, data_type, metric_df=df_classfication, train_threshold=None)\n",
    "df_classfication"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44bb63a-f6a7-4268-abb9-16d43766ae0b",
   "metadata": {},
   "source": [
    "### AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df623503-2c4b-472b-9b67-b34bc32aba6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import library\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# define the parameter grid for GridSearchCV\n",
    "parameters = parms.ada_parms()\n",
    "\n",
    "# base estimater\n",
    "estimator = DecisionTreeClassifier(max_depth=1)\n",
    "\n",
    "# create a AdaBoost model\n",
    "Model = AdaBoostClassifier(estimator=estimator, algorithm='SAMME', random_state=RANDOM_STATE)\n",
    "\n",
    "# CV with grid search for Hyper-Parameter tuning\n",
    "ada_fit = umf.stratified_grid(Model, parameters, X_train, y_train, seed=RANDOM_STATE, n_jobs=-1, n_split=5, score='f1')\n",
    "\n",
    "# best model\n",
    "Model = ada_fit.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da19d31a-a14f-471b-a928-1693d225ce6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223e0798-5f18-4b8a-9bed-8e2eaac25c70",
   "metadata": {},
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1ce207-9baa-4025-9aff-2a52cb683fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize variables\n",
    "algorithm = 'AdaBoost'\n",
    "desc = f'{algorithm} - {msg}'\n",
    "model = 'ada_fit'\n",
    "data_type = 'Training'\n",
    "\n",
    "# display\n",
    "df_classfication, threshold = umf.classification_main(algorithm, model, desc, Model, X_train, y_train, data_type, metric_df=df_classfication, train_threshold=None)\n",
    "df_classfication"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "232f4ad3-d8e7-4089-b4c7-f22f0a828310",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d431361f-405e-4d30-ab5b-c0ff3d920f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize variable\n",
    "data_type = 'Validation/Test'\n",
    "\n",
    "# display\n",
    "df_classfication, _ = umf.classification_main(algorithm, model, desc, Model, X_test, y_test, data_type, metric_df=df_classfication, train_threshold=None)\n",
    "df_classfication"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df406111-ed6d-4e86-a36f-650e3583a2e2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee3fa69-5473-4fee-96b6-b588eb20958c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ada = umf.plot_feature_importance(Model, pd.DataFrame(X_train, columns=X_train.columns.to_list()),figsize=(20,50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5914a343-515e-41b0-a0b5-c4150646ec0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ada.sort_values(by = 'Feature Importance Score', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456fc520-85ba-4cda-8beb-f25dc2e6903d",
   "metadata": {},
   "source": [
    "### Stacking Classifier\n",
    "- Both AdaBoost and XGBoost are boosting algorithms, but they have key differences:\n",
    "    - AdaBoost: Focuses on reducing bias by reweighting misclassified samples, works well with weak learners.\n",
    "        - AdaBoost → Handles noisy datasets and works well with simpler decision stumps. \n",
    "    - XGBoost: A gradient boosting algorithm that minimizes loss efficiently using second-order derivatives and feature importance techniques.\n",
    "        - XGBoost → Captures complex patterns, handles missing values, and optimizes performance.\n",
    "    - Random Forest is a bagging-based algorithm that reduces variance and is more robust to noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3eb9df-1819-462d-bd65-35a129a424e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import library\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "# best model\n",
    "AdaModel = ada_fit.best_estimator_\n",
    "XGBModel = xgb_fit.best_estimator_\n",
    "\n",
    "# filt model\n",
    "AdaModel.fit(X_train, y_train)\n",
    "XGBModel.fit(X_train, y_train)\n",
    "\n",
    "# create meta-model\n",
    "meta_model = LogisticRegression(random_state=RANDOM_STATE)\n",
    "\n",
    "# create stacking ensemble\n",
    "stacking_ensemble = StackingClassifier(\n",
    "    estimators=[('adaboost', AdaModel), ('xgboost', XGBModel)],\n",
    "    final_estimator=meta_model,\n",
    "    cv=5\n",
    ")\n",
    "\n",
    "# Fit the stacking ensemble\n",
    "stack_AdaXgb = stacking_ensemble.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53225fa3-17db-493a-899c-49f91b7849f3",
   "metadata": {},
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e71900-445d-41da-9279-7461dd8f5aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize variables\n",
    "algorithm = 'Stacking(AdaBoost & XGBoost)'\n",
    "desc = f'{algorithm} - {msg}'\n",
    "model = 'stack_AdaXgb'\n",
    "data_type = 'Training'\n",
    "\n",
    "# display\n",
    "df_classfication, threshold = umf.classification_main(algorithm, model, desc, stack_AdaXgb, X_train, y_train, data_type, metric_df=df_classfication, train_threshold=None)\n",
    "df_classfication"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3264ef7-a039-4437-9a84-85a8497c8e11",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b22bff-dbda-4fac-b1b4-ac3ca942aa7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize variables\n",
    "data_type = 'Validation/test'\n",
    "\n",
    "# display\n",
    "df_classfication, _ = umf.classification_main(algorithm, model, desc, stack_AdaXgb, X_test, y_test, data_type, metric_df=df_classfication, train_threshold=None)\n",
    "df_classfication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6675b96-9731-43fe-93ad-77186757bd9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "RFCModel = rfc_fit.best_estimator_\n",
    "XGBModel = xgb_fit.best_estimator_\n",
    "\n",
    "# filt model\n",
    "RFCModel.fit(X_train, y_train)\n",
    "XGBModel.fit(X_train, y_train)\n",
    "\n",
    "# create meta-model\n",
    "meta_model = LogisticRegression(random_state=RANDOM_STATE)\n",
    "\n",
    "# create stacking ensemble\n",
    "stacking_ensemble = StackingClassifier(\n",
    "    estimators=[('randomforest', RFCModel), ('xgboost', XGBModel)],\n",
    "    final_estimator=meta_model,\n",
    "    cv=5\n",
    ")\n",
    "\n",
    "# fit the stacking ensemble\n",
    "stack_RfcXgb = stacking_ensemble.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060a4719-c41a-4317-a092-d3c8ccd1fb0d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2e2714-5d71-4d65-9264-79c1fff94f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize variables\n",
    "algorithm = 'Stacking(RandomForest & XGBoost)'\n",
    "desc = f'{algorithm} - {msg}'\n",
    "model = 'stack_AdaXgb'\n",
    "data_type = 'Training'\n",
    "\n",
    "# display\n",
    "df_classfication, threshold = umf.classification_main(algorithm, model, desc, stack_RfcXgb, X_train, y_train, data_type, metric_df=df_classfication, train_threshold=None)\n",
    "df_classfication"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf61c5dc-7db7-4647-8bb2-96847fae2596",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0dd9319-903a-4cde-9943-417dfc811b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize variables\n",
    "data_type = 'Validation/test'\n",
    "\n",
    "# display\n",
    "df_classfication, _ = umf.classification_main(algorithm, model, desc, stack_RfcXgb, X_test, y_test, data_type, metric_df=df_classfication, train_threshold=threshold)\n",
    "df_classfication"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6138eb36-4467-4ec3-8e56-4d8ac0c162a2",
   "metadata": {},
   "source": [
    "#### Hyper-Paramater Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "addb378e-3add-4677-bf9f-7cbddd56b2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# paramater search\n",
    "parameters = parameters = parms.lrc_parms()\n",
    "\n",
    "# Base Model\n",
    "lrc_param = {'max_iter':10000, 'class_weight': class_weight_dict, 'random_state': RANDOM_STATE}\n",
    "\n",
    "# create meta-model\n",
    "meta_model = LogisticRegression(**lrc_param)\n",
    "\n",
    "# CV with grid search for Hyper-Parameter tuning\n",
    "meta_model_fit = umf.stratified_grid(meta_model, parameters, X_train, y_train, seed=RANDOM_STATE, n_jobs=-1, n_split=5, score='f1')\n",
    "\n",
    "# best model\n",
    "meta_model = meta_model_fit.best_estimator_\n",
    "\n",
    "# create stacking ensemble\n",
    "stacking_ensemble = StackingClassifier(\n",
    "    estimators=[('randomforest', RFCModel), ('xgboost', XGBModel)],\n",
    "    final_estimator=meta_model,\n",
    "    cv=5\n",
    ")\n",
    "\n",
    "# fit the stacking ensemble\n",
    "stack_GS_RfcXgb = stacking_ensemble.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f373b9-58d2-4af3-8c9c-dbca8d257964",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(stack_GS_RfcXgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e7c281e-7f9b-4bc7-9450-0b0dd4a0e9ce",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f076ed87-c901-4fb8-b305-e2289b442083",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize variables\n",
    "algorithm = 'Stacking(RandomForest & XGBoost)'\n",
    "desc = f'{algorithm} - {msg}'\n",
    "model = 'stack_GS_RfcXgb'\n",
    "data_type = 'Training'\n",
    "\n",
    "# display\n",
    "df_classfication, threshold = umf.classification_main(algorithm, model, desc, stack_GS_RfcXgb, X_train, y_train, data_type, metric_df=df_classfication, train_threshold=None)\n",
    "df_classfication"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd25b9f7-b0d6-4f9c-b14f-4428b2b3802d",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1f20c3-c4fc-4e15-9dab-30dc27098936",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize variables\n",
    "data_type = 'Validation/test'\n",
    "\n",
    "# display\n",
    "df_classfication, _ = umf.classification_main(algorithm, model, desc, stack_GS_RfcXgb, X_test, y_test, data_type, metric_df=df_classfication, train_threshold=None)\n",
    "df_classfication"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a705164e-47ad-46c1-a54b-fad7bd2a5089",
   "metadata": {},
   "source": [
    "## Overall Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413593ed-2965-4df8-939d-35b1d7558542",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display\n",
    "filtered_df = df_classfication[df_classfication.DataType != 'Training']\n",
    "filtered_df.sort_values(by=['Accuracy', 'ROC_AUC_Score'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5362f370-abd2-438f-af96-628b36851c00",
   "metadata": {},
   "source": [
    "## Save Model to Disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61bdded0-a61d-41ba-ba89-ebcd7553e40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# get the best model\n",
    "XGBmodel = xgb_fit.best_estimator_\n",
    "LRmodel = lrc_fit.best_estimator_\n",
    "RFmodel = rfc_fit.best_estimator_\n",
    "ADAmodel = ada_fit.best_estimator_\n",
    "KNNmodel = knn_fit.best_estimator_\n",
    "\n",
    "# save the model to a file\n",
    "print(joblib.dump(XGBmodel, '../Models/XGBmodel_Original_GridSearch.joblib'))\n",
    "print(joblib.dump(LRmodel, '../Models/LRmodel_Original_GridSearch.joblib'))\n",
    "print(joblib.dump(RFmodel, '../Models/RFmodel_Original_GridSearch.joblib'))\n",
    "print(joblib.dump(ADAmodel, '../Models/ADAmodel_Original_GridSearch.joblib'))\n",
    "print(joblib.dump(KNNmodel, '../Models/KNNmodel_Original_GridSearch.joblib'))\n",
    "\n",
    "# load the model from the file\n",
    "# loaded_model = joblib.load('../Models/KNN_Threshold.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "774d504a-5d70-40e9-85ff-1d1f2a3b6df5",
   "metadata": {},
   "source": [
    "#### Save Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2990afa-cc34-4458-ad49-7d5c1963abbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write dataset - # X_train, y_train, X_test, y_test files\n",
    "uf.write_to_file(X_train, 'X_train_GINI_GridCV_Orig',path='../Data/XyData/', format='pkl')\n",
    "uf.write_to_file(y_train, 'y_train_GINI_GridCV_Orig',path='../Data/XyData/', format='pkl')\n",
    "uf.write_to_file(X_test, 'X_test_GINI_GridCV_Orig',path='../Data/XyData/', format='pkl')\n",
    "uf.write_to_file(y_test, 'y_test_GINI_GridCV_Orig',path='../Data/XyData/', format='pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RFSurvival",
   "language": "python",
   "name": "survival_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
