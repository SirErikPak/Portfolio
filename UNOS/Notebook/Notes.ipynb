{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d569f6c-1e25-4bee-803c-e2342028dc06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(bool(1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b89bb1e-0ae2-499b-956c-2fc0c8697f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictionThreshold(model, threshold, Xdata):\n",
    "    # get the best model\n",
    "    modelBest = model.best_estimator_\n",
    "    \n",
    "    # predict probabilities\n",
    "    probabilities = modelBest.predict_proba(Xdata)\n",
    "\n",
    "    print(probabilities)\n",
    "    # define custom threshold\n",
    "    custom_threshold = threshold\n",
    "    \n",
    "    # assign class labels based on the custom threshold\n",
    "    predictions = (probabilities[:, 1] >= custom_threshold).astype(int)\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f715d973-82cb-4a33-b5ba-a80cb233cdfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score, f1_score\n",
    "\n",
    "# Sensitivity/Recall for the positive class (label=1 by default)\n",
    "recall_scorer = make_scorer(recall_score, pos_label=1)\n",
    "f1_scorer = make_scorer(f1_score, pos_label=1) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1cdbd4b-e844-43c7-a1ad-59a280763083",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define multiple scoring metrics\n",
    "scoring = {\n",
    "    'accuracy': 'accuracy',\n",
    "    'f1_macro': make_scorer(f1_score, average='macro')  # Custom F1 scorer\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ccd5a1a-8986-415b-9996-ed221819fac0",
   "metadata": {},
   "source": [
    "1. Adjust the decision threshold\n",
    "Most classifiers default to threshold = 0.5. But you can lower it to capture more positives:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65885f52-f2f1-41cb-ba18-bbc2ef091773",
   "metadata": {},
   "source": [
    "2. Use F-beta Score to favor recall\n",
    "- β < 1 → favors precision\n",
    "- β = 1 → balances precision & recall (this is the F1 score)\n",
    "- β > 1 → favors recall\n",
    "\n",
    "- The F-beta Score is a metric that combines precision and recall into a single number, giving you a way to balance the two based on your priorities.\n",
    "    - Precision = How many selected items are relevant (i.e., how many predicted positives are actually positive)?\n",
    "    - Recall = How many relevant items are selected (i.e., how many actual positives did we catch)?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc19c009-89e8-40fe-88d9-b5e9a12d623d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import fbeta_score\n",
    "\n",
    "# y_true: actual labels\n",
    "# y_pred: predicted labels\n",
    "fbeta_score(y_true, y_pred, beta=2)  # favors recall more\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20d21b82-acfd-4632-b76c-d4d47744b5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import library\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import optuna\n",
    "\n",
    "def objective(trial):\n",
    "    n_estimators = trial.suggest_int(\"n_estimators\", 50, 500)\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-3, 1.0, log=True)\n",
    "    max_depth = trial.suggest_int(\"max_depth\", 2, 10)\n",
    "    \n",
    "    model = XGBClassifier(\n",
    "        n_estimators=n_estimators,\n",
    "        learning_rate=learning_rate,\n",
    "        max_depth=max_depth\n",
    "    )\n",
    "    return cross_val_score(model, X, y, cv=3, scoring=\"roc_auc\").mean()\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da317be7-136b-4159-9a2d-8ff9e4bce3ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Real(low=0.01, high=7.0, prior='log-uniform', transform='identity')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from skopt.space import Real, Integer, Categorical\n",
    "\n",
    "Real(0.01, 7.0, 'log-uniform')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90d55e5-ee79-47e8-bd44-1c45bd2301ff",
   "metadata": {},
   "source": [
    "A Gaussian copula is a type of copula used in statistics to model the dependence structure between multiple random variables. It is particularly useful when the variables follow a normal distribution. \n",
    "\n",
    "- Key Concepts\n",
    "    - Copula: A function that links univariate marginal distribution functions to form a multivariate distribution.\n",
    "    - Gaussian Copula: Uses the multivariate normal distribution to describe the dependence between variables.\n",
    "        - How It Works\n",
    "            - Marginal Distributions: Convert each variable to a uniform distribution using its cumulative distribution function (CDF).\n",
    "            - Standard Normal Quantile Function: Transform these uniform variables to standard normal variables.\n",
    "            - Correlation Matrix: Model the dependencies using a correlation matrix.\n",
    "- Gaussian copulas are widely used in finance for risk management and portfolio optimization. They help in modeling the joint behavior of asset returns and assessing the risk of extreme events.\n",
    "- Advantages\n",
    "    - Flexibility: Gaussian copulas can model a wide range of dependency structures, including both positive and negative correlations.\n",
    "    - Simplicity: They are relatively easy to implement and understand, making them a popular choice in various applications.\n",
    "    - Tractability: The mathematical properties of Gaussian copulas allow for efficient computation and estimation, which is particularly useful in high-dimensional settings.\n",
    "    - Compatibility: They work well with normal marginals, which are common in many practical scenarios.\n",
    "    - Wide Application: Gaussian copulas are extensively used in finance for risk management and portfolio optimization due to their ability to model joint behaviors of asset returns.\n",
    "        - Applications\n",
    "            - Risk Management: Helps in assessing the risk of extreme events by modeling dependencies between different financial instruments.\n",
    "            - Portfolio Optimization: Assists in optimizing portfolios by understanding the joint distribution of asset returns.\n",
    "- Limitations\n",
    "    - Lack of Tail Dependence: Gaussian copulas do not capture extreme co-movements well, meaning they lack both upper and lower tail dependence. This can be problematic in scenarios where extreme events are crucial, such as financial crises.\n",
    "    - Assumption of Normality: They assume that the underlying variables follow a normal distribution, which may not always be the case. This can lead to inaccurate modeling if the actual data deviates significantly from normality.\n",
    "    - Static Nature: Gaussian copulas are static models and do not account for dynamic changes in dependencies over time. This can limit their effectiveness in applications requiring time-varying correlations.\n",
    "    - Simplification: The simplification inherent in Gaussian copulas can sometimes lead to oversimplified models that fail to capture complex dependencies.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9daebd33-0a61-45cd-a37e-a21b8922df76",
   "metadata": {},
   "source": [
    "- The `Kruskal-Wallis H Test` is a nonparametric method used to compare three or more independent groups based on an ordinal or continuous dependent variable. Contrary to common misconceptions, it does not compare medians directly but tests whether samples originate from the same distribution (or distributions with the same shape and spread).\n",
    "\n",
    "    - Here's a detailed breakdown:\n",
    "        1. Purpose\n",
    "            - Use Case: Determine if there are statistically significant differences between groups (nominal/ordinal) on a ranked dependent variable (ordinal/interval/ratio).\n",
    "\n",
    "        - Example: Compare customer satisfaction scores (ordinal: 1–5) across three store locations (nominal: A, B, C).\n",
    "\n",
    "        2. Key Assumptions\n",
    "            - Independent Groups: Groups are mutually exclusive (e.g., different participants in each group).\n",
    "            - Ordinal/Continuous Data: Dependent variable is at least ordinal or continuous.\n",
    "            - Similar Shape/Spread: Distributions across groups should have similar shapes and variances (though not strictly required for validity).\n",
    "\n",
    "        3. How It Works\n",
    "            - Rank All Data: Combine all groups and rank the dependent variable values.\n",
    "            - Calculate Group Ranks: Compute the sum of ranks for each group.\n",
    "        4. Misconceptions Clarified\n",
    "            - Not a Median Test: While often interpreted as comparing medians, the test evaluates differences in rank distributions (which may align with medians if distributions have similar shapes).\n",
    "            - Nonparametric: Does not assume normality (unlike ANOVA).\n",
    "        5. When to Use\n",
    "            - Ordinal Data: Likert scales, rankings.\n",
    "            - Non-Normal Continuous Data: Skewed distributions or small samples.\n",
    "            - Unequal Group Sizes: Robust to imbalanced group sizes.\n",
    "        6. Post-Hoc Analysis\n",
    "            - If the Kruskal-Wallis test is significant, use Dunn’s test to identify pairwise differences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8610b5e6-5296-4021-9958-1933beed5565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kruskal-Wallis H Statistic: 10.411\n",
      "P-value: 0.005\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import kruskal\n",
    "\n",
    "# Example data: Exam scores (ordinal/continuous) across three teaching methods\n",
    "group_A = [78, 85, 88, 92, 95]\n",
    "group_B = [65, 70, 75, 80, 85]\n",
    "group_C = [50, 55, 60, 65, 70]\n",
    "\n",
    "# Perform Kruskal-Wallis test\n",
    "statistic, p_value = kruskal(group_A, group_B, group_C)\n",
    "\n",
    "print(f\"Kruskal-Wallis H Statistic: {statistic:.3f}\")\n",
    "print(f\"P-value: {p_value:.3f}\")\n",
    "\n",
    "\n",
    "\n",
    "#  Interpretation\n",
    "# Significant Result: The small p-value (p < 0.05) means there are significant differences in the distributions of your dependent variable across the groups.\n",
    "\n",
    "# Reject the Null Hypothesis: The groups are not all from the same population (or populations with the same median/shape)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b07a9af-13e4-4977-ba8b-af9236f03797",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          1         2         3\n",
      "1  1.000000  0.115458  1.000000\n",
      "2  0.115458  1.000000  0.027465\n",
      "3  1.000000  0.027465  1.000000\n"
     ]
    }
   ],
   "source": [
    "import scikit_posthocs as sp\n",
    "\n",
    "# Step 1: Define groups\n",
    "group_A = [9, 10, 16, 9, 10, 5, 7, 13, 10, 9]\n",
    "group_B = [16, 19, 15, 17, 19, 11, 6, 17, 11, 9]\n",
    "group_C = [7, 9, 5, 8, 8, 14, 11, 9, 14, 8]\n",
    "\n",
    "# Step 2: Combine data\n",
    "data = [group_A, group_B, group_C]\n",
    "\n",
    "# Step 3: Perform Dunn's test\n",
    "dunn_results = sp.posthoc_dunn(data, p_adjust='bonferroni')\n",
    "print(dunn_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8879b9ad-bcdd-4228-9aad-39fcf971f92a",
   "metadata": {},
   "source": [
    "#### Post-hoc Dunn’s tests with Bonferroni correction revealed a significant difference between Group 2 and Group 3 (p = .027), but no significant differences between Group 1 and Group 2 (p = .115) or Group 1 and Group 3 (p > .999).\n",
    "- Common Pitfalls\n",
    "    - Misreading the Matrix: Diagonal values (e.g., 1 vs. 1) are always 1.000 (self-comparison).\n",
    "    - Ignoring Adjustments: Bonferroni reduces Type I errors but increases Type II risk. Consider alternatives like Benjamini-Hochberg for less stringent corrections.\n",
    "    - Overinterpreting Non-Significance: Small sample sizes or high variance can mask true differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31b51fe9-0719-41cb-b84d-8cf20851c65b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAh8AAAGxCAYAAADCo9TSAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABAEUlEQVR4nO3dd3hUZd7/8U/qpAATQ0nRJBARgUgoIkoxgIpICSJ2OrigBFYFH0SaEZci6LqoEBBZQSQo7goRBAELEH0MLoiYFVFEQ1kg4ENJqAGS+/eHv8wyZBIIDGdS3q/rygVzn/uc852ZMzOfOeUeL2OMEQAAgEW8PV0AAACoXAgfAADAUoQPAABgKcIHAACwFOEDAABYivABAAAsRfgAAACWInwAAABLET4AAIClKn34yMzM1GOPPabrr79egYGBCgwM1A033KDHH39cmzZt8nR5V+zLL7/UQw89pGuvvVb+/v6y2+1q1aqVZs2apRMnTni6vKuuXbt2ateunafLuGJ33nmnnnjiCae2bdu2qU+fPoqNjVVAQIBq1KihZs2aadiwYcrNzXX069+/v2rXrn3Va6xdu7b69+/v1Pbdd9+pbdu2stvt8vLy0vTp07Vu3Tp5eXlp3bp1V72mi1m0aJGmT5/ulmXl5ubqpZde0q233qqQkBD5+fkpLCxM99xzjxYtWqS8vDy3rMdq27dv1//8z//o5ptvVkhIiEJDQ9W6dWv985//9HRpF3XgwAGNGTNGTZo0UbVq1eTv76/rrrtOPXr00LJly5Sfn+/pEi/Lnj17dN999yk2NlbBwcGy2+1q2rSpZsyYoXPnzjn17dOnj7p37+6ZQktiKrHZs2cbX19fExcXZ1577TXz2Wefmc8//9zMmDHDtG7d2kgyO3bs8HSZl+355583kkyrVq3M3//+d7Nu3TqzcuVKM27cOFOrVi3z9NNPe7rEq27r1q1m69atni7jiqSlpRmbzWb+85//ONo2b95sAgMDTbNmzcy8efPM2rVrzT/+8Q8zbtw4U7duXZOVleXou2PHDrN58+arXufmzZuLvF6aNGlibrjhBrNy5UqTkZFh9u/fb3JyckxGRobJycm56jVdTJcuXUxMTMwVL2f79u0mNjbWVKlSxYwYMcJ89NFHJj093SxevNgMHDjQ2Gw2M27cuCsv2APeeOMNU79+fTNp0iSzZs0as3LlStOvXz8jyUyYMMHT5RUrIyPD1KxZ09SoUcOMHz/erFixwqxfv968++675qGHHjI+Pj5m7ty5ni7zsmzbts307dvXvP322+azzz4zK1euNMOGDTOSzGOPPebUd8eOHcbX19d8/vnnHqrWtUobPr766ivj7e1tEhMTTV5enss+H3zwgdm7d2+Jyzlx4sTVKO+KffDBB44NsaCgoMj03Nxcs3r1ag9UZo2y+rxcjhYtWphHHnnEqa1v374mODjY5ObmupzH1XPuCb6+vmbIkCGeLqNY7ggfZ8+eNQ0bNjQhISHmxx9/dNln586dZunSpSUu58yZM+bs2bNXVMvV8Pvvv7vcnrp06WKCgoLM6dOnPVBVyY4cOWLCwsJMnTp1zL59+1z2+f77780XX3xR4nJOnjxZZl5Ll+Khhx4yvr6+RZ6Trl27mg4dOnioKtcqbfjo3Lmz8fPzK3bDdKVfv34mODjYZGZmmg4dOpgqVaqY2267zRhjzKFDh8yQIUNMZGSk8fPzM3Xq1DFjxoxx2giysrKMJDNv3rwiy5ZkkpOTHbeTk5ONJLN582Zz3333mapVq5pq1aqZXr16mYMHD1601ptuuslcc801l/whfOrUKfPcc8+Z2rVrGz8/PxMZGWmSkpLMkSNHnPrFxMSYLl26mOXLl5smTZqYgIAAU79+fbN8+XJjjDHz5s0z9evXN0FBQeaWW24xGzdudPkY/vDDD+aOO+4wQUFBpkaNGmbo0KFFap0xY4a5/fbbTc2aNU1QUJC56aabzNSpU82ZM2ec+rVt29bExcWZ9evXm5YtW5rAwEDz8MMPO6a1bdvWqX9KSoqJj483wcHBpkqVKubGG280o0ePdurz73//23Tr1s2EhIQYm81mGjdubObPn+/UZ+3atUaSWbRokRkzZoyJiIgwVatWNXfeeaf56aefnPpu3rzZdOnSxdSsWdP4+/ubiIgI07lzZ7Nnz54Sn5fNmzcbSWbFihVO7V26dDERERGX9MbYr1+/Ih+wR44cMQMHDjTXXHONCQ4ONp07dza//vprsdvhDz/8YB555BFTrVo1U6tWLTNgwABz9OhRp2XGxMSYfv36GWP+2A4kFfk7/3Fbu3at0/wbNmwwXbt2NaGhocZms5nY2Fjz1FNPOab/8ssvpn///qZu3bomMDDQREZGmq5du5rMzEyn5Vzq89K2bdtiayyNwqD/8ssvX/I8hTUuWLDAjBgxwkRGRhovLy+zbds2Y4wxf//73018fLyx2WzmmmuuMd27dy8SbFxt28YUfb4L33emTp1qJk6caKKioozNZjM333yz+eyzz0p9fwtNmDDBSCrxPXTLli1Gkss9DCtXrjSSzEcffWSMMebgwYNm0KBB5rrrrjP+/v6mRo0aplWrVubTTz8tdW3Tpk0zksw//vGPS56ncJtdvXq1GTBggKlRo4aRZE6dOmXy8/PN1KlTzY033mj8/f1NzZo1TZ8+fYq8fs9/DZzvwueq8Pl/9913zfDhw01YWJgJCAgwCQkJV7SXcujQocbf379IiF28eLHx8vIqU3vyK+U5H/n5+Vq7dq2aN2+uiIiIUs175swZdevWTXfccYc++ugjTZgwQadPn1b79u21YMECjRgxQitWrFDv3r01bdo09ejR44pqve+++1S3bl3985//1AsvvKC0tDR17NhRZ8+eLXae/fv364cfftDdd9+toKCgi67DGKPu3bvrlVdeUZ8+fbRixQqNGDFC77zzju64444ix6q///57jR49WqNGjdKSJUtkt9vVo0cPJScna+7cuZo8ebJSU1OVk5Ojrl276tSpU07znz17Vp07d9add96ptLQ0DRs2TG+++aYefvhhp36//vqrevbsqXfffVcff/yxHnvsMb388st6/PHHXd7n3r17q2fPnlq5cqWSkpJc3tf3339fSUlJatu2rZYuXaq0tDQNHz7c6fyXn3/+Wa1atdLWrVv1+uuva8mSJWrYsKH69++vadOmFVnmmDFjtGvXLs2dO1dz5szRL7/8osTERMfx5BMnTqhDhw46cOCAZs6cqU8//VTTp09XdHS0jh07VuJz8/HHH8vHx0cJCQlO7S1bttT+/fvVq1cvrV+/vshjXJKCggIlJiZq0aJFGjVqlJYuXapbb71V99xzT7Hz3H///apXr54+/PBDPffcc1q0aJGGDx9ebP8uXbooIyNDkvTAAw8oIyPDcduV1atX6/bbb9fu3bv16quv6pNPPtG4ceN04MABR599+/apevXqeumll7Rq1SrNnDlTvr6+uvXWW/Xzzz8XWebFnpeUlBS1bt1a4eHhjvrOr7F///7y8vLSzp07i61bkj799FNJUrdu3Urs58ro0aO1e/duzZ49W8uXL1etWrU0ZcoUPfbYY4qLi9OSJUv02muvKTMzUy1bttQvv/xS6nUUmjFjhlatWqXp06dr4cKF8vb2VqdOnUp8Xkqydu1a1axZU7Vq1Sq2T+PGjdW0aVPNmzevyLT58+erVq1a6ty5s6Q/zk1IS0vT888/rzVr1mju3Lm66667dOjQoVLX9umnn8rHx8ex7NIYOHCg/Pz89O677+qf//yn/Pz8NGTIEI0aNUodOnTQsmXL9Je//EWrVq1Sq1at9H//93+lXkehMWPG6LffftPcuXM1d+5c7du3T+3atdNvv/12SfMbY3Tu3DkdOXJEixcv1vz58/XMM8/I19fXqV+7du1kjNHKlSsvu1a383D48Yjs7GwjqciubGOMOXfunDl79qzj7/xvloXHOd9++22neWbPnm0kmQ8++MCpferUqUaSWbNmjTHm8vZ8DB8+3KlfamqqkWQWLlxY7P3bsGGDkWSee+65Yvucb9WqVUaSmTZtmlP74sWLjSQzZ84cR1tMTIwJDAx0Ov+g8NtNRESE096LtLQ0I8ksW7bM0Vb4GL722mtO65o0aZKRZL766iuXNebn55uzZ8+aBQsWGB8fH3P48GHHtMJvsK6OaV74jWPYsGEmJCSkxMfjkUceMTabzezevdupvVOnTiYoKMjxjb/w20vnzp2d+hV+E87IyDDGGLNp0yYjyaSlpZW4Xlc6depk6tevX6T99OnTpnv37o5v6z4+PqZp06Zm7NixRfaMXfhNeMWKFUaSmTVrllO/KVOmFLsdXrhtJCUlmYCAAKfXh6tvfZLM0KFDndpc7fm4/vrrzfXXX29OnTpV0sPh5Ny5c+bMmTPmhhtucHqdXOrzYkzJh10GDhxofHx8zM6dO0us45577jGSiuzqLigocHovOXfuXJEaExISnOY5cuSICQwMLFL77t27jc1mMz179nS0lXbPR2RkpNPjm5uba0JDQ81dd91V4v1z5a233nL5Onbl9ddfN5LMzz//7Gg7fPiwsdls5plnnnG0ValSxW3nodWvX9+Eh4cXaS98Hyn8y8/Pd0wr3PPRt29fp3m2bdtmJJmkpCSn9m+++cZIMmPGjHG0lXbPR7NmzZxeQzt37jR+fn7mT3/60yXdz8LXrCTj5eVlxo4dW2zfa6+91rFHuCyolHs+SnLzzTfLz8/P8ffXv/61SJ/777/f6fYXX3yh4OBgPfDAA07thWf+f/7555ddT69evZxuP/TQQ/L19dXatWsve5kX+uKLLySpyJUKDz74oIKDg4vU36RJE1177bWO2w0aNJD0R7o+f09LYfuuXbuKrPPC+9WzZ09Jcrpf3333nbp166bq1avLx8dHfn5+6tu3r/Lz87V9+3an+a+55hrdcccdF72vLVq00NGjR/Xoo4/qo48+cvmt5YsvvtCdd96pqKgop/b+/fvr5MmTRb4pXviNNz4+XtJ/73fdunV1zTXXaNSoUZo9e7Z+/PHHi9ZZaN++fS6/WdpsNi1dulQ//vij/va3v+mRRx7R77//rkmTJqlBgwYu9wQUWr9+vaQ/tqXzPfroo8XO4+o+nj59WgcPHrzk+1Kc7du369dff9Vjjz2mgICAYvudO3dOkydPVsOGDeXv7y9fX1/5+/vrl19+0bZt2y6pZsn19ujK3//+d507d04xMTGluDf/9dprrzm9lzRu3LhInwvfSzIyMnTq1Kkir8WoqCjdcccdV/Re0qNHD6fHt2rVqkpMTFR6enqprvr45JNPNHToUD3wwAP685//fNH+vXr1ks1m0/z58x1t7733nvLy8jRgwABHW4sWLTR//nxNnDhRGzZsKHHv7uUaMWKE03Piam/Vhc9J4XvShc9JixYt1KBBgyt6Tnr27CkvLy/H7ZiYGLVq1eqS39/79++vjRs3avXq1Xr22Wf18ssvF/uc1KpVS3v37r3sWt2tUoaPGjVqKDAw0OWb0KJFi7Rx40YtW7bM5bxBQUGqVq2aU9uhQ4cUHh7utBFJfzzZvr6+l7XbsFB4eLjTbV9fX1WvXr3EZUZHR0uSsrKyLmkdhw4dkq+vr2rWrOnU7uXlpfDw8CLrCg0Ndbrt7+9fYvvp06dd3ofzFd7PwnXt3r1bt99+u/bu3avXXntNX375pTZu3KiZM2dKUpHDDJd6+KxPnz56++23tWvXLt1///2qVauWbr31Vseu88IaXC0vMjLSqcZCF94Xm83mVKPdbtf69evVpEkTjRkzRnFxcYqMjFRycvJF32BPnTpV4gdygwYN9PTTT2vhwoWOQxaHDh3S+PHji52n8Pm+8PkKCwsrdp6L3ccr8fvvv0uSrrvuuhL7jRgxQuPHj1f37t21fPlyffPNN9q4caMaN27sso6rWfP5Cl9vF76f9OzZUxs3btTGjRvVrFkzl/NeuJ0VblvFbX/ufC8pbDtz5oyOHz9+SctYvXq1evTooQ4dOig1NbXIe54roaGh6tatmxYsWOAIOfPnz1eLFi0UFxfn6Ld48WL169dPc+fOVcuWLRUaGqq+ffsqOzv7Eu/hf0VHR+v333/XyZMnndqfeeYZx3NS3HtGWXhOLnWZ4eHhat68ue6++2699NJLevHFFzVjxgx99913RfoGBAS4fdu/EpUyfPj4+OiOO+7Qpk2btH//fqdpDRs2VPPmzdWoUSOX87p6sVWvXl0HDhyQMcap/eDBgzp37pxq1KghSY4PkQvPoShpQ7vwhXfu3DkdOnSoyBvr+SIiItSoUSOtWbOmyIvPlerVq+vcuXOOD4FCxhhlZ2c76neXwvtwvsL7WXi/0tLSdOLECS1ZskS9e/dWmzZt1Lx5c0egudClvAkWGjBggL7++mvl5ORoxYoVMsaoa9eujg+P6tWrF9kupD/2Qki6rMejUaNGev/993Xo0CFt2bJFDz/8sF588UWXe9bOV6NGDR0+fPiS1uHl5aXhw4crJCREP/zwQ7H9Cp/vC5d7OW/y7lAYev/zn/+U2G/hwoXq27evJk+erI4dO6pFixZq3rz5FR1zd4cOHTpIUpEvLLVq1VLz5s3VvHlzVa1a1eW8F263hdt/cdvf+dteQECAy7FDins8XD2/2dnZ8vf3V5UqVVzOc77Vq1ere/fuatu2rT788MNiX4uuDBgwQHv37tWnn36qH3/8URs3bnTa6yH9sa1Pnz5dO3fu1K5duzRlyhQtWbKkyB6HS9GhQwfl5+cXOcchKirK8Zxc6nuJJ56Tkt7fS9KiRQtJKrJnWJIOHz7s9vfyK1Epw4f0x4le+fn5euKJJ654996dd96p48ePKy0tzal9wYIFjunSH98sAwIClJmZ6dTvo48+KnbZqampTrc/+OADnTt37qIDZ40fP15HjhzRk08+WSQUSdLx48e1Zs0ap/oWLlzo1OfDDz/UiRMnHNPd6cL7tWjRIkly3K/CN4DCb6vSH2HorbfeclsNwcHB6tSpk8aOHaszZ85o69atkv54PL744gtH2Ci0YMECBQUF6bbbbrvsdXp5ealx48b629/+ppCQEG3evLnE/vXr13d58pmrN0LpjzfD3Nxcx14aV9q2bSvpj2+a53v//fcvVv5VUa9ePV1//fV6++23SxyIy8vLy2l7kKQVK1Zc0a5km812xd8G77vvPjVs2FCTJ0/WTz/9dEXLatmypQIDA4u8Fv/zn/84DgcWql27trZv3+70mB06dEhff/21y2UvWbLEaS/ksWPHtHz5ct1+++3y8fEpsa41a9aoe/fuatOmjdLS0oo8Dxdz991369prr9W8efM0b948BQQElHiYLzo6WsOGDVOHDh0u+hpx5U9/+pPCwsL07LPPFvtauVSFh3MvfE42btyobdu2FXlOLnx/3759e7GHQd977z2n9+ddu3bp66+/vuyBEQsP19StW9ep/dy5c9qzZ48aNmx4Wcu9Gnwv3qViat26tWbOnKk///nPatasmQYPHqy4uDh5e3tr//79+vDDDyWpyCEWV/r27auZM2eqX79+2rlzpxo1aqSvvvpKkydPVufOnXXXXXdJ+uPNs3fv3nr77bd1/fXXq3HjxvrXv/7l+OB1ZcmSJfL19VWHDh20detWjR8/Xo0bNy5yvP5CDz74oMaPH6+//OUv+umnnxyjuJ48eVLffPON4+qSu+++Wx06dFDHjh01atQo5ebmqnXr1srMzFRycrKaNm2qPn36lOKRvTh/f3/99a9/1fHjx3XLLbfo66+/1sSJE9WpUye1adNG0h/fXPz9/fXoo4/q2Wef1enTpzVr1iwdOXLkitY9aNAgBQYGqnXr1oqIiFB2dramTJkiu92uW265RZKUnJysjz/+WO3bt9fzzz+v0NBQpaamasWKFZo2bZrsdnup1vnxxx8rJSVF3bt3V2xsrIwxWrJkiY4ePer41lycdu3a6e2339b27dtVr149R/vgwYN19OhR3X///brpppvk4+Ojn376SX/729/k7e2tUaNGFbvMe+65R61bt9Yzzzyj3Nxc3XzzzcrIyHCEZW9v67+TzJw5U4mJibrttts0fPhwRUdHa/fu3Vq9erUjqHbt2lXz589X/fr1FR8fr2+//VYvv/zyRQ/XlKRRo0ZasmSJZs2apZtvvlne3t5q3ry5JOmxxx7TO++8o19//bXE8z58fHwcV6G1aNFCgwYNUrt27XTNNdfo6NGj+uabb/T99987zoEqSUhIiMaPH68xY8aob9++evTRR3Xo0CFNmDBBAQEBSk5OdvTt06eP3nzzTfXu3VuDBg3SoUOHNG3atGLfs3x8fNShQweNGDFCBQUFmjp1qnJzczVhwoQSa/rqq6/UvXt3hYeHa8yYMdqyZYvT9IYNG170fdLHx0d9+/bVq6++qmrVqqlHjx5Or6OcnBy1b99ePXv2VP369VW1alVt3LhRq1atcrpi8MUXX9SLL76ozz//3BGiXQkJCVFaWpoSExPVuHFjDRkyRLfddpuqVKmiQ4cOKT09XdnZ2WrVqlWJdUvSjTfeqMGDB+uNN95wXCG0c+dOjR8/XlFRUU5XffXp00e9e/dWUlKS7r//fu3atUvTpk0rcki70MGDB3Xfffdp0KBBysnJUXJysgICAjR69OgSa0pOTtaBAweUkJCga6+9VkePHtWqVav01ltv6cEHH9TNN9/s1D8zM1MnT55U+/btL3p/LePBk13LhC1btpgBAwaYOnXqGJvNZgICAkzdunVN3759i1w9UThGhSuHDh0yTzzxhImIiDC+vr4mJibGjB49usgZ8Dk5OeZPf/qTCQsLM8HBwSYxMdHs3Lmz2KsMvv32W5OYmGiqVKliqlatah599FFz4MCBS75/69evNw888ICJiIgwfn5+plq1aqZly5bm5Zdfdhqg6tSpU2bUqFEmJibG+Pn5mYiICDNkyJBix/m4kFxc1VB4lv354x+cP1ZKu3btTGBgoAkNDTVDhgwxx48fd5p/+fLlpnHjxiYgIMBce+21ZuTIkeaTTz4pcqVE4Tgfrlx4lvk777xj2rdvb8LCwoy/v7+JjIw0Dz30UJGxIv7973+bxMREY7fbjb+/v2ncuHGRq5QKz1i/cCyBC69q+umnn8yjjz5qrr/+ehMYGGjsdrtp0aJFkXFDXMnJyTFVqlQpcrXJ6tWrzcCBA03Dhg2N3W43vr6+JiIiwvTo0cPpag5jXI/zcfjwYTNgwAATEhJigoKCTIcOHRxXSZ1/BUPhdvj77787zV94ZcD5I6leydUuxvwxImWnTp2M3W43NpvNXH/99U5XsRw5csQ89thjplatWiYoKMi0adPGfPnll8VeSXCx56XwcXjggQdMSEiI8fLychrno/DKrPPvY0lycnLM5MmTzS233GKqVatmfH19Ta1atUyHDh3MzJkzna4EK67GQnPnzjXx8fHG39/f2O12c++997ocqfedd94xDRo0MAEBAaZhw4Zm8eLFJY7zMWHCBMc4Gk2bNr2kgQYLt4Hi/i58Houzfft2xzwXjt1x+vRp88QTT5j4+HhTrVo1ExgYaG688UaTnJzs9LgV1nKp68zOzjajR492jOtTOIZRYmKiWbBggdN4GIXb9IVjExljHON81KtXz/j5+ZkaNWqY3r17Fxnno6CgwEybNs3ExsaagIAA07x5c/PFF1+UOM7Hk08+aWrWrGlsNpu5/fbbzaZNmy56v5YtW2buuusuExYWZnx9fU2VKlVMixYtzOuvv+5yoLrx48ebGjVqlKkB4Sp9+CirinvTL+9KCnBwbdiwYaZBgwZXfaTFwsu4//d///eqrgfWcvUlAJ51sfDpTufOnTO1a9d2uiS4LKi0h12A8mLcuHFasGCBPvzwwyKXc1+u9957T3v37lWjRo3k7e2tDRs26OWXX1ZCQsIl7YoGUD4sXLhQx48f18iRIz1dihPCB1DGhYWFKTU19YrPdzlf1apV9f7772vixIk6ceKEIiIi1L9/f02cONFt6wDgeQUFBUpNTVVISIinS3HiZYyLSyEAAACukkp7qS0AAPAMwgcAALAU4QMAAFiqzJ1wWlBQoH379qlq1aqlGjIbAAB4jjFGx44dU2Rk5EUHKyxz4WPfvn1Ffk0UAACUD3v27LnoyMNlLnwU/gDTnj17LmlocwAA4Hm5ubmKiooq9ocUz1fmwkfhoZZq1aoRPgAAKGcu5ZQJTjgFAACWInwAAABLET4AAIClCB8AAMBShA8AAGApwgcAALAU4QMAAFiK8AEAACxF+AAAAJYifAAAAEsRPgAAgKUIHwAAwFJl7oflAFwdp0+f1u7duz1dRpkSHR2tgIAAT5cBVDqED6CS2L17twYPHuzpMsqUOXPmqF69ep4uA6h0CB9AJREdHa05c+Z4tIZdu3Zp0qRJGjt2rGJiYjxai/THYwLAeoQPoJIICAgoM9/yY2JiykwtAKzHCacAAMBShA8AAGApwgcAALAU4QMAAFiK8AEAACxF+AAAAJYifAAAAEsRPgAAgKUIHwAAwFKEDwAAYCnCBwAAsBThAwAAWIrwAQAALEX4AAAAliJ8AAAASxE+AACApQgfAADAUoQPAABgqVKHj/T0dCUmJioyMlJeXl5KS0tzmn78+HENGzZM1113nQIDA9WgQQPNmjXLXfUCAIByrtTh48SJE2rcuLFmzJjhcvrw4cO1atUqLVy4UNu2bdPw4cP15z//WR999NEVFwsAAMo/39LO0KlTJ3Xq1KnY6RkZGerXr5/atWsnSRo8eLDefPNNbdq0Sffee2+R/nl5ecrLy3Pczs3NLW1JAACgHHH7OR9t2rTRsmXLtHfvXhljtHbtWm3fvl0dO3Z02X/KlCmy2+2Ov6ioKHeXBAAAyhC3h4/XX39dDRs21HXXXSd/f3/dc889SklJUZs2bVz2Hz16tHJychx/e/bscXdJAACgDCn1YZeLef3117VhwwYtW7ZMMTExSk9PV1JSkiIiInTXXXcV6W+z2WSz2dxdBgAAKKPcGj5OnTqlMWPGaOnSperSpYskKT4+Xlu2bNErr7ziMnwAAIDKxa2HXc6ePauzZ8/K29t5sT4+PiooKHDnqgAAQDlV6j0fx48f144dOxy3s7KytGXLFoWGhio6Olpt27bVyJEjFRgYqJiYGK1fv14LFizQq6++6tbCAQBA+VTq8LFp0ya1b9/ecXvEiBGSpH79+mn+/Pl6//33NXr0aPXq1UuHDx9WTEyMJk2apCeeeMJ9VQMAgHKr1OGjXbt2MsYUOz08PFzz5s27oqIAAEDFxW+7AAAASxE+AACApQgfAADAUoQPAABgKcIHAACwFOEDAABYivABAAAsRfgAAACWInwAAABLET4AAIClCB8AAMBShA8AAGApwgcAALAU4QMAAFiK8AEAACzl6+kCgMriwIEDysnJ8XQZHrVr1y6nfys7u92usLAwT5cBWM7LGGM8XcT5cnNzZbfblZOTo2rVqnm6HMAtDhw4oN59+ursmTxPl4IyxM/fpoXvLiCAoEIozec3ez4AC+Tk5OjsmTydim2rggC7p8tBGeB9Okf6bb1ycnIIH6h0CB+AhQoC7CoIruHpMgDAozjhFAAAWIrwAQAALEX4AAAAliJ8AAAASxE+AACApQgfAADAUoQPAABgKcIHAACwFOEDAABYivABAAAsRfgAAACWInwAAABLET4AAIClCB8AAMBShA8AAGApwgcAALCUr6cLwNWRn5+vzMxMHT58WKGhoYqPj5ePj4+nywIAgPBREaWnpyslJUXZ2dmOtvDwcCUlJSkhIcGDlQEAcBmHXdLT05WYmKjIyEh5eXkpLS2tSJ9t27apW7dustvtqlq1qm677Tbt3r3bHfXiItLT05WcnKzY2FjNnDlTK1eu1MyZMxUbG6vk5GSlp6d7ukQAQCVX6vBx4sQJNW7cWDNmzHA5/ddff1WbNm1Uv359rVu3Tt9//73Gjx+vgICAKy4WJcvPz1dKSopatmypiRMnKi4uTkFBQYqLi9PEiRPVsmVLzZo1S/n5+Z4uFQBQiZX6sEunTp3UqVOnYqePHTtWnTt31rRp0xxtsbGxxfbPy8tTXl6e43Zubm5pS8L/l5mZqezsbI0fP17e3s650tvbW7169dLQoUOVmZmppk2beqhKAEBl59arXQoKCrRixQrVq1dPHTt2VK1atXTrrbe6PDRTaMqUKbLb7Y6/qKgod5ZUqRw+fFiSVKdOHZfTC9sL+wEA4AluDR8HDx7U8ePH9dJLL+mee+7RmjVrdN9996lHjx5av369y3lGjx6tnJwcx9+ePXvcWVKlEhoaKknKyspyOb2wvbAfAACe4PY9H5J07733avjw4WrSpImee+45de3aVbNnz3Y5j81mU7Vq1Zz+cHni4+MVHh6u1NRUx3NRqKCgQKmpqYqIiFB8fLyHKgQAwM3ho0aNGvL19VXDhg2d2hs0aMDVLhbw8fFRUlKSMjIyNG7cOG3dulUnT57U1q1bNW7cOGVkZGjIkCGM9wEA8Ci3jvPh7++vW265RT///LNT+/bt2xUTE+POVaEYCQkJmjBhglJSUjR06FBHe0REhCZMmMA4HwAAjyt1+Dh+/Lh27NjhuJ2VlaUtW7YoNDRU0dHRGjlypB5++GElJCSoffv2WrVqlZYvX65169a5s26UICEhQa1bt2aEUwBAmVTq8LFp0ya1b9/ecXvEiBGSpH79+mn+/Pm67777NHv2bE2ZMkVPPvmkbrzxRn344Ydq06aN+6rGRfn4+HA5LQCgTCp1+GjXrp2MMSX2GThwoAYOHHjZRQEAgIqLX7UFAACWInwAAABLET4AAICl3HqpLYCSeZ866ukSUEawLaAyI3wAFgrMSvd0CQDgcYQPwEKn6iSoIDDE02WgDPA+dZQwikqL8AFYqCAwRAXBNTxdBgB4FCecAgAASxE+AACApQgfAADAUoQPAABgKcIHAACwFOEDAABYivABAAAsRfgAAACWInwAAABLET4AAIClCB8AAMBShA8AAGApwgcAALAU4QMAAFiK8AEAACxF+AAAAJYifAAAAEsRPgAAgKUIHwAAwFKEDwAAYCnCBwAAsBThAwAAWIrwAQAALEX4AAAAliJ8AAAASxE+AACApQgfAADAUoQPAABgKcIHAACwFOEDAABYqtThIz09XYmJiYqMjJSXl5fS0tKK7fv444/Ly8tL06dPv4ISAQBARVLq8HHixAk1btxYM2bMKLFfWlqavvnmG0VGRl52cQAAoOLxLe0MnTp1UqdOnUrss3fvXg0bNkyrV69Wly5dSuybl5envLw8x+3c3NzSlgQAKKdOnz6t3bt3e7qMMiM6OloBAQGeLuOqK3X4uJiCggL16dNHI0eOVFxc3EX7T5kyRRMmTHB3GQCAcmD37t0aPHiwp8soM+bMmaN69ep5uoyrzu3hY+rUqfL19dWTTz55Sf1Hjx6tESNGOG7n5uYqKirK3WUBAMqg6OhozZkzx6M17Nq1S5MmTdLYsWMVExPj0Vqio6M9un6ruDV8fPvtt3rttde0efNmeXl5XdI8NptNNpvNnWUAAMqJgICAMvNNPyYmpszUUtG59VLbL7/8UgcPHlR0dLR8fX3l6+urXbt26ZlnnlHt2rXduSoAAFBOuXXPR58+fXTXXXc5tXXs2FF9+vTRgAED3LkqAABQTpU6fBw/flw7duxw3M7KytKWLVsUGhqq6OhoVa9e3am/n5+fwsPDdeONN155tQAAoNwrdfjYtGmT2rdv77hdeLJov379NH/+fLcVBgAAKqZSh4927drJGHPJ/Xfu3FnaVQAAgAqM33YBAACWInwAAABLET4AAIClCB8AAMBShA8AAGApwgcAALAU4QMAAFiK8AEAACxF+AAAAJYifAAAAEsRPgAAgKVK/dsuKB/y8/OVmZmpw4cPKzQ0VPHx8fLx8fF0WQAAED4qovT0dKWkpCg7O9vRFh4erqSkJCUkJHiwMgAAOOxS4aSnpys5OVmxsbGaOXOmVq5cqZkzZyo2NlbJyclKT0/3dIkAgEqO8FGB5OfnKyUlRS1bttTEiRMVFxenoKAgxcXFaeLEiWrZsqVmzZql/Px8T5cKAKjECB8VSGZmprKzs9WrVy95ezs/td7e3urVq5f279+vzMxMD1UIAADho0I5fPiwJKlOnToupxe2F/YDAMATCB8VSGhoqCQpKyvL5fTC9sJ+AAB4AuGjAomPj1d4eLhSU1NVUFDgNK2goECpqamKiIhQfHy8hyoEAIDwUaH4+PgoKSlJGRkZGjdunLZu3aqTJ09q69atGjdunDIyMjRkyBDG+wAAeBTjfFQwCQkJmjBhglJSUjR06FBHe0REhCZMmMA4HwAAjyN8VEAJCQlq3bo1I5wCAMokwkcF5ePjo6ZNm3q6DAAAiuCcDwAAYCnCBwAAsBThAwAAWIrwAQAALEX4AAAAliJ8AAAASxE+AACApQgfAADAUoQPAABgKcIHAACwFOEDAABYivABAAAsRfgAAACWInwAAABLlTp8pKenKzExUZGRkfLy8lJaWppj2tmzZzVq1Cg1atRIwcHBioyMVN++fbVv3z531gwAAMqxUoePEydOqHHjxpoxY0aRaSdPntTmzZs1fvx4bd68WUuWLNH27dvVrVs3txQLAADKP9/SztCpUyd16tTJ5TS73a5PP/3Uqe2NN95QixYttHv3bkVHRxeZJy8vT3l5eY7bubm5pS0JAACUI1f9nI+cnBx5eXkpJCTE5fQpU6bIbrc7/qKioq52SQAAwIOuavg4ffq0nnvuOfXs2VPVqlVz2Wf06NHKyclx/O3Zs+dqlgQAADys1IddLtXZs2f1yCOPqKCgQCkpKcX2s9lsstlsV6sMAABQxlyV8HH27Fk99NBDysrK0hdffFHsXg8AAFD5uD18FAaPX375RWvXrlX16tXdvQoAAFCOlTp8HD9+XDt27HDczsrK0pYtWxQaGqrIyEg98MAD2rx5sz7++GPl5+crOztbkhQaGip/f3/3VQ4AAMqlUoePTZs2qX379o7bI0aMkCT169dPL7zwgpYtWyZJatKkidN8a9euVbt27S6/UgAAUCGUOny0a9dOxphip5c0DQAAgN92AQAAliJ8AAAASxE+AACApQgfAADAUoQPAABgKcIHAACwFOEDAABYivABAAAsRfgAAACWInwAAABLET4AAIClCB8AAMBShA8AAGApwgcAALAU4QMAAFjK19MFAJWJ9+kcT5eAMoJtAZUZ4QOwgN1ul5+/TfptvadLQRni52+T3W73dBmA5QgfgAXCwsK08N0Fysmp3N92d+3apUmTJmns2LGKiYnxdDkeZ7fbFRYW5ukyAMsRPgCLhIWF8UHz/8XExKhevXqeLgOAh3DCKQAAsBThAwAAWIrwAQAALEX4AAAAliJ8AAAASxE+AACApQgfAADAUoQPAABgKQYZA4BK7MCBA4y8u2uX07+VmVWj7hI+AKCSOnDggHr36auzZ/I8XUqZMGnSJE+X4HF+/jYtfHfBVQ8ghA8AqKRycnJ09kyeTsW2VUEAP3BX2XmfzpF+W6+cnBzCBwDg6ioIsKsguIany0AlwgmnAADAUoQPAABgKcIHAACwFOEDAABYivABAAAsRfgAAACWKnX4SE9PV2JioiIjI+Xl5aW0tDSn6cYYvfDCC4qMjFRgYKDatWunrVu3uqteAABQzpU6fJw4cUKNGzfWjBkzXE6fNm2aXn31Vc2YMUMbN25UeHi4OnTooGPHjl1xsQAAoPwr9SBjnTp1UqdOnVxOM8Zo+vTpGjt2rHr06CFJeueddxQWFqZFixbp8ccfLzJPXl6e8vL+O7Rvbm5uaUtyydO/V5CXl6fs7GyPrb+sCQ8Pl81m89j6rfq9AgDAxbl1hNOsrCxlZ2fr7rvvdrTZbDa1bdtWX3/9tcvwMWXKFE2YMMGdZfB7BSjCqt8rAABcnFvDR+E3/Qvf4MPCwor9tcDRo0drxIgRjtu5ubmKioq6ojrKxO8VFJyTd95xz6y7DCqwVZG8PTOav5W/VwAAuLir8mng5eXldNsYU6StkM1mu2q74z39ewUFVT22agAAyiy3XmobHh4uSUXOdTh48CDfOAEAgCQ3h486deooPDxcn376qaPtzJkzWr9+vVq1auXOVQEAgHKq1Iddjh8/rh07djhuZ2VlacuWLQoNDVV0dLSefvppTZ48WTfccINuuOEGTZ48WUFBQerZs6dbCwcAAOVTqcPHpk2b1L59e8ftwpNF+/Xrp/nz5+vZZ5/VqVOnlJSUpCNHjujWW2/VmjVrVLUqJ0AAAIDLCB/t2rWTMabY6V5eXnrhhRf0wgsvXEldAACgguK3XQAAgKUIHwAAwFKEDwAAYCnPDDlpEe9TRz1dAsoAtgMAKFsqdPgIzEr3dAkAAOACFTp8nKqToILAEE+XAQ/zPnWUIAoAZUiFDh8FgSEe/W0XAABQFCecAgAASxE+AACApQgfAADAUoQPAABgKcIHAACwFOEDAABYivABAAAsRfgAAACWqtCDjHmfzvHcygvOyTvvuOfWX8YU2KpI3p7Z3Dy6HQAAiqiQ4cNut8vP3yb9tt7TpaCM8PO3yW63e7oMAIAqaPgICwvTwncXKCfHc9948/LylJ2d7bH1lzXh4eGy2WweW7/dbldYWJjH1g8A+K8KGT6kPwKIpz9sGjVq5NH1AwBQFnHCKQAAsBThAwAAWIrwAQAALEX4AAAAliJ8AAAASxE+AACApQgfAADAUoQPAABgqQo7yBgA4NJ4nzrq6RJQBli5HRA+AKCSC8xK93QJqGQIHwBQyZ2qk6CCwBBPlwEP8z511LIgSvgAgEquIDBEBcE1PF0GKhFOOAUAAJYifAAAAEsRPgAAgKUIHwAAwFKEDwAAYCnCBwAAsJTbw8e5c+c0btw41alTR4GBgYqNjdWLL76ogoICd68KAACUQ24f52Pq1KmaPXu23nnnHcXFxWnTpk0aMGCA7Ha7nnrqKXevDgAAlDNuDx8ZGRm699571aVLF0lS7dq19d5772nTpk0u++fl5SkvL89xOzc3190lAQBK4H06x9MloAywcjtwe/ho06aNZs+ere3bt6tevXr6/vvv9dVXX2n69Oku+0+ZMkUTJkxwdxkAgIuw2+3y87dJv633dCkoI/z8bbLb7Vd9PW4PH6NGjVJOTo7q168vHx8f5efna9KkSXr00Udd9h89erRGjBjhuJ2bm6uoqCh3lwUAuEBYWJgWvrtAOTmVe8/Hrl27NGnSJI0dO1YxMTGeLsej7Ha7wsLCrvp63B4+Fi9erIULF2rRokWKi4vTli1b9PTTTysyMlL9+vUr0t9ms8lms7m7DADAJQgLC7Pkw6Y8iImJUb169TxdRqXg9vAxcuRIPffcc3rkkUckSY0aNdKuXbs0ZcoUl+EDAABULm6/1PbkyZPy9nZerI+PD5faAgAASVdhz0diYqImTZqk6OhoxcXF6bvvvtOrr76qgQMHuntVAACgHHJ7+HjjjTc0fvx4JSUl6eDBg4qMjNTjjz+u559/3t2rAgAA5ZDbw0fVqlU1ffr0Yi+tBQAAlRu/7QIAACxF+AAAAJYifAAAAEsRPgAAgKUIHwAAwFKEDwAAYCnCBwAAsBThAwAAWIrwAQAALEX4AAAAliJ8AAAAS7n9t11QNuTn5yszM1OHDx9WaGio4uPj5ePj4+myAAAgfFRE6enpSklJUXZ2tqMtPDxcSUlJSkhI8GBlAABw2KXCSU9PV3JysmJjYzVz5kytXLlSM2fOVGxsrJKTk5Wenu7pEgEAlRzhowLJz89XSkqKWrZsqYkTJyouLk5BQUGKi4vTxIkT1bJlS82aNUv5+fmeLhUAUIkRPiqQzMxMZWdnq1evXvL2dn5qvb291atXL+3fv1+ZmZkeqhAAAMJHhXL48GFJUp06dVxOL2wv7AcAgCcQPiqQ0NBQSVJWVpbL6YXthf0AAPAEwkcFEh8fr/DwcKWmpqqgoMBpWkFBgVJTUxUREaH4+HgPVQgAAOGjQvHx8VFSUpIyMjI0btw4bd26VSdPntTWrVs1btw4ZWRkaMiQIYz3AQDwKMb5qGASEhI0YcIEpaSkaOjQoY72iIgITZgwgXE+AAAeR/iogBISEtS6dWtGOAUAlEmEjwrKx8dHTZs29XQZAAAUwTkfAADAUoQPAABgKcIHAACwFOEDAABYivABAAAsRfgAAACWInwAAABLET4AAIClCB8AAMBShA8AAGApwgcAALAU4QMAAFiK8AEAACxF+AAAAJa6KuFj79696t27t6pXr66goCA1adJE33777dVYFQAAKGd83b3AI0eOqHXr1mrfvr0++eQT1apVS7/++qtCQkLcvSoAAFAOuT18TJ06VVFRUZo3b56jrXbt2sX2z8vLU15enuN2bm6uu0sCIOn06dPavXu3R2vYtWuX07+eFh0drYCAAE+XAVQ6bg8fy5YtU8eOHfXggw9q/fr1uvbaa5WUlKRBgwa57D9lyhRNmDDB3WUAuMDu3bs1ePBgT5chSZo0aZKnS5AkzZkzR/Xq1fN0GUCl42WMMe5cYOG3iBEjRujBBx/Uv/71Lz399NN688031bdv3yL9Xe35iIqKUk5OjqpVq+bO0oBKrSzs+Shr2PMBSdq+fbsGDx5MGL1Cubm5stvtl/T57fY9HwUFBWrevLkmT54sSWratKm2bt2qWbNmuQwfNptNNpvN3WUAuEBAQABvrADKBLdf7RIREaGGDRs6tTVo0IBvXAAAQNJVCB+tW7fWzz//7NS2fft2xcTEuHtVAACgHHJ7+Bg+fLg2bNigyZMna8eOHVq0aJHmzJmjoUOHuntVAACgHHJ7+Ljlllu0dOlSvffee7rpppv0l7/8RdOnT1evXr3cvSoAAFAOuf2EU0nq2rWrunbtejUWDQAAyjl+2wUAAFiK8AEAACxF+AAAAJYifAAAAEsRPgAAgKUIHwAAwFKEDwAAYCnCBwAAsBThAwAAWIrwAQAALEX4AAAAlroqv+0Cz8vPz1dmZqYOHz6s0NBQxcfHy8fHx9NlAQBA+KiI0tPTlZKSouzsbEdbeHi4kpKSlJCQ4MHKAADgsEuFk56eruTkZMXGxmrmzJlauXKlZs6cqdjYWCUnJys9Pd3TJQIAKjnCRwWSn5+vlJQUtWzZUhMnTlRcXJyCgoIUFxeniRMnqmXLlpo1a5by8/M9XSoAoBLjsEsFkpmZqezsbI0fP17e3s650tvbW7169dLQoUOVmZmppk2beqhKAPiv06dPa/fu3R6tYdeuXU7/elJ0dLQCAgI8XcZVR/ioQA4fPixJqlOnjsvphe2F/QDA03bv3q3Bgwd7ugxJ0qRJkzxdgubMmaN69ep5uoyrjvBRgYSGhkqSsrKyFBcXV2R6VlaWUz8A8LTo6GjNmTPH02WUGdHR0Z4uwRKEjwokPj5e4eHhSk1N1cSJE50OvRQUFCg1NVURERGKj4/3YJUA8F8BAQGV4ps+nHHCaQXi4+OjpKQkZWRkaNy4cdq6datOnjyprVu3aty4ccrIyNCQIUMY7wMA4FFexhjj6SLOl5ubK7vdrpycHFWrVs3T5ZRLrsb5iIiI0JAhQxjnAwBwVZTm85vwUUExwikAwEql+fzmnI8KysfHh8tpAQBlEud8AAAASxE+AACApQgfAADAUoQPAABgKcIHAACwFOEDAABYivABAAAsRfgAAACWInwAAABLlbkRTgtHe8/NzfVwJQAA4FIVfm5fyq+2lLnwcezYMUlSVFSUhysBAACldezYMdnt9hL7lLkflisoKNC+fftUtWpVeXl5ebqcci03N1dRUVHas2cPP9KHMoFtEmUR26V7GGN07NgxRUZGytu75LM6ytyeD29vb1133XWeLqNCqVatGi8olClskyiL2C6v3MX2eBTihFMAAGApwgcAALAU4aMCs9lsSk5Ols1m83QpgCS2SZRNbJfWK3MnnAIAgIqNPR8AAMBShA8AAGApwgcAALAU4QMAAFiK8AEAACxF+CgDsrOz9dRTT6lu3boKCAhQWFiY2rRpo9mzZ+vkyZOeLk+nT59W//791ahRI/n6+qp79+6eLgkWKOvb5bp163TvvfcqIiJCwcHBatKkiVJTUz1dFq6isr5N/vzzz2rfvr3CwsIUEBCg2NhYjRs3TmfPnvV0aWVOmRtevbL57bff1Lp1a4WEhGjy5Mlq1KiRzp07p+3bt+vtt99WZGSkunXrVmS+s2fPys/Pz5Ia8/PzFRgYqCeffFIffvihJeuEZ5WH7fLrr79WfHy8Ro0apbCwMK1YsUJ9+/ZVtWrVlJiYaEkNsE552Cb9/PzUt29fNWvWTCEhIfr+++81aNAgFRQUaPLkyZbUUG4YeFTHjh3NddddZ44fP+5yekFBgTHGGElm1qxZplu3biYoKMg8//zzxhhjUlJSTGxsrPHz8zP16tUzCxYscMyblZVlJJnvvvvO0XbkyBEjyaxdu9YYY8zatWuNJPPxxx+b+Ph4Y7PZTIsWLUxmZqbLevr162fuvffeK7/jKNPK23ZZqHPnzmbAgAFXcM9RVpXXbXL48OGmTZs2V3DPKyYOu3jQoUOHtGbNGg0dOlTBwcEu+5z/y77Jycm699579e9//1sDBw7U0qVL9dRTT+mZZ57RDz/8oMcff1wDBgzQ2rVrS13LyJEj9corr2jjxo2qVauWunXrxq7CSqo8b5c5OTkKDQ0t9XpQtpXXbXLHjh1atWqV2rZtW+r1VHieTj+V2YYNG4wks2TJEqf26tWrm+DgYBMcHGyeffZZY8wfaf7pp5926teqVSszaNAgp7YHH3zQdO7c2RhTujT//vvvO/ocOnTIBAYGmsWLFxepmT0fFV953C6NMeYf//iH8ff3Nz/88MNl3W+UXeVtm2zZsqWx2WxGkhk8eLDJz8+/ovtfEbHnoww4P7FL0r/+9S9t2bJFcXFxysvLc7Q3b97cqd+2bdvUunVrp7bWrVtr27Ztpa6hZcuWjv+HhobqxhtvvKzloOIoT9vlunXr1L9/f7311luKi4sr9XpQPpSXbXLx4sXavHmzFi1apBUrVuiVV14p9XoqOk449aC6devKy8tLP/30k1N7bGysJCkwMNCp3dXuxgtfjMYYR5u3t7ejrVBpDqVcuGxUDuVtu1y/fr0SExP16quvqm/fvpe8HJQf5W2bjIqKkiQ1bNhQ+fn5Gjx4sJ555hn5+Phc8jIrOvZ8eFD16tXVoUMHzZgxQydOnCj1/A0aNNBXX33l1Pb111+rQYMGkqSaNWtKkvbv3++YvmXLFpfL2rBhg+P/R44c0fbt21W/fv1S14Tyrzxtl+vWrVOXLl300ksvafDgwaWuFeVDedomL2SM0dmzZ52CDdjz4XEpKSlq3bq1mjdvrhdeeEHx8fHy9vbWxo0b9dNPP+nmm28udt6RI0fqoYceUrNmzXTnnXdq+fLlWrJkiT777DNJf3wbuO222/TSSy+pdu3a+r//+z+NGzfO5bJefPFFVa9eXWFhYRo7dqxq1KjhNJ7Hjz/+qDNnzujw4cM6duyY44XZpEkTdz0UKEPKw3ZZGDyeeuop3X///crOzpYk+fv7c9JpBVQetsnU1FT5+fmpUaNGstls+vbbbzV69Gg9/PDD8vXl49aJ5043QaF9+/aZYcOGmTp16hg/Pz9TpUoV06JFC/Pyyy+bEydOGGP+OIlq6dKlReYt6fIxY4z58ccfzW233WYCAwNNkyZNzJo1a1yeRLV8+XITFxdn/P39zS233GK2bNnitJyYmBgjqcgfKq6yvl3269fP5TbZtm3bq/WQwMPK+jb5/vvvm2bNmpkqVaqY4OBg07BhQzN58mRz6tSpq/aYlFdexrAvqDJbt26d2rdvryNHjigkJMTT5QCS2C5R9rBNuhfnfAAAAEsRPgAAgKU47AIAACzFng8AAGApwgcAALAU4QMAAFiK8AEAACxF+AAAAJYifAAAAEsRPgAAgKUIHwAAwFL/D6RFJ45mMK/iAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Example data\n",
    "groups = ['Group1']*10 + ['Group2']*10 + ['Group3']*10\n",
    "values = group_A + group_B + group_C  # Replace with your actual data\n",
    "\n",
    "# Boxplot\n",
    "sns.boxplot(x=groups, y=values)\n",
    "plt.title(\"Group Comparisons (Significant: Group 2 vs. Group 3)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a36f19-7513-4bf0-9f79-c2b2f980b965",
   "metadata": {},
   "source": [
    "#### The `Conover-Iman` test is a non-parametric post-hoc procedure used for multiple pairwise comparisons following the rejection of a Kruskal-Wallis test. It's particularly useful when the assumption of equal variances is violated, as it doesn't require homogeneity of variances. This test evaluates whether there are significant differences between group medians by analyzing the ranks of the data.\n",
    "\n",
    "    - Key Features of the Conover-Iman Test:\n",
    "        - Non-Parametric Nature: Does not assume normality of the data, making it suitable for ordinal data or data that doesn't meet parametric test assumptions.\n",
    "        - Pairwise Comparisons: Conducts multiple pairwise comparisons to identify which specific groups differ after a significant Kruskal-Wallis test result.\n",
    "        - Flexibility with Variances: Appropriate for data with unequal variances, addressing scenarios where homogeneity of variances cannot be assumed.\n",
    "\n",
    "    - Considerations:\n",
    "        - Prerequisite Kruskal-Wallis Test: The Conover-Iman test should be conducted only if the Kruskal-Wallis test indicates significant differences among groups.\n",
    "        - Multiple Testing Correction: Applying adjustments like Holm's method helps control the family-wise error rate during multiple comparisons.\n",
    "        - Assumption of Continuous Distributions: The test assumes that the distributions are continuous and that any differences are due to shifts in central tendency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ecc144c-a6c1-4c9a-9145-d4236d59b9f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          A         B         C\n",
      "A  1.000000  0.003023  0.519491\n",
      "B  0.003023  1.000000  0.006655\n",
      "C  0.519491  0.006655  1.000000\n"
     ]
    }
   ],
   "source": [
    "import scikit_posthocs as sp\n",
    "import pandas as pd\n",
    "\n",
    "# Sample data\n",
    "data = pd.DataFrame({\n",
    "    'values': [7, 8, 5, 6, 9, 4, 3, 5, 4, 2, 6, 7, 8, 5, 6],\n",
    "    'groups': ['A', 'A', 'A', 'A', 'A', \n",
    "               'B', 'B', 'B', 'B', 'B',\n",
    "               'C', 'C', 'C', 'C', 'C']\n",
    "})\n",
    "\n",
    "# Perform Conover-Iman test\n",
    "p_values = sp.posthoc_conover(data, val_col='values', group_col='groups', p_adjust='holm')\n",
    "print(p_values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f8715d-bfad-4203-ac8c-649b195931b1",
   "metadata": {},
   "source": [
    "#### Explanation:\n",
    "- Data Structure: The data DataFrame contains two columns: values (the observations) and groups (the group labels). In this example, there are three groups labeled 'A', 'B', and 'C', each with five observations.\n",
    "- Function Usage: The posthoc_conover function from the scikit-posthocs library is used to perform the Conover-Iman test. The parameters val_col and group_col specify the columns containing the data values and group labels, respectively.\n",
    "- p-value Adjustment: The p_adjust='holm' parameter applies Holm's correction to adjust for multiple comparisons, controlling the family-wise error rate.\n",
    "- In this matrix, the diagonal elements are set to -1.000000 (or sometimes NaN) as they represent self-comparisons. The off-diagonal elements show the adjusted p-values for the pairwise comparisons between groups.​\n",
    "- Notes:\n",
    "    - Prerequisite Test: It's important to conduct a Kruskal-Wallis test before performing the Conover-Iman test to determine if there are overall differences among group medians. If the Kruskal-Wallis test is significant, the Conover-Iman test can help identify which specific groups differ.​\n",
    "    - Data Requirements: Ensure that the data meets the assumptions of the Conover-Iman test, particularly that the data is at least ordinal and that the groups are independent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c11189-8113-4d6b-97e8-b2f4ae8335e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0538b9db-9bd0-4c7b-9a8d-4792346e9954",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e6ba5051-deba-4224-860d-008d10adbba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "u_stat 434.0\n",
      "p_u 0.004808662736744625\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import ttest_ind, mannwhitneyu  \n",
    "import numpy as np\n",
    "\n",
    "# Large sample data  \n",
    "group_A = np.random.normal(50, 10, 40)  \n",
    "group_B = np.random.normal(55, 10, 35)  \n",
    "\n",
    "# Parametric  \n",
    "t_stat, p_t = ttest_ind(group_A, group_B)  \n",
    "\n",
    "# Nonparametric (if needed)  \n",
    "u_stat, p_u = mannwhitneyu(group_A, group_B)  \n",
    "\n",
    "print(\"u_stat\", u_stat)\n",
    "print(\"p_u\", p_u)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbcf8dd1-a327-4184-a53e-e373a477f73f",
   "metadata": {},
   "source": [
    "The values you provided (u_stat = 434.0, p_u = 0.0048) appear to be results from a Mann-Whitney U test (a non-parametric test comparing two independent groups). Here's how to interpret and contextualize these results:\n",
    "\n",
    "Interpretation\n",
    "U Statistic (434.0)\n",
    "\n",
    "The Mann-Whitney U statistic quantifies the degree of separation between two groups.\n",
    "\n",
    "A larger U value suggests greater overlap between groups (if group sizes are unequal, interpret with caution).\n",
    "\n",
    "Compare this to the critical U value for your sample sizes (use a U-table or statistical software).\n",
    "\n",
    "P-Value (0.0048)\n",
    "\n",
    "The p-value is statistically significant at common thresholds (e.g., α = 0.05).\n",
    "\n",
    "This indicates strong evidence against the null hypothesis, suggesting the distributions of the two groups differ significantly.\n",
    "\n",
    "Key Considerations\n",
    "Null Hypothesis\n",
    "\n",
    "H₀: The two groups are drawn from the same population (no difference in distributions).\n",
    "\n",
    "H₁: The two groups are not drawn from the same population.\n",
    "\n",
    "Effect Size\n",
    "\n",
    "While the p-value indicates significance, calculate the effect size (e.g., rank-biserial correlation or Cohen’s d) to quantify practical importance:\n",
    "\n",
    "Next Steps\n",
    "Report Results\n",
    "\n",
    "Format: U = 434.0, p = 0.0048 (or p < 0.01).\n",
    "\n",
    "Specify the test (e.g., \"Mann-Whitney U test\") and significance threshold (e.g., α = 0.05).\n",
    "\n",
    "Visualize Data\n",
    "\n",
    "Use boxplots, violin plots, or ECDFs to illustrate group differences.\n",
    "\n",
    "python\n",
    "import seaborn as sns  \n",
    "sns.boxplot(x='Group', y='Variable', data=df)  \n",
    "Post-Hoc Analysis\n",
    "\n",
    "If working with multiple comparisons, apply corrections (e.g., Bonferroni).\n",
    "\n",
    "Consider confidence intervals for the median difference.\n",
    "\n",
    "Alternative Tests\n",
    "\n",
    "If assumptions are violated, consider:\n",
    "\n",
    "Welch’s t-test (for normally distributed data with unequal variances)\n",
    "\n",
    "Kolmogorov-Smirnov test (for comparing distributions)\n",
    "\n",
    "Example Conclusion\n",
    "\"The Mann-Whitney U test revealed a statistically significant difference between groups (U = 434.0, p = 0.0048). We reject the null hypothesis and conclude that the distributions of [variable] differ significantly between [Group A] and [Group B].\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7388f649-a64c-458e-a63b-0d16e5a6df12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.38\n"
     ]
    }
   ],
   "source": [
    "import numpy as np  \n",
    "effect_size = 1 - (2 * u_stat) / (len(group_A) * len(group_B))  # Rank-biserial correlation  \n",
    "print(effect_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988f39bd-ccfa-4d95-991a-3eea7a73cc09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import spearmanr, kendalltau\n",
    "\n",
    "# Spearman's correlation\n",
    "spearman_corr, spearman_p = spearmanr(df['feature1'], df['feature2'])\n",
    "print(f\"Spearman's correlation: {spearman_corr}, p-value: {spearman_p}\")\n",
    "\n",
    "# Kendall's tau\n",
    "kendall_corr, kendall_p = kendalltau(df['feature1'], df['feature2'])\n",
    "print(f\"Kendall's tau: {kendall_corr}, p-value: {kendall_p}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a26c9741-1ad9-4de2-8d60-0260ebd0fa13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kendall’s Tau: 0.200, p-value: 0.8167\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import kendalltau  \n",
    "\n",
    "x = [1, 2, 3, 4, 5]  \n",
    "y = [3, 4, 1, 2, 5]  \n",
    "tau, p_value = kendalltau(x, y)  \n",
    "\n",
    "print(f\"Kendall’s Tau: {tau:.3f}, p-value: {p_value:.4f}\")  \n",
    "# Output: Kendall’s Tau: 0.200, p-value: 0.5647  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e502363-cb1c-4b46-914d-186405233719",
   "metadata": {},
   "outputs": [],
   "source": [
    "Effect Size (τ = 0.200)\n",
    "\n",
    "Indicates a weak positive monotonic relationship between the variables.\n",
    "\n",
    "The direction is positive (as one variable increases, the other tends to increase), but the strength is minimal.\n",
    "\n",
    "Statistical Significance (p = 0.8167)\n",
    "\n",
    "The p-value is not statistically significant at common thresholds (e.g., α = 0.05 or 0.10).\n",
    "\n",
    "This means we fail to reject the null hypothesis—there is no strong evidence of a monotonic relationship.\n",
    "\n",
    "Practical Implications\n",
    "The weak association (τ = 0.2) is likely due to random chance rather than a true relationship.\n",
    "\n",
    "Even if a slight trend exists in your data, it is not statistically distinguishable from noise.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bff5c873-51b2-43f2-a0c3-e47aa2769627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman correlation: 0.9999999999999999, p-value: 1.4042654220543672e-24\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import spearmanr\n",
    "\n",
    "x = [1, 2, 3, 4, 5]\n",
    "y = [2, 4, 6, 7, 8]\n",
    "corr, p_value = spearmanr(x, y)\n",
    "print(f\"Spearman correlation: {corr}, p-value: {p_value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9fea53-cdb3-4872-9984-24b6ad6581a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "67bdb9b5-960d-47ea-935e-aeaf0e86bccc",
   "metadata": {},
   "source": [
    "#### Nonlinear Regression\n",
    "- Understanding the Basics of Nonlinear Regression\n",
    "Nonlinear regression is a statistical method that models the relationship between a dependent variable and one or more independent variables. Unlike linear regression, which assumes a linear relationship between the dependent and independent variables, nonlinear regression allows for more complex relationships that can be modeled using nonlinear functions.\n",
    "\n",
    "- Nonlinear functions can take many forms, such as polynomial, exponential, logarithmic, or trigonometric functions. The choice of function depends on the nature of the data and the research question. In general, the goal of nonlinear regression is to find the best-fit parameters of the chosen function that minimize the sum of the squared errors between the predicted values and the actual values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e1463a-9fd0-4517-99ab-e00531518588",
   "metadata": {},
   "source": [
    "Nonlinear regression is a statistical technique that models the relationship between a dependent variable and one or more independent variables using a nonlinear function. In Python, the scipy.optimize module provides the curve_fit function, which employs non-linear least squares to fit a function to data. ​\n",
    "Medium\n",
    "+2\n",
    "SciPy Documentation\n",
    "+2\n",
    "MolSSI Education\n",
    "+2\n",
    "\n",
    "Implementing Nonlinear Regression in Python:\n",
    "\n",
    "Here's a step-by-step guide to performing nonlinear regression using curve_fit:​\n",
    "\n",
    "Import Necessary Libraries:\n",
    "\n",
    "python\n",
    "Copy\n",
    "Edit\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import curve_fit\n",
    "Define the Nonlinear Function:\n",
    "\n",
    "Specify the model function you aim to fit to your data. For example, a quadratic function:\n",
    "\n",
    "python\n",
    "Copy\n",
    "Edit\n",
    "def quadratic_model(x, a, b, c):\n",
    "    return a * x**2 + b * x + c\n",
    "Prepare Your Data:\n",
    "\n",
    "Assume you have datasets x_data and y_data representing your independent and dependent variables, respectively.\n",
    "\n",
    "Fit the Model to the Data:\n",
    "\n",
    "Use curve_fit to estimate the parameters of your model:\n",
    "\n",
    "python\n",
    "Copy\n",
    "Edit\n",
    "params, covariance = curve_fit(quadratic_model, x_data, y_data)\n",
    "Here, params contains the optimal values for the parameters (a, b, c), and covariance provides the estimated covariance of these parameters.\n",
    "\n",
    "Visualize the Fit:\n",
    "\n",
    "To assess the quality of the fit, plot the original data alongside the fitted curve:\n",
    "\n",
    "python\n",
    "Copy\n",
    "Edit\n",
    "plt.scatter(x_data, y_data, label='Data')\n",
    "plt.plot(x_data, quadratic_model(x_data, *params), color='red', label='Fitted curve')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "Considerations:\n",
    "\n",
    "Initial Parameter Estimates: Providing initial guesses for the parameters can enhance the convergence of the fitting process. This can be done using the p0 argument in curve_fit.​\n",
    "Medium\n",
    "+1\n",
    "SciPy Documentation\n",
    "+1\n",
    "\n",
    "Parameter Bounds: To constrain the parameters within specific ranges, utilize the bounds argument. For example:​\n",
    "\n",
    "python\n",
    "Copy\n",
    "Edit\n",
    "  params, covariance = curve_fit(quadratic_model, x_data, y_data, bounds=([0, 0, 0], [np.inf, np.inf, np.inf]))\n",
    "This constrains all parameters to be non-negative.​\n",
    "\n",
    "Handling Outliers: Outliers can significantly impact the fit. Consider using robust fitting methods or preprocessing your data to mitigate their influence.​\n",
    "\n",
    "For a more comprehensive tutorial on nonlinear regression in Python, you might find this resource helpful\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a44c1862-61f2-47cd-8dbf-822c54833c92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "\n",
    "# Generate sample data\n",
    "np.random.seed(0)\n",
    "x = np.linspace(-5, 5, num=50)\n",
    "y = 2.0 + 1.5 * x + 3.0 * x**2 + np.random.normal(scale=3.0, size=x.shape)\n",
    "\n",
    "\n",
    "# Define the nonlinear function\n",
    "def quadratic_func(x, a, b, c):\n",
    "    return a + b * x + c * x**2\n",
    "\n",
    "\n",
    "# Fit the nonlinear model\n",
    "popt, pcov = curve_fit(quadratic_func, x, y)\n",
    "\n",
    "\n",
    "# Visualize the results\n",
    "plt.scatter(x, y, label='Data')\n",
    "plt.plot(x, quadratic_func(x, *popt), 'r-', label='Fit')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e69f13-9d72-4120-82fc-88c70bac98ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f9498b-f8ae-432d-a0c2-2186e51ff539",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d95b856-f9d0-4a70-a088-742587c2adae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a215c330-a084-4888-8731-9e66cf4fe125",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d497f8b0-d10d-48ef-9b89-c81eb6079d76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "312f27fd-6ec1-403b-be47-95cef095624f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Feature  MI Score\n",
      "0  Feature1  0.200000\n",
      "1  Feature2  0.116667\n",
      "2  Feature3  0.000000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import mutual_info_regression\n",
    "import pandas as pd\n",
    "\n",
    "# Example dataset with multiple features\n",
    "df = pd.DataFrame({\n",
    "    'Feature1': [10, 20, 30, 40, 50],\n",
    "    'Feature2': [5, 3, 2, 4, 1],\n",
    "    'Feature3': [0, 1, 1, 0, 1],\n",
    "    'Target': [100, 200, 300, 400, 500]\n",
    "})\n",
    "\n",
    "# Extract features and target\n",
    "X = df.drop(columns=['Target'])  # Features\n",
    "y = df['Target']  # Target variable\n",
    "\n",
    "# Compute Mutual Information for all features\n",
    "mi_scores = mutual_info_regression(X, y)\n",
    "\n",
    "# Convert to a DataFrame for better visualization\n",
    "mi_df = pd.DataFrame({'Feature': X.columns, 'MI Score': mi_scores})\n",
    "\n",
    "# Sort by importance\n",
    "mi_df = mi_df.sort_values(by=\"MI Score\", ascending=False)\n",
    "\n",
    "print(mi_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "63028415-0b6f-4b08-94aa-149305962b4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mutual Information Score: 0.0188\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import mutual_info_regression\n",
    "\n",
    "mi_score = mutual_info_regression(df_encoded[['Weather']], df_encoded['PlayTennis'])\n",
    "print(f\"Mutual Information Score: {mi_score[0]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87060d6b-8408-473d-ad46-729365ab03d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37d9a49-bde5-45e0-a1ce-71094cccc41f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14b65b2-3385-46b3-bb36-720c06115fc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa73978-4c83-4357-8eeb-e5c52b2a27b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "580bb0af-dd9a-4d87-8870-a5819af3acc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mutual Information (Entropy-Based) Score for Weather: 0.1842\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Sample data\n",
    "df = pd.DataFrame({\n",
    "    'Weather': ['Sunny', 'Sunny', 'Overcast', 'Rainy', 'Rainy', 'Rainy', 'Overcast', 'Sunny'],\n",
    "    'PlayTennis': ['No', 'No', 'Yes', 'Yes', 'Yes', 'No', 'Yes', 'Yes']\n",
    "})\n",
    "\n",
    "# Encode categorical data\n",
    "df_encoded = df.apply(LabelEncoder().fit_transform)\n",
    "\n",
    "# Compute mutual information\n",
    "mi_scores = mutual_info_classif(df_encoded[['Weather']], df_encoded['PlayTennis'], discrete_features=True)\n",
    "\n",
    "# Display result\n",
    "print(f\"Mutual Information (Entropy-Based) Score for Weather: {mi_scores[0]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2624c24b-6c45-41b4-8282-dc03f83fd75b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 0.0808\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import entropy\n",
    "\n",
    "# Sample probabilities (e.g., class distribution)\n",
    "probs = np.array([.99, 0.01])  # Example: 50% \"Yes\", 50% \"No\"\n",
    "\n",
    "# Compute entropy\n",
    "entropy_value = entropy(probs, base=2)\n",
    "print(f\"Entropy: {entropy_value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bed22e2c-6a47-4553-b9bc-19b9f94b4e87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of CPU cores: 16\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "num_workers = os.cpu_count()\n",
    "print(f\"Number of CPU cores: {num_workers}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3505ef31-707b-41d2-96b0-038df67b31a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "xfrom sklearn.inspection import permutation_importance\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming you have X (features) and y (target) datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train your model (e.g., RandomForestClassifier)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Calculate permutation importance\n",
    "result = permutation_importance(\n",
    "    model, X_test, y_test,\n",
    "    n_repeats=10,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Sort features by importance\n",
    "importance = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'importance': result.importances_mean,\n",
    "    'std': result.importances_std\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "# Plot results\n",
    "importance.plot(x='feature', y='importance', kind='bar', yerr='std', figsize=(10, 6))\n",
    "plt.title(\"Permutation Feature Importance\")\n",
    "plt.xlabel(\"Features\")\n",
    "plt.ylabel(\"Mean accuracy decrease\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d16206b-8b0f-4778-829b-30726b725c29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MI Score: 0.0000\n",
      "               SkewedFeature    Target\n",
      "SkewedFeature       1.000000  0.032353\n",
      "Target              0.032353  1.000000\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.feature_selection import mutual_info_regression\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Simulate a skewed distribution (e.g., exponential)\n",
    "np.random.seed(42)\n",
    "df = pd.DataFrame({\n",
    "    'SkewedFeature': np.random.exponential(scale=2, size=1000),\n",
    "    'Target': np.random.uniform(0, 100, 1000)  # Continuous target\n",
    "})\n",
    "\n",
    "# Compute MI\n",
    "mi_score = mutual_info_regression(df[['SkewedFeature']], df['Target'])\n",
    "print(f\"MI Score: {mi_score[0]:.4f}\")\n",
    "print(df.corr())\n",
    "# plot\n",
    "sns.histplot(df['SkewedFeature'], bins=30, kde=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64f725cb-5c9e-4026-bb44-2b6fd62cce78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Feature  MI Score\n",
      "0  Feature1  0.025352\n",
      "2  Feature3  0.014123\n",
      "1  Feature2  0.000000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import mutual_info_regression\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Simulate a dataset with multiple skewed features\n",
    "np.random.seed(42)\n",
    "df = pd.DataFrame({\n",
    "    'Feature1': np.random.exponential(scale=2, size=1000),\n",
    "    'Feature2': np.random.exponential(scale=5, size=1000),\n",
    "    'Feature3': np.random.uniform(0, 50, 1000),\n",
    "    'Target': np.random.uniform(0, 100, 1000)  # Continuous target\n",
    "})\n",
    "\n",
    "# Compute MI for all features\n",
    "mi_scores = mutual_info_regression(df[['Feature1', 'Feature2', 'Feature3']], df['Target'])\n",
    "\n",
    "# Convert to a DataFrame for better readability\n",
    "mi_df = pd.DataFrame({'Feature': ['Feature1', 'Feature2', 'Feature3'], 'MI Score': mi_scores})\n",
    "print(mi_df.sort_values(by='MI Score', ascending=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efedfc5d-8382-4d17-83aa-b5a97dbe8bd5",
   "metadata": {},
   "source": [
    "#### An MI score of 0.0000 suggests that the feature contains no useful information about the target variable. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be95e1a-c6cf-480a-bb0a-bc1f414900c7",
   "metadata": {},
   "source": [
    "#### [Quantile Transformer](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.QuantileTransformer.html)\n",
    "- The `QuantileTransformer` is a non-linear transformation that maps data to a uniform or normal distribution based on quantiles. It helps make data more Gaussian-like and is particularly useful when dealing with skewed or heavy-tailed distributions. Feature independence in the context of the `QuantileTransformer` means that each feature (or column) in your dataset is transformed independently of the others.\n",
    "    - Feature Independence: The `QuantileTransformer` operates independently on each feature, so it doesn't require the features to be on the same scale.\n",
    "    - Outliers: The `QuantileTransformer` is robust to outliers, as it spreads out the most frequent values and reduces the impact of marginal outliers.\n",
    "    - Non-linear Transformation: Since the transformation is non-linear, it may distort linear relationships between variables. If preserving linear relationships is important for your analysis, you might want to consider other scaling methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6b1a98ec-6624-4943-81db-b794e49f125b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>QuantileTransformer(n_quantiles=2000, output_distribution=&#x27;normal&#x27;,\n",
       "                    random_state=1776)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;QuantileTransformer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.preprocessing.QuantileTransformer.html\">?<span>Documentation for QuantileTransformer</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>QuantileTransformer(n_quantiles=2000, output_distribution=&#x27;normal&#x27;,\n",
       "                    random_state=1776)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "QuantileTransformer(n_quantiles=2000, output_distribution='normal',\n",
       "                    random_state=1776)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import library\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "\n",
    "# initialize transformer\n",
    "transformer = QuantileTransformer(output_distribution='normal', n_quantiles=2000, random_state=RANDOM_STATE)\n",
    "\n",
    "# fit the transformer on the training data\n",
    "transformer.fit(train_data[numericCols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0c4f43d6-e5d1-455e-8b7f-ebf43c77e6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform both the training and testing data\n",
    "train_data_transformed = pd.DataFrame(transformer.transform(train_data[numericCols]),columns=numericCols)\n",
    "test_data_transformed = pd.DataFrame(transformer.transform(test_data[numericCols]),columns=numericCols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c1859a-47e4-40e6-a5a4-7f90c62f6a4f",
   "metadata": {},
   "source": [
    "- For the normal distribution (output_distribution='normal'):\n",
    "    - The transformed values approximate a standard normal distribution.\n",
    "    - Extreme values are mapped to the tails of the normal distribution.\n",
    "    - The highest value is typically mapped close to 3 (3 standard deviations above the mean)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "de8b67c4-456f-4890-ac40-f49b6e66d067",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Age_DON</th>\n",
       "      <td>21655.0</td>\n",
       "      <td>-0.001761</td>\n",
       "      <td>0.999583</td>\n",
       "      <td>-5.199338</td>\n",
       "      <td>-0.691511</td>\n",
       "      <td>0.008778</td>\n",
       "      <td>0.677247</td>\n",
       "      <td>5.199338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age_CAN</th>\n",
       "      <td>21655.0</td>\n",
       "      <td>-0.016138</td>\n",
       "      <td>1.075381</td>\n",
       "      <td>-5.199338</td>\n",
       "      <td>-0.684362</td>\n",
       "      <td>-0.025709</td>\n",
       "      <td>0.646804</td>\n",
       "      <td>5.199338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BMI_CAN</th>\n",
       "      <td>21643.0</td>\n",
       "      <td>0.003493</td>\n",
       "      <td>0.999326</td>\n",
       "      <td>-5.199338</td>\n",
       "      <td>-0.670952</td>\n",
       "      <td>0.018183</td>\n",
       "      <td>0.691511</td>\n",
       "      <td>5.199338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BMI_DON</th>\n",
       "      <td>21649.0</td>\n",
       "      <td>0.001690</td>\n",
       "      <td>0.998931</td>\n",
       "      <td>-5.199338</td>\n",
       "      <td>-0.666609</td>\n",
       "      <td>-0.000599</td>\n",
       "      <td>0.678894</td>\n",
       "      <td>5.199338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BloodUreaNitrogenLevel_DON</th>\n",
       "      <td>21614.0</td>\n",
       "      <td>0.000318</td>\n",
       "      <td>1.003988</td>\n",
       "      <td>-5.199338</td>\n",
       "      <td>-0.727804</td>\n",
       "      <td>-0.025709</td>\n",
       "      <td>0.699496</td>\n",
       "      <td>5.199338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WeightKg_DON</th>\n",
       "      <td>21652.0</td>\n",
       "      <td>0.005182</td>\n",
       "      <td>0.999217</td>\n",
       "      <td>-5.199338</td>\n",
       "      <td>-0.659219</td>\n",
       "      <td>-0.000627</td>\n",
       "      <td>0.674883</td>\n",
       "      <td>5.199338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WeightKg_CAN</th>\n",
       "      <td>21649.0</td>\n",
       "      <td>0.004353</td>\n",
       "      <td>0.997399</td>\n",
       "      <td>-5.199338</td>\n",
       "      <td>-0.661559</td>\n",
       "      <td>0.013167</td>\n",
       "      <td>0.672129</td>\n",
       "      <td>5.199338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HeightCm_CAN</th>\n",
       "      <td>21655.0</td>\n",
       "      <td>0.003546</td>\n",
       "      <td>0.995759</td>\n",
       "      <td>-5.199338</td>\n",
       "      <td>-0.602602</td>\n",
       "      <td>-0.004389</td>\n",
       "      <td>0.627601</td>\n",
       "      <td>5.199338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HeightCm_DON</th>\n",
       "      <td>21655.0</td>\n",
       "      <td>0.006364</td>\n",
       "      <td>0.996675</td>\n",
       "      <td>-5.199338</td>\n",
       "      <td>-0.682778</td>\n",
       "      <td>0.020064</td>\n",
       "      <td>0.663901</td>\n",
       "      <td>5.199338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Creatinine_DON</th>\n",
       "      <td>21614.0</td>\n",
       "      <td>-0.001178</td>\n",
       "      <td>0.994696</td>\n",
       "      <td>-5.199338</td>\n",
       "      <td>-0.680623</td>\n",
       "      <td>-0.008151</td>\n",
       "      <td>0.683569</td>\n",
       "      <td>5.199338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CreatinineTransplant_CAN</th>\n",
       "      <td>21613.0</td>\n",
       "      <td>0.011612</td>\n",
       "      <td>1.005554</td>\n",
       "      <td>-5.199338</td>\n",
       "      <td>-0.664683</td>\n",
       "      <td>0.045157</td>\n",
       "      <td>0.694700</td>\n",
       "      <td>5.199338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CreatinineRegistration_CAN</th>\n",
       "      <td>21584.0</td>\n",
       "      <td>0.006908</td>\n",
       "      <td>0.998607</td>\n",
       "      <td>-5.199338</td>\n",
       "      <td>-0.665465</td>\n",
       "      <td>0.065880</td>\n",
       "      <td>0.694700</td>\n",
       "      <td>5.199338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HemodynamicsRegistration_CO_CAN</th>\n",
       "      <td>20419.0</td>\n",
       "      <td>0.001232</td>\n",
       "      <td>0.996742</td>\n",
       "      <td>-5.199338</td>\n",
       "      <td>-0.670167</td>\n",
       "      <td>-0.002508</td>\n",
       "      <td>0.667031</td>\n",
       "      <td>5.199338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HemodynamicsTransplant_CO_CAN</th>\n",
       "      <td>20703.0</td>\n",
       "      <td>-0.000621</td>\n",
       "      <td>1.003086</td>\n",
       "      <td>-5.199338</td>\n",
       "      <td>-0.667031</td>\n",
       "      <td>0.016929</td>\n",
       "      <td>0.664683</td>\n",
       "      <td>5.199338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HemodynamicsRegistration_PA_DIA_CAN</th>\n",
       "      <td>20878.0</td>\n",
       "      <td>-0.000621</td>\n",
       "      <td>1.006716</td>\n",
       "      <td>-5.199338</td>\n",
       "      <td>-0.705112</td>\n",
       "      <td>0.006270</td>\n",
       "      <td>0.684362</td>\n",
       "      <td>5.199338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HemodynamicsTransplant_PA_DIA_CAN</th>\n",
       "      <td>21037.0</td>\n",
       "      <td>-0.003620</td>\n",
       "      <td>1.010983</td>\n",
       "      <td>-5.199338</td>\n",
       "      <td>-0.660778</td>\n",
       "      <td>-0.050806</td>\n",
       "      <td>0.721283</td>\n",
       "      <td>5.199338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HemodynamicsRegistration_PA_MN_CAN</th>\n",
       "      <td>20672.0</td>\n",
       "      <td>-0.004510</td>\n",
       "      <td>1.012421</td>\n",
       "      <td>-5.199338</td>\n",
       "      <td>-0.676459</td>\n",
       "      <td>-0.003135</td>\n",
       "      <td>0.709138</td>\n",
       "      <td>5.199338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HemodynamicsTransplant_PA_MN_CAN</th>\n",
       "      <td>20851.0</td>\n",
       "      <td>0.000121</td>\n",
       "      <td>1.005640</td>\n",
       "      <td>-5.199338</td>\n",
       "      <td>-0.632954</td>\n",
       "      <td>-0.008151</td>\n",
       "      <td>0.700297</td>\n",
       "      <td>5.199338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HemodynamicsRegistration_PCW_CAN</th>\n",
       "      <td>19608.0</td>\n",
       "      <td>-0.006309</td>\n",
       "      <td>1.014648</td>\n",
       "      <td>-5.199338</td>\n",
       "      <td>-0.724540</td>\n",
       "      <td>0.023200</td>\n",
       "      <td>0.664683</td>\n",
       "      <td>5.199338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HemodynamicsTransplant_PCW_CAN</th>\n",
       "      <td>20062.0</td>\n",
       "      <td>-0.002902</td>\n",
       "      <td>1.020051</td>\n",
       "      <td>-5.199338</td>\n",
       "      <td>-0.693104</td>\n",
       "      <td>-0.009405</td>\n",
       "      <td>0.692307</td>\n",
       "      <td>5.199338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HemodynamicsRegistration_SYS_CAN</th>\n",
       "      <td>20892.0</td>\n",
       "      <td>-0.001954</td>\n",
       "      <td>1.005047</td>\n",
       "      <td>-5.199338</td>\n",
       "      <td>-0.709138</td>\n",
       "      <td>0.014421</td>\n",
       "      <td>0.697895</td>\n",
       "      <td>5.199338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HemodynamicsTransplant_SYS_CAN</th>\n",
       "      <td>21050.0</td>\n",
       "      <td>-0.002395</td>\n",
       "      <td>1.004684</td>\n",
       "      <td>-5.199338</td>\n",
       "      <td>-0.636789</td>\n",
       "      <td>-0.014421</td>\n",
       "      <td>0.674883</td>\n",
       "      <td>5.199338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TotalDayWaitList_CAN</th>\n",
       "      <td>21655.0</td>\n",
       "      <td>-0.004573</td>\n",
       "      <td>1.007080</td>\n",
       "      <td>-5.199338</td>\n",
       "      <td>-0.689124</td>\n",
       "      <td>-0.003762</td>\n",
       "      <td>0.668598</td>\n",
       "      <td>5.199338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TotalBilirubinTransplant_CAN</th>\n",
       "      <td>21582.0</td>\n",
       "      <td>0.000653</td>\n",
       "      <td>1.034729</td>\n",
       "      <td>-5.199338</td>\n",
       "      <td>-0.542036</td>\n",
       "      <td>0.021319</td>\n",
       "      <td>0.721283</td>\n",
       "      <td>5.199338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TerminalTotalBilirubin_DON</th>\n",
       "      <td>21612.0</td>\n",
       "      <td>-0.019785</td>\n",
       "      <td>0.982660</td>\n",
       "      <td>-5.199338</td>\n",
       "      <td>-0.575753</td>\n",
       "      <td>-0.040764</td>\n",
       "      <td>0.604859</td>\n",
       "      <td>5.199338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OrganRecovery_PCO2_DON</th>\n",
       "      <td>21587.0</td>\n",
       "      <td>-0.010585</td>\n",
       "      <td>1.002689</td>\n",
       "      <td>-5.199338</td>\n",
       "      <td>-0.713983</td>\n",
       "      <td>-0.005643</td>\n",
       "      <td>0.670952</td>\n",
       "      <td>5.199338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Level_SGOT_AST_DON</th>\n",
       "      <td>21611.0</td>\n",
       "      <td>-0.005945</td>\n",
       "      <td>1.003753</td>\n",
       "      <td>-5.199338</td>\n",
       "      <td>-0.676459</td>\n",
       "      <td>-0.023827</td>\n",
       "      <td>0.671737</td>\n",
       "      <td>5.199338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Level_SGOT_ALT_DON</th>\n",
       "      <td>21611.0</td>\n",
       "      <td>-0.003651</td>\n",
       "      <td>1.004851</td>\n",
       "      <td>-5.199338</td>\n",
       "      <td>-0.703505</td>\n",
       "      <td>-0.019437</td>\n",
       "      <td>0.685947</td>\n",
       "      <td>5.199338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DistanceFromDonorHospitaltoTXCenter</th>\n",
       "      <td>21655.0</td>\n",
       "      <td>-0.237124</td>\n",
       "      <td>1.631753</td>\n",
       "      <td>-5.199338</td>\n",
       "      <td>-0.659219</td>\n",
       "      <td>0.008778</td>\n",
       "      <td>0.670952</td>\n",
       "      <td>5.199338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hematocrit_DON</th>\n",
       "      <td>21614.0</td>\n",
       "      <td>0.007825</td>\n",
       "      <td>0.998956</td>\n",
       "      <td>-5.199338</td>\n",
       "      <td>-0.652999</td>\n",
       "      <td>0.009405</td>\n",
       "      <td>0.689919</td>\n",
       "      <td>5.199338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IschemicTimeHour_DON</th>\n",
       "      <td>21519.0</td>\n",
       "      <td>0.014588</td>\n",
       "      <td>1.008877</td>\n",
       "      <td>-5.199338</td>\n",
       "      <td>-0.656884</td>\n",
       "      <td>-0.021946</td>\n",
       "      <td>0.740116</td>\n",
       "      <td>5.199338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BloodPH_DON</th>\n",
       "      <td>21593.0</td>\n",
       "      <td>0.001915</td>\n",
       "      <td>0.996429</td>\n",
       "      <td>-5.199338</td>\n",
       "      <td>-0.642944</td>\n",
       "      <td>-0.018810</td>\n",
       "      <td>0.683569</td>\n",
       "      <td>5.199338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LV_EjectionFractionPercent_DON</th>\n",
       "      <td>21630.0</td>\n",
       "      <td>0.005741</td>\n",
       "      <td>0.979852</td>\n",
       "      <td>-5.199338</td>\n",
       "      <td>-0.671737</td>\n",
       "      <td>-0.212886</td>\n",
       "      <td>0.533342</td>\n",
       "      <td>5.199338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LungPO2_DON</th>\n",
       "      <td>21585.0</td>\n",
       "      <td>0.000935</td>\n",
       "      <td>1.009236</td>\n",
       "      <td>-5.199338</td>\n",
       "      <td>-0.667031</td>\n",
       "      <td>-0.001129</td>\n",
       "      <td>0.670952</td>\n",
       "      <td>5.199338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LungPO2_FIO2_DON</th>\n",
       "      <td>21524.0</td>\n",
       "      <td>2.917741</td>\n",
       "      <td>3.012568</td>\n",
       "      <td>-5.199338</td>\n",
       "      <td>-0.619985</td>\n",
       "      <td>5.199338</td>\n",
       "      <td>5.199338</td>\n",
       "      <td>5.199338</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       count      mean       std       min  \\\n",
       "Age_DON                              21655.0 -0.001761  0.999583 -5.199338   \n",
       "Age_CAN                              21655.0 -0.016138  1.075381 -5.199338   \n",
       "BMI_CAN                              21643.0  0.003493  0.999326 -5.199338   \n",
       "BMI_DON                              21649.0  0.001690  0.998931 -5.199338   \n",
       "BloodUreaNitrogenLevel_DON           21614.0  0.000318  1.003988 -5.199338   \n",
       "WeightKg_DON                         21652.0  0.005182  0.999217 -5.199338   \n",
       "WeightKg_CAN                         21649.0  0.004353  0.997399 -5.199338   \n",
       "HeightCm_CAN                         21655.0  0.003546  0.995759 -5.199338   \n",
       "HeightCm_DON                         21655.0  0.006364  0.996675 -5.199338   \n",
       "Creatinine_DON                       21614.0 -0.001178  0.994696 -5.199338   \n",
       "CreatinineTransplant_CAN             21613.0  0.011612  1.005554 -5.199338   \n",
       "CreatinineRegistration_CAN           21584.0  0.006908  0.998607 -5.199338   \n",
       "HemodynamicsRegistration_CO_CAN      20419.0  0.001232  0.996742 -5.199338   \n",
       "HemodynamicsTransplant_CO_CAN        20703.0 -0.000621  1.003086 -5.199338   \n",
       "HemodynamicsRegistration_PA_DIA_CAN  20878.0 -0.000621  1.006716 -5.199338   \n",
       "HemodynamicsTransplant_PA_DIA_CAN    21037.0 -0.003620  1.010983 -5.199338   \n",
       "HemodynamicsRegistration_PA_MN_CAN   20672.0 -0.004510  1.012421 -5.199338   \n",
       "HemodynamicsTransplant_PA_MN_CAN     20851.0  0.000121  1.005640 -5.199338   \n",
       "HemodynamicsRegistration_PCW_CAN     19608.0 -0.006309  1.014648 -5.199338   \n",
       "HemodynamicsTransplant_PCW_CAN       20062.0 -0.002902  1.020051 -5.199338   \n",
       "HemodynamicsRegistration_SYS_CAN     20892.0 -0.001954  1.005047 -5.199338   \n",
       "HemodynamicsTransplant_SYS_CAN       21050.0 -0.002395  1.004684 -5.199338   \n",
       "TotalDayWaitList_CAN                 21655.0 -0.004573  1.007080 -5.199338   \n",
       "TotalBilirubinTransplant_CAN         21582.0  0.000653  1.034729 -5.199338   \n",
       "TerminalTotalBilirubin_DON           21612.0 -0.019785  0.982660 -5.199338   \n",
       "OrganRecovery_PCO2_DON               21587.0 -0.010585  1.002689 -5.199338   \n",
       "Level_SGOT_AST_DON                   21611.0 -0.005945  1.003753 -5.199338   \n",
       "Level_SGOT_ALT_DON                   21611.0 -0.003651  1.004851 -5.199338   \n",
       "DistanceFromDonorHospitaltoTXCenter  21655.0 -0.237124  1.631753 -5.199338   \n",
       "Hematocrit_DON                       21614.0  0.007825  0.998956 -5.199338   \n",
       "IschemicTimeHour_DON                 21519.0  0.014588  1.008877 -5.199338   \n",
       "BloodPH_DON                          21593.0  0.001915  0.996429 -5.199338   \n",
       "LV_EjectionFractionPercent_DON       21630.0  0.005741  0.979852 -5.199338   \n",
       "LungPO2_DON                          21585.0  0.000935  1.009236 -5.199338   \n",
       "LungPO2_FIO2_DON                     21524.0  2.917741  3.012568 -5.199338   \n",
       "\n",
       "                                          25%       50%       75%       max  \n",
       "Age_DON                             -0.691511  0.008778  0.677247  5.199338  \n",
       "Age_CAN                             -0.684362 -0.025709  0.646804  5.199338  \n",
       "BMI_CAN                             -0.670952  0.018183  0.691511  5.199338  \n",
       "BMI_DON                             -0.666609 -0.000599  0.678894  5.199338  \n",
       "BloodUreaNitrogenLevel_DON          -0.727804 -0.025709  0.699496  5.199338  \n",
       "WeightKg_DON                        -0.659219 -0.000627  0.674883  5.199338  \n",
       "WeightKg_CAN                        -0.661559  0.013167  0.672129  5.199338  \n",
       "HeightCm_CAN                        -0.602602 -0.004389  0.627601  5.199338  \n",
       "HeightCm_DON                        -0.682778  0.020064  0.663901  5.199338  \n",
       "Creatinine_DON                      -0.680623 -0.008151  0.683569  5.199338  \n",
       "CreatinineTransplant_CAN            -0.664683  0.045157  0.694700  5.199338  \n",
       "CreatinineRegistration_CAN          -0.665465  0.065880  0.694700  5.199338  \n",
       "HemodynamicsRegistration_CO_CAN     -0.670167 -0.002508  0.667031  5.199338  \n",
       "HemodynamicsTransplant_CO_CAN       -0.667031  0.016929  0.664683  5.199338  \n",
       "HemodynamicsRegistration_PA_DIA_CAN -0.705112  0.006270  0.684362  5.199338  \n",
       "HemodynamicsTransplant_PA_DIA_CAN   -0.660778 -0.050806  0.721283  5.199338  \n",
       "HemodynamicsRegistration_PA_MN_CAN  -0.676459 -0.003135  0.709138  5.199338  \n",
       "HemodynamicsTransplant_PA_MN_CAN    -0.632954 -0.008151  0.700297  5.199338  \n",
       "HemodynamicsRegistration_PCW_CAN    -0.724540  0.023200  0.664683  5.199338  \n",
       "HemodynamicsTransplant_PCW_CAN      -0.693104 -0.009405  0.692307  5.199338  \n",
       "HemodynamicsRegistration_SYS_CAN    -0.709138  0.014421  0.697895  5.199338  \n",
       "HemodynamicsTransplant_SYS_CAN      -0.636789 -0.014421  0.674883  5.199338  \n",
       "TotalDayWaitList_CAN                -0.689124 -0.003762  0.668598  5.199338  \n",
       "TotalBilirubinTransplant_CAN        -0.542036  0.021319  0.721283  5.199338  \n",
       "TerminalTotalBilirubin_DON          -0.575753 -0.040764  0.604859  5.199338  \n",
       "OrganRecovery_PCO2_DON              -0.713983 -0.005643  0.670952  5.199338  \n",
       "Level_SGOT_AST_DON                  -0.676459 -0.023827  0.671737  5.199338  \n",
       "Level_SGOT_ALT_DON                  -0.703505 -0.019437  0.685947  5.199338  \n",
       "DistanceFromDonorHospitaltoTXCenter -0.659219  0.008778  0.670952  5.199338  \n",
       "Hematocrit_DON                      -0.652999  0.009405  0.689919  5.199338  \n",
       "IschemicTimeHour_DON                -0.656884 -0.021946  0.740116  5.199338  \n",
       "BloodPH_DON                         -0.642944 -0.018810  0.683569  5.199338  \n",
       "LV_EjectionFractionPercent_DON      -0.671737 -0.212886  0.533342  5.199338  \n",
       "LungPO2_DON                         -0.667031 -0.001129  0.670952  5.199338  \n",
       "LungPO2_FIO2_DON                    -0.619985  5.199338  5.199338  5.199338  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_transformed.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ff986e-2eb4-4d62-9062-9e5ffac7ab8e",
   "metadata": {},
   "source": [
    "#### Histogram After Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bbd584cb-3ee1-44e9-86ef-7fba248a3200",
   "metadata": {},
   "outputs": [],
   "source": [
    "uv.histogramPlot(train_data_transformed, numericCols, bins=30, txt='Train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86682f5d-3bad-4af2-bf4f-8cb8dec23a73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2f903b-cb65-4bda-aa0d-d44213d5035e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5adc6e7e-ccf3-427c-a582-6d3b450d3484",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "30dbeaaa-5ed4-4174-822c-8ac10c4d7c8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Array 1: [1 2 3 4 5]\n",
      "Array 2: [ 6  7  8  9 10]\n",
      "Average: [3.5 4.5 5.5 6.5 7.5]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Assuming you have two arrays: array1 and array2\n",
    "array1 = np.array([1, 2, 3, 4, 5])\n",
    "array2 = np.array([6, 7, 8, 9, 10])\n",
    "\n",
    "# Calculate the average\n",
    "average_array = (array1 + array2) / 2\n",
    "\n",
    "print(\"Array 1:\", array1)\n",
    "print(\"Array 2:\", array2)\n",
    "print(\"Average:\", average_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b091cf2-a911-4141-b6f1-b8bc227a401c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   A\n",
      "1  2\n",
      "1  3\n",
      "3  5\n",
      "3  6\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Example DataFrame with duplicate indices\n",
    "data = {'A': [1, 2, 3, 4, 5, 6]}\n",
    "df = pd.DataFrame(data, index=[0, 1, 1, 2, 3, 3])\n",
    "\n",
    "# Show all duplicate indices\n",
    "duplicates = df[df.index.duplicated(keep=False)]\n",
    "print(duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a5e38c2-c7cb-4425-8ce7-6807773ecf8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imputeGMM Index:\n",
      " Index([0, 1, 2], dtype='int64')\n",
      "imputeKNN Index:\n",
      " Index([0, 1, 2], dtype='int64')\n",
      "df_impute Index:\n",
      " Index([0, 1, 2], dtype='int64')\n",
      "imputeGMM Columns:\n",
      " Index(['A', 'B'], dtype='object')\n",
      "imputeKNN Columns:\n",
      " Index(['A', 'B'], dtype='object')\n",
      "df_impute Columns:\n",
      " Index(['A', 'B'], dtype='object')\n",
      "Aligned imputeGMM Index:\n",
      " Index([0, 1, 2], dtype='int64')\n",
      "Aligned imputeKNN Index:\n",
      " Index([0, 1, 2], dtype='int64')\n",
      "Aligned imputeGMM Columns:\n",
      " Index(['A', 'B'], dtype='object')\n",
      "Aligned imputeKNN Columns:\n",
      " Index(['A', 'B'], dtype='object')\n",
      "   count  mean  std  min  25%  50%  75%  max\n",
      "A    3.0   2.0  1.0  1.0  1.5  2.0  2.5  3.0\n",
      "B    3.0   5.0  1.0  4.0  4.5  5.0  5.5  6.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample DataFrames for demonstration\n",
    "df_impute = pd.DataFrame({'A': [1, 2, np.nan], 'B': [4, np.nan, 6]}, index=[0, 1, 2])\n",
    "imputeGMM = pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6]}, index=[0, 1, 2])\n",
    "imputeKNN = pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6]}, index=[0, 1, 2])\n",
    "\n",
    "# Check Index and Columns\n",
    "print(\"imputeGMM Index:\\n\", imputeGMM.index)\n",
    "print(\"imputeKNN Index:\\n\", imputeKNN.index)\n",
    "print(\"df_impute Index:\\n\", df_impute.index)\n",
    "\n",
    "print(\"imputeGMM Columns:\\n\", imputeGMM.columns)\n",
    "print(\"imputeKNN Columns:\\n\", imputeKNN.columns)\n",
    "print(\"df_impute Columns:\\n\", df_impute.columns)\n",
    "\n",
    "# Align Index and Columns\n",
    "imputeGMM = imputeGMM.reindex(index=df_impute.index, columns=df_impute.columns)\n",
    "imputeKNN = imputeKNN.reindex(index=df_impute.index, columns=df_impute.columns)\n",
    "\n",
    "# Verify Alignment\n",
    "print(\"Aligned imputeGMM Index:\\n\", imputeGMM.index)\n",
    "print(\"Aligned imputeKNN Index:\\n\", imputeKNN.index)\n",
    "print(\"Aligned imputeGMM Columns:\\n\", imputeGMM.columns)\n",
    "print(\"Aligned imputeKNN Columns:\\n\", imputeKNN.columns)\n",
    "\n",
    "# Combine the imputed DataFrames\n",
    "df_concat = pd.concat([imputeGMM, imputeKNN])\n",
    "df_mean = df_concat.groupby(df_concat.index).mean()\n",
    "\n",
    "# Update the original DataFrame with the mean imputed values\n",
    "df_impute = df_mean\n",
    "\n",
    "# Describe the updated DataFrame\n",
    "print(df_impute.describe().T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9365edfc-d5f9-4cdd-8828-3f15e202a793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame 1:\n",
      "   A  B  C\n",
      "0  1  1  1\n",
      "1  1  1  1\n",
      "2  1  1  1\n",
      "\n",
      "DataFrame 2:\n",
      "   A  B  C\n",
      "0  2  2  2\n",
      "1  2  2  2\n",
      "2  2  2  2\n",
      "\n",
      "Vertical Concatenation Result:\n",
      "     A    B    C\n",
      "0  1.5  1.5  1.5\n",
      "1  1.5  1.5  1.5\n",
      "2  1.5  1.5  1.5\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create two sample DataFrames\n",
    "df1 = pd.DataFrame({\n",
    "    'A': [1, 1, 1],\n",
    "    'B': [1, 1, 1],\n",
    "    'C': [1, 1, 1]\n",
    "})\n",
    "\n",
    "df2 = pd.DataFrame({\n",
    "    'A': [2, 2, 2],\n",
    "    'B': [2, 2, 2],\n",
    "    'C': [2, 2, 2]\n",
    "})\n",
    "\n",
    "print(\"DataFrame 1:\")\n",
    "print(df1)\n",
    "print(\"\\nDataFrame 2:\")\n",
    "print(df2)\n",
    "\n",
    "# Concatenate the DataFrames vertically (along rows)\n",
    "result_vertical = pd.concat([df1, df2])\n",
    "\n",
    "# Calculate the mean by index\n",
    "df_mean = result_vertical.groupby(result_vertical.index).mean()\n",
    "\n",
    "\n",
    "print(\"\\nVertical Concatenation Result:\")\n",
    "print(df_mean)\n",
    "\n",
    "# # Concatenate the DataFrames horizontally (along columns)\n",
    "# df3 = pd.DataFrame({\n",
    "#     'D': ['D0', 'D1', 'D2'],\n",
    "#     'E': ['E0', 'E1', 'E2']\n",
    "# }, index=[0, 1, 2])\n",
    "\n",
    "# result_horizontal = pd.concat([df1, df3], axis=1)\n",
    "\n",
    "# print(\"\\nHorizontal Concatenation Result:\")\n",
    "# print(result_horizontal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0d71158-e370-4cc7-b9a1-bc992f7b085a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   feature1  feature2  feature3\n",
      "0   1.00000   3.00101  5.000000\n",
      "1   2.00000   1.00000  4.000000\n",
      "2   3.66589   2.00000  3.000000\n",
      "3   4.00000   3.00000  1.833968\n",
      "4   5.00000   4.00000  1.000000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.impute import KNNImputer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def KNN_GMM\n",
    "    # GMM Imputation\n",
    "    gmm = GaussianMixture(n_components=2, random_state=0)\n",
    "    gmm.fit(data.dropna())\n",
    "    gmm_imputed_data = data.copy()\n",
    "    for feature in data.columns:\n",
    "        missing_indices = data[feature].isnull()\n",
    "        if missing_indices.any():\n",
    "            imputed_values = gmm.sample(missing_indices.sum())[0]\n",
    "            gmm_imputed_data.loc[missing_indices, feature] = imputed_values[:, data.columns.get_loc(feature)]\n",
    "    \n",
    "    # KNN Imputation\n",
    "    knn_imputer = KNNImputer(n_neighbors=3)\n",
    "    knn_imputed_data = pd.DataFrame(knn_imputer.fit_transform(data), columns=data.columns)\n",
    "    \n",
    "    # Combine GMM and KNN Imputed Values\n",
    "    combined_imputed_data = data.copy()\n",
    "    for feature in data.columns:\n",
    "        combined_imputed_data[feature] = (gmm_imputed_data[feature] + knn_imputed_data[feature]) / 2\n",
    "\n",
    "print(combined_imputed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a07ffdb-d02c-4d0f-9f9d-ed7348a10fe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 1, iteration: 1/100, moves: 0, cost: 5.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 2, iteration: 1/100, moves: 0, cost: 8.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 3, iteration: 1/100, moves: 0, cost: 5.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 4, iteration: 1/100, moves: 0, cost: 5.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 5, iteration: 1/100, moves: 0, cost: 5.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 6, iteration: 1/100, moves: 0, cost: 5.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 7, iteration: 1/100, moves: 0, cost: 8.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 8, iteration: 1/100, moves: 0, cost: 8.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 9, iteration: 1/100, moves: 1, cost: 8.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 10, iteration: 1/100, moves: 1, cost: 5.0\n",
      "Best run was number 1\n",
      "   education_level  income_level  diagnosis_B  diagnosis_C  cluster\n",
      "0                0             0        False        False        1\n",
      "1                1             1         True        False        0\n",
      "2                2             2        False         True        1\n",
      "3                3             2        False        False        1\n",
      "4                1             1         True        False        0\n",
      "5                2             0        False        False        1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from kmodes.kmodes import KModes\n",
    "import numpy as np\n",
    "\n",
    "# Sample DataFrame with nominal and ordinal variables\n",
    "data = {\n",
    "    'education_level': ['High School', 'Bachelors', 'Masters', 'PhD', 'Bachelors', 'Masters'],\n",
    "    'diagnosis': ['A', 'B', 'C', 'A', 'B', 'A'],\n",
    "    'income_level': ['Low', 'Medium', 'High', 'High', 'Medium', 'Low'],\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Ordinal encoding for \"education_level\" and \"income_level\" (ordinal features)\n",
    "ordinal_mapping = {\n",
    "    'education_level': {'High School': 0, 'Bachelors': 1, 'Masters': 2, 'PhD': 3},\n",
    "    'income_level': {'Low': 0, 'Medium': 1, 'High': 2}\n",
    "}\n",
    "df['education_level'] = df['education_level'].map(ordinal_mapping['education_level'])\n",
    "df['income_level'] = df['income_level'].map(ordinal_mapping['income_level'])\n",
    "\n",
    "# One-Hot Encoding for \"diagnosis\" (nominal feature)\n",
    "df = pd.get_dummies(df, columns=['diagnosis'], drop_first=True)\n",
    "\n",
    "# Convert DataFrame to numpy array for KModes\n",
    "X = df.values\n",
    "\n",
    "# Apply K-modes clustering\n",
    "k_modes = KModes(n_clusters=2, init='Huang', n_init=10, verbose=1)\n",
    "clusters = k_modes.fit_predict(X)\n",
    "\n",
    "# Add the cluster labels to the DataFrame\n",
    "df['cluster'] = clusters\n",
    "\n",
    "# Display the clustered DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68228895-cd43-4999-98ab-834ccd8dd84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.mixture import GaussianMixture\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Sample DataFrame with nominal and ordinal variables\n",
    "# Example: \"education_level\" (ordinal), \"diagnosis\" (nominal)\n",
    "\n",
    "data = {\n",
    "    'education_level': ['High School', 'Bachelors', 'Masters', 'PhD', 'Bachelors', 'Masters'],\n",
    "    'diagnosis': ['A', 'B', 'C', 'A', 'B', 'A'],\n",
    "}\n",
    "\n",
    "# Convert the data to a pandas DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Ordinal Encoding for \"education_level\" (ordinal feature)\n",
    "ordinal_encoder = OrdinalEncoder(categories=[['High School', 'Bachelors', 'Masters', 'PhD']])\n",
    "df['education_level'] = ordinal_encoder.fit_transform(df[['education_level']])\n",
    "\n",
    "# One-Hot Encoding for \"diagnosis\" (nominal feature)\n",
    "df = pd.get_dummies(df, columns=['diagnosis'], drop_first=True)\n",
    "\n",
    "# Display the DataFrame after encoding\n",
    "print(\"Preprocessed DataFrame:\")\n",
    "print(df)\n",
    "\n",
    "# Fit the Latent Class Analysis model using Gaussian Mixture Model (GMM)\n",
    "# Specify the number of latent classes (k)\n",
    "k = 2  # Number of latent classes\n",
    "\n",
    "# Convert the DataFrame to a numpy array for fitting\n",
    "X = df.values\n",
    "\n",
    "# Initialize and fit the Gaussian Mixture Model\n",
    "gmm = GaussianMixture(n_components=k, covariance_type='full', random_state=42)\n",
    "gmm.fit(X)\n",
    "\n",
    "# Predict the latent class for each observation\n",
    "df['predicted_class'] = gmm.predict(X)\n",
    "\n",
    "# Display the DataFrame with the predicted latent classes\n",
    "print(\"\\nDataFrame with Predicted Latent Classes:\")\n",
    "print(df)\n",
    "\n",
    "# Optionally, visualize the cluster assignments for the first two features\n",
    "# Since the number of features is more than 2, you can visualize using PCA or just the first 2 dimensions for simplicity\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X)\n",
    "\n",
    "plt.scatter(X_pca[:, 0], X_pca[:, 1], c=df['predicted_class'], cmap='viridis')\n",
    "plt.xlabel('PCA Component 1')\n",
    "plt.ylabel('PCA Component 2')\n",
    "plt.title('Latent Class Analysis - Clusters (PCA)')\n",
    "plt.colorbar(label='Predicted Class')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f168cd-bc48-4761-ae84-079379516b7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16bca757-2b30-4e71-8dbc-a95ce3cd684f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "\n",
    "# Generate sample data\n",
    "X, _ = make_blobs(n_samples=300, centers=4, cluster_std=0.60, random_state=0)\n",
    "\n",
    "def plot_dbscan(X, eps, min_samples):\n",
    "    db = DBSCAN(eps=eps, min_samples=min_samples).fit(X)\n",
    "    core_samples_mask = np.zeros_like(db.labels_, dtype=bool)\n",
    "    core_samples_mask[db.core_sample_indices_] = True\n",
    "    labels = db.labels_\n",
    "\n",
    "    n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "    n_noise_ = list(labels).count(-1)\n",
    "\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    unique_labels = set(labels)\n",
    "    colors = [plt.cm.Spectral(each) for each in np.linspace(0, 1, len(unique_labels))]\n",
    "    for k, col in zip(unique_labels, colors):\n",
    "        if k == -1:\n",
    "            col = [0, 0, 0, 1]\n",
    "        class_member_mask = (labels == k)\n",
    "        xy = X[class_member_mask & core_samples_mask]\n",
    "        plt.plot(xy[:, 0], xy[:, 1], 'o', markerfacecolor=tuple(col),\n",
    "                 markeredgecolor='k', markersize=14)\n",
    "        xy = X[class_member_mask & ~core_samples_mask]\n",
    "        plt.plot(xy[:, 0], xy[:, 1], 'o', markerfacecolor=tuple(col),\n",
    "                 markeredgecolor='k', markersize=6)\n",
    "    plt.title(f'DBSCAN: eps={eps}, min_samples={min_samples}\\n'\n",
    "              f'Estimated number of clusters: {n_clusters_}')\n",
    "    plt.show()\n",
    "\n",
    "# 1. K-distance Graph\n",
    "def k_distance_graph(X, k):\n",
    "    nbrs = NearestNeighbors(n_neighbors=k).fit(X)\n",
    "    distances, _ = nbrs.kneighbors(X)\n",
    "    distances = np.sort(distances, axis=0)\n",
    "    distances = distances[:, k-1]\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    plt.plot(distances)\n",
    "    plt.title(f'{k}-distance Graph')\n",
    "    plt.xlabel('Points sorted by distance')\n",
    "    plt.ylabel(f'Distance to {k}th nearest neighbor')\n",
    "    plt.show()\n",
    "\n",
    "k_distance_graph(X, 4)  # Try different k values\n",
    "\n",
    "# 2. Grid Search with Silhouette Score\n",
    "def grid_search(X, eps_range, min_samples_range):\n",
    "    best_score = -1\n",
    "    best_params = None\n",
    "    for eps in eps_range:\n",
    "        for min_samples in min_samples_range:\n",
    "            dbscan = DBSCAN(eps=eps, min_samples=min_samples)\n",
    "            labels = dbscan.fit_predict(X)\n",
    "            if len(np.unique(labels)) > 1:  # More than one cluster\n",
    "                score = silhouette_score(X, labels)\n",
    "                if score > best_score:\n",
    "                    best_score = score\n",
    "                    best_params = (eps, min_samples)\n",
    "    return best_params\n",
    "\n",
    "eps_range = np.arange(0.1, 1.0, 0.1)\n",
    "min_samples_range = range(2, 10)\n",
    "best_eps, best_min_samples = grid_search(X, eps_range, min_samples_range)\n",
    "print(f\"Best parameters: eps={best_eps}, min_samples={best_min_samples}\")\n",
    "\n",
    "# 3. Elbow Method for eps\n",
    "def elbow_method(X):\n",
    "    neighbors = NearestNeighbors(n_neighbors=2)\n",
    "    nbrs = neighbors.fit(X)\n",
    "    distances, _ = nbrs.kneighbors(X)\n",
    "    distances = np.sort(distances, axis=0)\n",
    "    distances = distances[:, 1]\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    plt.plot(distances)\n",
    "    plt.title('Elbow Method for eps')\n",
    "    plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4cfd0b8-6218-4a7d-9878-3955d10690bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8541601-4403-41bf-894c-f03e8359f24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cluster import DBSCAN\n",
    "from gower import gower_matrix\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
    "\n",
    "# Sample mixed dataset\n",
    "data = pd.DataFrame({\n",
    "    \"Education_Level\": [\"High School\", \"Bachelor\", \"Master\", \"PhD\", \"Bachelor\"],\n",
    "    \"Shopping_Frequency\": [\"Weekly\", \"Monthly\", \"Rarely\", \"Weekly\", \"Monthly\"],\n",
    "    \"Payment_Method\": [\"Credit Card\", \"Debit Card\", \"Cash\", \"Credit Card\", \"Digital Wallet\"]\n",
    "})\n",
    "\n",
    "# Define order for ordinal features\n",
    "education_order = [\"High School\", \"Bachelor\", \"Master\", \"PhD\"]\n",
    "frequency_order = [\"Rarely\", \"Monthly\", \"Weekly\"]\n",
    "\n",
    "# Encode ordinal features\n",
    "ordinal_enc = OrdinalEncoder(categories=[education_order, frequency_order])\n",
    "data[[\"Education_Level\", \"Shopping_Frequency\"]] = ordinal_enc.fit_transform(data[[\"Education_Level\", \"Shopping_Frequency\"]])\n",
    "\n",
    "# One-hot encode nominal features\n",
    "encoder = OneHotEncoder(sparse_output=False, drop='first')\n",
    "encoded_nominal = encoder.fit_transform(data[[\"Payment_Method\"]])\n",
    "nominal_cols = encoder.get_feature_names_out([\"Payment_Method\"])\n",
    "\n",
    "# Convert to DataFrame\n",
    "encoded_nominal_df = pd.DataFrame(encoded_nominal, columns=nominal_cols)\n",
    "\n",
    "# Combine transformed ordinal and nominal data\n",
    "processed_data = pd.concat([data.drop(columns=[\"Payment_Method\"]), encoded_nominal_df], axis=1)\n",
    "\n",
    "# Compute Gower's Distance\n",
    "gower_dist = gower_matrix(processed_data)\n",
    "\n",
    "# Apply DBSCAN\n",
    "dbscan = DBSCAN(eps=0.3, min_samples=2, metric=\"precomputed\")  # Adjust 'eps' as needed\n",
    "clusters = dbscan.fit_predict(gower_dist)\n",
    "\n",
    "# Add cluster labels to data\n",
    "data[\"Cluster\"] = clusters\n",
    "\n",
    "print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ba10c0-0de6-4e20-accd-0f6de83935e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d05f861-88a4-41ee-9966-10c2d102b188",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cluster import DBSCAN\n",
    "from gower import gower_matrix\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "# Sample mixed dataset\n",
    "data = pd.DataFrame({\n",
    "    'Education_Level': ['High School', 'Associate', 'Bachelor', 'Master', 'Associate'],\n",
    "    'Shopping_Frequency': ['Weekly', 'Monthly', 'Rarely', 'Weekly', 'Monthly'],\n",
    "    'Payment_Method': ['Credit Card', 'Debit Card', 'Cash', 'Credit Card', 'Digital Wallet']\n",
    "})\n",
    "\n",
    "# Encoding ordinal features (Education Level, Shopping Frequency)\n",
    "ordinal_enc = OrdinalEncoder(categories=[\n",
    "    ['High School', 'Associate', 'Bachelor', 'Master'],  # Education Level (ordered)\n",
    "    ['Rarely', 'Monthly', 'Weekly']  # Shopping Frequency (ordered)\n",
    "])\n",
    "data[['Education_Level', 'Shopping_Frequency']] = ordinal_enc.fit_transform(\n",
    "    data[['Education_Level', 'Shopping_Frequency']]\n",
    ")\n",
    "\n",
    "# Compute Gower distance matrix\n",
    "distance_matrix = gower_matrix(data)\n",
    "\n",
    "# Apply DBSCAN with tuned parameters\n",
    "dbscan = DBSCAN(eps=0.4, min_samples=2, metric=\"precomputed\")  # Adjust eps and min_samples\n",
    "data[\"Cluster\"] = dbscan.fit_predict(distance_matrix)\n",
    "\n",
    "print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73509b3b-db8b-4070-b416-44f7d49140a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211293e6-8fe5-49fb-a493-38bed9edcb98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8633adc9-009c-4ad1-b0cb-c4d1730f3050",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Sample categorical dataset\n",
    "data = np.array([\n",
    "    [\"A\", \"Weekly\", \"Credit Card\"],\n",
    "    [\"B\", \"Monthly\", \"Debit Card\"],\n",
    "    [\"A\", \"Weekly\", \"Cash\"],\n",
    "    [\"C\", \"Rarely\", \"Credit Card\"],\n",
    "    [\"B\", \"Weekly\", \"Digital Wallet\"]\n",
    "])\n",
    "\n",
    "# One-hot encode categorical data\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "encoded_data = encoder.fit_transform(data)\n",
    "\n",
    "# Apply Gaussian Mixture Model\n",
    "gmm = GaussianMixture(n_components=2, random_state=42)\n",
    "gmm.fit(encoded_data)\n",
    "\n",
    "# Predict cluster membership\n",
    "clusters = gmm.predict(encoded_data)\n",
    "\n",
    "# Add results to DataFrame\n",
    "df = pd.DataFrame(data, columns=[\"Preferred Brand\", \"Shopping Frequency\", \"Payment Method\"])\n",
    "df[\"Cluster\"] = clusters\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40702252-b5e0-4639-a6a1-946984300515",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class KFoldTargetEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, categorical_column, target_column, n_splits=5, smoothing=10):\n",
    "        self.categorical_column = categorical_column\n",
    "        self.target_column = target_column\n",
    "        self.n_splits = n_splits\n",
    "        self.smoothing = smoothing\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.global_mean_ = X[self.target_column].mean()\n",
    "        self.kf_ = KFold(n_splits=self.n_splits, shuffle=True, random_state=42)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        df_encoded = X.copy()\n",
    "        df_encoded[f\"{self.categorical_column}_encoded\"] = np.nan\n",
    "\n",
    "        for _, val_idx in self.kf_.split(X):\n",
    "            train_mask = ~X.index.isin(val_idx)\n",
    "            train_fold = X[train_mask]\n",
    "            val_fold = X.iloc[val_idx]\n",
    "\n",
    "            category_stats = train_fold.groupby(self.categorical_column)[self.target_column].agg(['mean', 'count'])\n",
    "            category_stats['smooth_mean'] = (category_stats['mean'] * category_stats['count'] + self.global_mean_ * self.smoothing) / (category_stats['count'] + self.smoothing)\n",
    "            \n",
    "            df_encoded.loc[val_fold.index, f\"{self.categorical_column}_encoded\"] = val_fold[self.categorical_column].map(category_stats['smooth_mean'])\n",
    "        \n",
    "        df_encoded[f\"{self.categorical_column}_encoded\"] = df_encoded[f\"{self.categorical_column}_encoded\"].fillna(self.global_mean_)\n",
    "        return df_encoded[[f\"{self.categorical_column}_encoded\"]]\n",
    "\n",
    "# Simulated dataset\n",
    "np.random.seed(42)\n",
    "df = pd.DataFrame({\n",
    "    'category': np.random.choice(['A', 'B', 'C', 'D', 'E'], 500),\n",
    "    'target': np.random.randint(0, 2, 500)\n",
    "})\n",
    "\n",
    "# Define range of smoothing values to test\n",
    "param_grid = {\n",
    "    'encoder__smoothing': [1, 5, 10, 20, 50, 100],\n",
    "    'classifier__n_estimators': [50, 100, 200]\n",
    "}\n",
    "\n",
    "# Create pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('encoder', KFoldTargetEncoder(categorical_column='category', target_column='target')),\n",
    "    ('classifier', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "# Perform Grid Search\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='roc_auc', n_jobs=-1)\n",
    "grid_search.fit(df, df['target'])\n",
    "\n",
    "print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best AUC: {grid_search.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b98d65b-1d73-4844-bfd2-bbc524028580",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f42d24-aed0-4f1b-ab35-b7333909d7be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7ff269-5100-4b5d-b86f-e2446289f845",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "def kfold_target_encoding_smooth(df, categorical_column, target_column, n_splits=5, smoothing=10):\n",
    "    df_encoded = df.copy()  # Ensure we're working on a copy of the original DataFrame\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    \n",
    "    global_mean = df[target_column].mean()\n",
    "    df_encoded[f\"{categorical_column}_encoded\"] = np.nan\n",
    "\n",
    "    for _, val_idx in kf.split(df):\n",
    "        train_mask = ~df.index.isin(val_idx)\n",
    "        train_fold = df[train_mask]\n",
    "        val_fold = df.iloc[val_idx]\n",
    "\n",
    "        category_stats = train_fold.groupby(categorical_column)[target_column].agg(['mean', 'count'])\n",
    "        category_stats['smooth_mean'] = (category_stats['mean'] * category_stats['count'] + global_mean * smoothing) / (category_stats['count'] + smoothing)\n",
    "        \n",
    "        # Use .loc to avoid chained assignment\n",
    "        df_encoded.loc[val_fold.index, f\"{categorical_column}_encoded\"] = val_fold[categorical_column].map(category_stats['smooth_mean'])\n",
    "    \n",
    "    # Replace inplace=True with explicit reassignment\n",
    "    df_encoded[f\"{categorical_column}_encoded\"] = df_encoded[f\"{categorical_column}_encoded\"].fillna(global_mean)\n",
    "    \n",
    "    return df_encoded\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Simulated dataset\n",
    "np.random.seed(42)\n",
    "df = pd.DataFrame({\n",
    "    'category': np.random.choice(['A', 'B', 'C', 'D', 'E'], 500),\n",
    "    'target': np.random.randint(0, 2, 500)\n",
    "})\n",
    "\n",
    "# Define range of smoothing values to test\n",
    "smoothing_values = [1, 5, 10, 15, 20, 40, 50, 75]\n",
    "best_smoothing = None\n",
    "best_score = -np.inf\n",
    "\n",
    "# Perform Cross-Validation Loop\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for smoothing in smoothing_values:\n",
    "    scores = []\n",
    "    \n",
    "    for train_idx, val_idx in kf.split(df):\n",
    "        train_df, val_df = df.iloc[train_idx], df.iloc[val_idx]\n",
    "        \n",
    "        # Apply target encoding within the current fold\n",
    "        train_encoded = kfold_target_encoding_smooth(train_df, 'category', 'target', smoothing=smoothing)\n",
    "        \n",
    "        # Use the encoding from train_encoded to encode val_df\n",
    "        category_stats = train_encoded.groupby('category')['category_encoded'].mean()\n",
    "        val_encoded = val_df.copy()\n",
    "        # In the cross-validation loop:\n",
    "        val_encoded['category_encoded'] = val_df['category'].map(category_stats)\n",
    "        val_encoded['category_encoded'] = val_encoded['category_encoded'].fillna(train_encoded['category_encoded'].mean())\n",
    "        \n",
    "        # Prepare features\n",
    "        X_train, X_val = train_encoded[['category_encoded']], val_encoded[['category_encoded']]\n",
    "        y_train, y_val = train_df['target'], val_df['target']\n",
    "        \n",
    "        # Train model\n",
    "        model = RandomForestClassifier(random_state=42)\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Evaluate model\n",
    "        y_pred = model.predict_proba(X_val)[:, 1]\n",
    "        auc_score = roc_auc_score(y_val, y_pred)\n",
    "        scores.append(auc_score)\n",
    "    \n",
    "    mean_score = np.mean(scores)\n",
    "    print(f\"Smoothing: {smoothing}, Mean AUC: {mean_score:.4f}\")\n",
    "    \n",
    "    if mean_score > best_score:\n",
    "        best_score = mean_score\n",
    "        best_smoothing = smoothing\n",
    "\n",
    "print(f\"\\nBest smoothing value: {best_smoothing} with AUC: {best_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2c7321-5e46-4373-91fa-18992b2c26b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6c7fc0-7295-4bc7-82da-f80fb7a9bef5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5bd8beb-7693-485a-aff9-1e6764f2620f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c39588-d680-4bfa-b690-ad7852a65e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "X = np.random.rand(300, 2)  # Replace with your dataset\n",
    "\n",
    "# Compute distances to k-nearest neighbors\n",
    "k = 5  # Typically, k = min_samples\n",
    "nbrs = NearestNeighbors(n_neighbors=k).fit(X)\n",
    "distances, indices = nbrs.kneighbors(X)\n",
    "\n",
    "# Sort and plot k-distance graph\n",
    "sorted_distances = np.sort(distances[:, k - 1])\n",
    "plt.plot(sorted_distances)\n",
    "plt.xlabel(\"Points sorted by distance\")\n",
    "plt.ylabel(f\"Distance to {k}th nearest neighbor\")\n",
    "plt.title(\"K-Distance Plot\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2871671-b9b5-470e-ba1f-eb6dcb352604",
   "metadata": {},
   "outputs": [],
   "source": [
    "from feature_engine.transformation import YeoJohnsonTransformer\n",
    "import pandas as pd\n",
    "\n",
    "# Example: Transforming a DataFrame using Yeo-Johnson transformation\n",
    "df = pd.DataFrame({'A': [1, 2, 3, 4, 5]})\n",
    "transformer = YeoJohnsonTransformer(variables=['A'])\n",
    "df_transformed = transformer.fit_transform(df)\n",
    "print(df_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e87c605-f9c5-4cb8-9c88-70110c09f789",
   "metadata": {},
   "outputs": [],
   "source": [
    "from feature_engine.transformation import YeoJohnsonTransformer\n",
    "import pandas as pd\n",
    "\n",
    "# Sample data\n",
    "df = pd.DataFrame({'A': [1, 2, 3, 4, 5], 'B': [-1, -2, -3, -4, -5]})\n",
    "\n",
    "# Initialize the YeoJohnsonTransformer\n",
    "transformer = YeoJohnsonTransformer(variables=['A', 'B'])\n",
    "\n",
    "# Fit and transform the data\n",
    "df_transformed = transformer.fit_transform(df)\n",
    "\n",
    "print(\"Original Data:\\n\", df)\n",
    "print(\"Transformed Data:\\n\", df_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a55efba-362f-4b13-9d34-56391a309a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.cluster import DBSCAN #For outlier detection/clustering\n",
    "\n",
    "# --- 1. Example with Numerical Features (Clustering Data) ---\n",
    "data = {'Feature1': [1.00, 1.10, 2.00, 1.05],\n",
    "        'Feature2': [2.0, 2.2, 4.0, 2.1],\n",
    "        'Feature3': [3.00, 3.30, 6.00, 3.15]}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Initialize QuantileTransformer (normal distribution as example)\n",
    "quantile_transformer = QuantileTransformer(output_distribution='normal',\n",
    "                                           n_quantiles=4, #Important: should be <= number of samples\n",
    "                                           random_state=0)\n",
    "\n",
    "# Fit and transform the data\n",
    "df_transformed = quantile_transformer.fit_transform(df)\n",
    "df_transformed = pd.DataFrame(df_transformed, columns=df.columns) #Convert back to DataFrame\n",
    "\n",
    "print(\"Transformed Clustering Data:\\n\", df_transformed)\n",
    "\n",
    "# Example of using the transformed data for DBSCAN clustering (outlier detection)\n",
    "dbscan = DBSCAN(eps=0.5, min_samples=2)  # Adjust parameters as needed\n",
    "clusters = dbscan.fit_predict(df_transformed) #predict the clusters using transformed data\n",
    "\n",
    "print(\"\\nCluster Labels:\\n\", clusters)\n",
    "# Add cluster labels to original dataframe\n",
    "df['Cluster'] = clusters\n",
    "print(\"\\nCombined dataframe with clusters\")\n",
    "print(df)\n",
    "\n",
    "# --- 2. Example with Severity Level Data (Illustrative, requires cleaning) ---\n",
    "data2 = {'column1': ['Unknown', 'Unknown', 'Unknown', 'Unknown', 'Unknown', 'Unknown', '50% - Requires considerable assistance and fre...', '20% - Very sick, hospitalization necessary: ac...', 'Unknown', 'Unknown', '20% - Very sick, hospitalization necessary: ac...', '50% - Very sick, hospitalization necessary: ac...'],\n",
    "         'column2': ['Unknown', 'Unknown', 'Unknown', 'Unknown', 'Unknown', 'Unknown', '50% - Requires considerable assistance and fre...', '20% - Very sick, hospitalization necessary: ac...', 'Unknown', 'Unknown', '50% - Very sick, hospitalization necessary: ac...', '20% - Very sick, hospitalization necessary: ac...']}\n",
    "df2 = pd.DataFrame(data2)\n",
    "\n",
    "# Replace 'Unknown' values with NaN\n",
    "df2 = df2.replace('Unknown', np.nan)\n",
    "\n",
    "# Function to extract the percentage (requires cleaning and handling NaN)\n",
    "def extract_percentage(text):\n",
    "    if pd.isna(text):  # Handle NaN values\n",
    "        return np.nan\n",
    "    try:\n",
    "        return float(text.split('%')[0])  # Extract percentage as float\n",
    "    except:\n",
    "        return np.nan  #Handle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ceade5a-813a-454c-8e6b-79e7031bdf24",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c35d620-7266-4627-966e-972bb57ba09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c27a7a-d669-475f-a0a7-e5f5caf1f761",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine features\n",
    "features = ['BloodInfectionSource_DON','UrineInfection_DON','PulmonaryInfection_DON','InfectionClinical_DON','OtherInfectionSource_DON']\n",
    "\n",
    "# new feature\n",
    "df['Infection_CountTotal_DON'] = df[features].apply(lambda row: sum(1 for value in row if value == 1 or value == 'Yes'), axis=1)\n",
    "\n",
    "# update DataFrame\n",
    "df_drop  = uf.insertIntoDataFrame(df_drop, features)\n",
    "df_don  = uf.insertIntoDataFrame(df_don, ['Infection_CountTotal_DON'])\n",
    "df_ordinal  = uf.insertIntoDataFrame(df_ordinal, ['Infection_CountTotal_DON'])\n",
    "\n",
    "# change datatype to category\n",
    "df = uf.toCategory(df, ['Infection_CountTotal_DON'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36885915-4e78-43b4-a6a1-8443b302907d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import OneClassSVM\n",
    "import numpy as np\n",
    "\n",
    "# Example: Generate random data (normal data)\n",
    "X_train = np.random.randn(100, 2)  # 100 normal data points with 2 features\n",
    "\n",
    "# Train One-Class SVM\n",
    "clf = OneClassSVM(nu=0.1, kernel=\"rbf\", gamma=\"scale\")\n",
    "clf.fit(X_train)\n",
    "\n",
    "# Example: New data for prediction\n",
    "X_new = np.array([[1,1],[-1,-1],[-1.5,-2.5]])\n",
    "\n",
    "# Predict anomalies (1 for normal, -1 for outlier)\n",
    "predictions = clf.predict(X_new)\n",
    "\n",
    "print(predictions)  # Output: [ 1 -1], where -1 is an outlier and 1 is normal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1fede3-ff84-4d06-a9a2-87693d70d14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa264ff-6827-4101-ac36-9b0d4b61bd10",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.min(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a88e7a-9fc5-49ff-b01e-e1f6d95c8a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e905c8-d8bf-4994-a9e3-ad1c1865ee0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PowerTransformer\n",
    "\n",
    "# Initialize the PowerTransformer\n",
    "transformer = PowerTransformer(method='box-cox')\n",
    "\n",
    "# Fit and transform the data\n",
    "transformed_data = transformer.fit_transform(df[features])\n",
    "\n",
    "# Convert transformed data back to DataFrame\n",
    "transformed_df = pd.DataFrame(transformed_data, columns=features)\n",
    "\n",
    "print(\"Transformed data:\")\n",
    "print(transformed_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ebc1b36-27ec-47c7-a605-196b89979aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "import numpy as np\n",
    "\n",
    "# Assuming you have a dataset with missing values\n",
    "X = np.array([[1, 2, np.nan], [3, np.nan, 1], [np.nan, 5, 6]])\n",
    "\n",
    "# Initialize and fit the SimpleImputer\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_imputed = imputer.fit_transform(X)\n",
    "\n",
    "# X_imputed now contains the imputed dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d646f7-0ff1-4206-887c-1697d2d1138d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d91697-25fb-47a3-95cf-2d11357524a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.experimental import enable_iterative_imputer  # noqa\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "# Sample dataset with missing values\n",
    "X = np.array([[1, 2, np.nan], \n",
    "              [3, np.nan, 1], \n",
    "              [np.nan, 5, 6], \n",
    "              [8, 7, 9]])\n",
    "\n",
    "# Initialize the IterativeImputer\n",
    "imputer = IterativeImputer(max_iter=10, random_state=0)\n",
    "\n",
    "# Fit and transform the dataset\n",
    "X_imputed = imputer.fit_transform(X)\n",
    "\n",
    "print(\"Original Data:\\n\", X)\n",
    "print(\"Imputed Data:\\n\", X_imputed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f39bea-30b5-41bf-9066-63037a5661ec",
   "metadata": {},
   "source": [
    "#### Customizing Estimators\n",
    "##### In the example below:\n",
    "- You can replace LinearRegression() with any other regression model (like DecisionTreeRegressor, BayesianRidge, etc.) based on your requirements.\n",
    "- The IterativeImputer will use the specified model to predict missing values iteratively.\n",
    "- Handling Convergence Issues\n",
    "    - If you encounter convergence warnings (as seen in your search results), consider these strategies:\n",
    "    - Increase max_iter: Allow more iterations for convergence.\n",
    "    - Feature Scaling: Ensure that your features are appropriately scaled (e.g., using StandardScaler).\n",
    "    - Regularization: If using models like Elastic Net within the imputer, consider adjusting regularization parameters.\n",
    "\n",
    "- By specifying different regression models for imputing each feature, you can leverage the strengths of various algorithms to achieve better imputation results tailored to your data characteristics.\n",
    "- Bayesian Ridge Regression is a probabilistic model that extends traditional linear regression by incorporating Bayesian principles. It provides a way to estimate the uncertainty of the model parameters, allowing for more robust predictions, especially in the presence of noise or overfitting.\n",
    "- Bayesian Elastic Net Regression combines the principles of Bayesian inference with the Elastic Net regularization technique. This approach is particularly useful for handling datasets with multicollinearity and for situations where the number of predictors exceeds the number of observations.\n",
    "    - Key Features of Bayesian Elastic Net Regression\n",
    "    - Bayesian Framework: Unlike traditional regression methods that provide point estimates, Bayesian methods yield a distribution of possible values for each coefficient, allowing for uncertainty quantification.\n",
    "    - Elastic Net Regularization: This method incorporates both L1 (Lasso) and L2 (Ridge) penalties, which helps in feature selection and reduces overfitting. The combination allows it to perform well in high-dimensional spaces.\n",
    "    - Automatic Hyperparameter Tuning: Bayesian methods can automatically estimate hyperparameters related to the priors on coefficients, making it easier to find optimal settings without manual tuning.\n",
    "    - Handling Convergence Issues: As indicated in your search results, convergence warnings may arise when fitting the model. This can often be addressed by increasing the number of iterations or adjusting feature scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf35bcb2-57ba-4626-b21b-bb0f5f36e2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "\n",
    "# Sample dataset\n",
    "X = np.array([[1, 2], [2, 3], [3, 4], [4, 5]])\n",
    "y = np.array([1.5, 2.5, 3.5, 4.5])\n",
    "\n",
    "# Initialize ElasticNet with cross-validation to find optimal alpha and l1_ratio\n",
    "elastic_net = ElasticNetCV(cv=3)\n",
    "elastic_net.fit(X, y)\n",
    "\n",
    "# Use the coefficients from ElasticNet as priors in Bayesian Ridge\n",
    "model = BayesianRidge()\n",
    "model.fit(X, y)\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(X)\n",
    "\n",
    "print(\"Predictions:\", predictions)\n",
    "print(\"Coefficients:\", model.coef_)\n",
    "print(\"Intercept:\", model.intercept_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85a603e-2a82-494d-847d-f84f28388807",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.experimental import enable_iterative_imputer  # noqa\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.linear_model import LinearRegression, BayesianRidge\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Sample dataset with missing values\n",
    "X = np.array([[1, 2, np.nan], \n",
    "              [3, np.nan, 1], \n",
    "              [np.nan, 5, 6], \n",
    "              [8, 7, 9]])\n",
    "\n",
    "# Define different estimators for each feature\n",
    "estimators = {\n",
    "    0: LinearRegression(),        # For the first feature\n",
    "    1: DecisionTreeRegressor(),   # For the second feature\n",
    "    2: BayesianRidge()            # For the third feature\n",
    "}\n",
    "\n",
    "# Initialize the IterativeImputer with a custom estimator for each feature\n",
    "imputer = IterativeImputer(estimator=LinearRegression(), max_iter=10, random_state=0)\n",
    "\n",
    "# Fit and transform the dataset\n",
    "X_imputed = imputer.fit_transform(X)\n",
    "\n",
    "print(\"Original Data:\\n\", X)\n",
    "print(\"Imputed Data:\\n\", X_imputed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79b7bce-bfe0-460f-95ad-1276f3479a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "\n",
    "data = np.array([[1], [2], [6], [8], [10]])\n",
    "discretizer = KBinsDiscretizer(n_bins=3, encode='ordinal', strategy='uniform')\n",
    "discretized_data = discretizer.fit_transform(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3419f258-6598-4c17-8675-d5376b4182be",
   "metadata": {},
   "outputs": [],
   "source": [
    "discretized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d81abc-cbf9-49d7-8d3f-bdc2f6e2fb85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = np.random.rand(10) * 100  # Sample continuous data\n",
    "bins = [0, 25, 50, 75, 100]\n",
    "discretized_data = pd.cut(data, bins=bins)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e09942-c72f-4d30-9a22-c6b0cd30f4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "discretized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b13028-d14f-4472-9b48-ee2d2e900b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load dataset (Iris dataset as an example)\n",
    "data = load_iris()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# Split into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define a range of gamma values to test\n",
    "gamma_values = [0, 0.1, 0.5, 1, 10]\n",
    "train_accuracies = []\n",
    "val_accuracies = []\n",
    "\n",
    "# Train models with different gamma values and record accuracies\n",
    "for gamma in gamma_values:\n",
    "    model = XGBClassifier(gamma=gamma)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on training and validation sets\n",
    "    train_pred = model.predict(X_train)\n",
    "    val_pred = model.predict(X_val)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    train_accuracy = accuracy_score(y_train, train_pred)\n",
    "    val_accuracy = accuracy_score(y_val, val_pred)\n",
    "    \n",
    "    train_accuracies.append(train_accuracy)\n",
    "    val_accuracies.append(val_accuracy)\n",
    "\n",
    "# Plotting the results\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(gamma_values, train_accuracies, label='Training Accuracy', marker='o')\n",
    "plt.plot(gamma_values, val_accuracies, label='Validation Accuracy', marker='o')\n",
    "plt.title('Effect of Gamma on Model Performance')\n",
    "plt.xlabel('Gamma Value')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xticks(gamma_values)\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23309910-a5c6-4c33-a0bb-93395cac37fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load dataset (Iris dataset as an example)\n",
    "data = load_iris()\n",
    "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "y = data.target\n",
    "\n",
    "# Split into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and fit Random Forest model\n",
    "model = RandomForestClassifier(n_estimators=100)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Get feature importances\n",
    "importances = model.feature_importances_\n",
    "\n",
    "# Create a DataFrame for visualization\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Importance': importances\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Plotting feature importance\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(feature_importance_df['Feature'], feature_importance_df['Importance'], color='steelblue')\n",
    "plt.xlabel('Importance Score')\n",
    "plt.title('Feature Importance in Random Forest')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644e5c9d-4bfa-45d3-8779-aa70d4289130",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fuzzywuzzy import fuzz, process\n",
    "\n",
    "# Example DataFrame\n",
    "import pandas as pd\n",
    "data = {'Name': ['John Smith', 'Jon Smith', 'Johnny Smth', 'Jane Doe']}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Comparing strings for similarity\n",
    "for i in range(len(df)):\n",
    "    for j in range(i + 1, len(df)):\n",
    "        similarity = fuzz.ratio(df['Name'][i], df['Name'][j])\n",
    "        if similarity > 80:  # Set threshold for duplicates\n",
    "            print(f\"Possible duplicate: '{df['Name'][i]}' and '{df['Name'][j]}' with similarity {similarity}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e108bbc4-9d85-4cae-8635-9a5fa2345e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Example DataFrame\n",
    "data = {\n",
    "    'Feature1': [1, 1.1, 2, 1.05],\n",
    "    'Feature2': [2, 2.2, 4, 2.1],\n",
    "    'Feature3': [3, 3.3, 6, 3.15]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Compute cosine similarity\n",
    "similarity_matrix = cosine_similarity(df)\n",
    "\n",
    "# Set a threshold for near-duplicates\n",
    "threshold = 0.99\n",
    "for i in range(len(similarity_matrix)):\n",
    "    for j in range(i + 1, len(similarity_matrix)):\n",
    "        if similarity_matrix[i, j] > threshold:\n",
    "            print(f\"Rows {i} and {j} are near-duplicates with similarity {similarity_matrix[i, j]:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33baadd2-268e-48bf-b877-a9649b732375",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1f6857-c86b-4ab8-a1d7-a5279ecde323",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "# Compute pairwise Euclidean distance\n",
    "distance_matrix = cdist(df, df, metric='euclidean')\n",
    "\n",
    "# Set a threshold for near-duplicates\n",
    "threshold = 0.1\n",
    "for i in range(len(distance_matrix)):\n",
    "    for j in range(i + 1, len(distance_matrix)):\n",
    "        if distance_matrix[i, j] < threshold:\n",
    "            print(f\"Rows {i} and {j} are near-duplicates with distance {distance_matrix[i, j]:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860f35ed-f7a6-4c0e-b2c2-e64b276f1b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712c7769-a858-49b6-aca2-e07e76b9c3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute pairwise Manhattan distance\n",
    "manhattan_matrix = cdist(df, df, metric='cityblock')\n",
    "\n",
    "# Set a threshold for near-duplicates\n",
    "threshold = 0.2\n",
    "for i in range(len(manhattan_matrix)):\n",
    "    for j in range(i + 1, len(manhattan_matrix)):\n",
    "        if manhattan_matrix[i, j] < threshold:\n",
    "            print(f\"Rows {i} and {j} are near-duplicates with distance {manhattan_matrix[i, j]:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05054f89-2387-4958-81e6-476b2479fd02",
   "metadata": {},
   "outputs": [],
   "source": [
    "manhattan_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdea2353-257b-43da-a7bd-a042d490e520",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "import numpy as np\n",
    "\n",
    "# Fit DBSCAN\n",
    "db = DBSCAN(eps=0.2, min_samples=2, metric='euclidean').fit(df)\n",
    "\n",
    "# Assign cluster labels\n",
    "df['Cluster'] = db.labels_\n",
    "\n",
    "# Find duplicates (rows in the same cluster)\n",
    "for cluster in set(db.labels_):\n",
    "    if cluster != -1:  # Ignore noise points\n",
    "        duplicate_rows = df[df['Cluster'] == cluster]\n",
    "        print(f\"Cluster {cluster} contains potential duplicates:\")\n",
    "        print(duplicate_rows, \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51065bc-196b-4e8a-9be0-e2bc6a274efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161f6e0c-de02-47af-a2e4-eb46417e2771",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cedfb95-52b8-4018-8839-5306eed23799",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.imputation.mice import MICEData\n",
    "\n",
    "# Create a DataFrame with missing values\n",
    "df = pd.DataFrame({\n",
    "    'CPRA_Recent_CAN': [11.2, 0.0, np.nan, 7.0, 100.0],\n",
    "    'CPRA_Peak_CAN': [14.9, np.nan, 19.0, 0.0, 100.0]\n",
    "})\n",
    "\n",
    "# Apply MICE (Multiple Imputation by Chained Equations)\n",
    "mice_data = MICEData(df)\n",
    "imputed_data = mice_data.data\n",
    "\n",
    "# View the imputed dataset\n",
    "print(imputed_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91cd7802-fb1a-4cbf-8a82-748388200e61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f5bebc-4eb6-4d22-ae7e-1db857db7697",
   "metadata": {},
   "outputs": [],
   "source": [
    "import missingno as msno\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Visualize missing data\n",
    "msno.matrix(df)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90238d04-3c28-4475-b848-e38abb06dd66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "imputer = KNNImputer(n_neighbors=5, weights='distance')\n",
    "df_imputed = imputer.fit_transform(df[['CPRA_Recent_CAN', 'CPRA_Peak_CAN']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abed7274-78f9-43cf-8219-51ac5b369d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "# Assuming df is your dataframe with the two columns\n",
    "data = df[['CPRA_Recent_CAN', 'CPRA_Peak_CAN']]\n",
    "\n",
    "# Create multiple imputations\n",
    "n_imputations = 5\n",
    "imputed_data_sets = []\n",
    "\n",
    "for i in range(n_imputations):\n",
    "    imputer = IterativeImputer(random_state=i)\n",
    "    imputed_data = imputer.fit_transform(data)\n",
    "    imputed_data_sets.append(pd.DataFrame(imputed_data, columns=data.columns))\n",
    "\n",
    "# Analyze results across multiple imputations\n",
    "for i, imputed_df in enumerate(imputed_data_sets):\n",
    "    print(f\"Imputation {i+1} correlation:\")\n",
    "    print(imputed_df.corr())\n",
    "    print(\"\\n\")\n",
    "\n",
    "# You can then combine results from these multiple imputations for your analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e225cd-8929-4680-a269-aaf648d3792f",
   "metadata": {},
   "source": [
    "#### `Predictive Mean Matching (PMM)` is a robust and widely used imputation method for handling missing data.\n",
    "- `PMM` imputes missing values by borrowing observed values from the dataset, ensuring that the imputed values maintain the original distribution of the data\n",
    "    - For example:\n",
    "        - If the original variable is skewed, the imputed values will also be skewed.\n",
    "        - If the variable is bounded (e.g., 0 to 100), PMM ensures that imputed values respect these bounds\n",
    "- Instead of directly using the predicted values, PMM identifies observed data points (donors) whose predicted values are closest to the predicted value of the missing case\n",
    "- From a pool of donor observations with similar predicted values, PMM randomly selects one observed value to replace the missing value\n",
    "- Unlike parametric methods (e.g., linear regression imputation), `PMM` does not assume normality or linearity in relationships between variables\n",
    "    - It works well with:\n",
    "        - Non-normal distributions.\n",
    "        - Heteroscedasticity (unequal variance).\n",
    "        - Nonlinear associations.\n",
    "- Traditional methods like mean or median imputation can introduce bias, especially when data is not missing completely at random (MCAR). PMM reduces this risk by matching missing values with observed ones from similar cases "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e5980a-9bc9-48f6-bf05-9a491877d0cb",
   "metadata": {},
   "source": [
    "#### Given the high correlation, we should use an imputation technique that leverages the relationship between these two columns while preserving their statistical properties.\n",
    "- KNNImputer:\n",
    "    - Use k-Nearest Neighbors to impute missing values based on similar rows in the dataset.\n",
    "    - This method can preserve relationships between features because it imputes missing values based on neighbors' patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a50228b-aafe-40a0-ad67-cd3d758e09c6",
   "metadata": {},
   "source": [
    "#### Since two features have almost identical missing values, it suggests that the missingness in one feature is strongly related to the other. This can indicate that the data is Missing at Random (MAR) or even Missing Not at Random (MNAR) instead of Missing Completely at Random (MCAR)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e07036-3528-4b21-b4be-f95e87cf76ed",
   "metadata": {},
   "source": [
    "#### Summing features that represent the combined value of the original two features. For example, if you have two features representing the number of hours studied and the number of hours slept, summing them could give a new feature representing the total hours spent on these activities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0e3fcb-e627-4859-8fc1-107550e0db57",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['missing_CPRA_Peak_CAN'] = df['CPRA_Recent_CAN'].isnull().astype(int)\n",
    "chi2, p_value, _, _ = chi2_contingency(pd.crosstab(df['missing_CPRA_Peak_CAN'], df['CPRA_Recent_CAN']))\n",
    "print(f'Chi-square test p-value: {p_value}')\n",
    "\n",
    "# Interpretation\n",
    "if p_value > 0.05:\n",
    "    print(\"Fail to reject null hypothesis:  There is no significant association between the variables.\")\n",
    "else:\n",
    "    print(\"Reject null hypothesis: There is a significant association between the variables.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d9c0cf-aed1-4bab-b0e3-24f6b3e05147",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "# Create a missingness indicator for CPRA_Recent_CAN (1 if missing, 0 if not)\n",
    "df['missing_CPRA_Recent_CAN'] = df['CPRA_Recent_CAN'].isnull().astype(int)\n",
    "\n",
    "# Use CPRA_Peak_CAN as a predictor (add a constant for the intercept)\n",
    "X = sm.add_constant(df['CPRA_Peak_CAN'])\n",
    "y = df['missing_CPRA_Recent_CAN']\n",
    "\n",
    "# Fit logistic regression\n",
    "model = sm.Logit(y, X, missing='drop')  # drops rows with missing predictor values\n",
    "result = model.fit()\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eff5fdb-d401-40fd-986d-afa991769d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import miceforest as mf\n",
    "\n",
    "# Initialize the kernel\n",
    "kernel = mf.ImputationKernel(\n",
    "    df[['CPRA_Recent_CAN','CPRA_Peak_CAN']],\n",
    "    num_datasets=5,\n",
    "    save_all_iterations_data=True,\n",
    "    random_state=RANDOM_STATE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4dd91c1-5e13-4ca1-9b80-c9d78d6b0d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the MICE algorithm for 10 iterations\n",
    "kernel.mice(iterations=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3375410b-e5d9-4937-a3bd-31f8c1b1033e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.mixture import GaussianMixture\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Sample data: Replace with your actual dataset\n",
    "data = np.array([[1, 2], [2, 3], [3, 4], [8, 9], [9, 10], [10, 11]])\n",
    "\n",
    "# Initialize the GMM with the desired number of components\n",
    "gmm = GaussianMixture(n_components=2, random_state=42)\n",
    "\n",
    "# Fit the GMM to the data\n",
    "gmm.fit(data)\n",
    "\n",
    "# Predict the labels for each data point\n",
    "labels = gmm.predict(data)\n",
    "\n",
    "# Access the means and covariances of the components\n",
    "means = gmm.means_\n",
    "covariances = gmm.covariances_\n",
    "\n",
    "# Plotting the data points and the Gaussian components\n",
    "plt.scatter(data[:, 0], data[:, 1], c=labels, cmap='viridis')\n",
    "plt.scatter(means[:, 0], means[:, 1], c='red', marker='x', s=100, label='Means')\n",
    "plt.title('Gaussian Mixture Model Clustering')\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3c7651-9aaf-4a97-b841-d4716c9ce798",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.mixture import GaussianMixture\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Sample data: Replace with your actual dataset\n",
    "data = np.array([[1, 2], [2, 3], [3, 4], [8, 9], [9, 10], [10, 11]])\n",
    "\n",
    "# Initialize the GMM with the desired number of components\n",
    "gmm = GaussianMixture(n_components=2, random_state=42)\n",
    "\n",
    "# Fit the GMM to the data\n",
    "gmm.fit(data)\n",
    "\n",
    "# Predict the labels for each data point\n",
    "labels = gmm.predict(data)\n",
    "\n",
    "# Access the means and covariances of the components\n",
    "means = gmm.means_\n",
    "covariances = gmm.covariances_\n",
    "\n",
    "# Plotting the data points and the Gaussian components\n",
    "plt.scatter(data[:, 0], data[:, 1], c=labels, cmap='viridis')\n",
    "plt.scatter(means[:, 0], means[:, 1], c='red', marker='x', s=100, label='Means')\n",
    "plt.title('Gaussian Mixture Model Clustering')\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e012692-b945-4c1a-8aa1-a16fa7fbe0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Sample data: Replace with your actual dataset\n",
    "data = np.array([[0,1],[1, 2], [2, 3], [3, 4], [8, 9], [9, 10], [10, 11], [11,12], [12,13],[13,14],[14,15],[15,16],[16,17],[11,12]])\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test = train_test_split(data, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize lists to store AIC and BIC scores\n",
    "aic_scores = []\n",
    "bic_scores = []\n",
    "\n",
    "# Range of components to test\n",
    "n_components_range = range(1, 9)\n",
    "\n",
    "for n_components in n_components_range:\n",
    "    # Initialize the GMM\n",
    "    gmm = GaussianMixture(n_components=n_components, random_state=42)\n",
    "    \n",
    "    # Fit the GMM to the training data\n",
    "    gmm.fit(X_train)\n",
    "    \n",
    "    # Compute AIC and BIC\n",
    "    aic_scores.append(gmm.aic(X_train))\n",
    "    bic_scores.append(gmm.bic(X_train))\n",
    "\n",
    "# Plot AIC and BIC scores\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(n_components_range, aic_scores, label='AIC', marker='o')\n",
    "plt.plot(n_components_range, bic_scores, label='BIC', marker='o')\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('Score')\n",
    "plt.title('AIC and BIC Scores for Different Number of Components')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Select the optimal number of components based on the lowest BIC\n",
    "optimal_n_components = n_components_range[np.argmin(bic_scores)]\n",
    "print(f'Optimal number of components: {optimal_n_components}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a598625-1f05-4e4b-9965-28d83f69fb94",
   "metadata": {},
   "outputs": [],
   "source": [
    "bic_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c29829-b923-46c2-8071-ba533e6431b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "aic_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a0dde4-a53f-4255-8ed1-d2850a61e421",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38ac8fb-9feb-4958-8934-0cb0d12af68a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f3be08-a7de-4b90-8c11-163a2fbe2588",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample data\n",
    "data = pd.DataFrame([\n",
    "    [\"Unknown\", \"Unknown\"],\n",
    "    [\"Unknown\", \"Unknown\"],\n",
    "    [\"Unknown\", \"Unknown\"],\n",
    "    [\"Unknown\", \"Unknown\"],\n",
    "    [\"Unknown\", \"Unknown\"],\n",
    "    [\"Unknown\", \"Unknown\"],\n",
    "    [\"Unknown\", \"50% - Requires considerable assistance and frequent medical care\"],\n",
    "    [\"20% - Very sick, hospitalization necessary: active treatment necessary\", \"Unknown\"],\n",
    "    [\"Unknown\", \"Unknown\"],\n",
    "    [\"Unknown\", \"Unknown\"],\n",
    "    [\"20% - Very sick, hospitalization necessary: active treatment necessary\", \"50% - Very sick, hospitalization necessary: active treatment necessaryown\"],\n",
    "    [\"50% - Very sick, hospitalization necessary: active treatment necessary\", \"20% - Very sick, hospitalization necessary: active treatment necessaryown\"]\n",
    "], columns=['column1', 'column2'])\n",
    "\n",
    "# Print the DataFrame to verify\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4be8d5a-9bca-4931-b723-3df517f6ea54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to update unknown values\n",
    "def update_unknown(row):\n",
    "    if row['column1'] == 'Unknown' and row['column2'] != 'Unknown':\n",
    "        row['column1'] = row['column2']\n",
    "    elif row['column1'] != 'Unknown' and row['column2'] == 'Unknown':\n",
    "        row['column2'] = row['column1']\n",
    "    return row\n",
    "\n",
    "# Apply the function row-wise\n",
    "data = data.apply(update_unknown, axis=1)\n",
    "\n",
    "# Print the updated DataFrame\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b02fc3-9edf-45f3-83b9-0e9e7a4fa814",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.apply(update_unknown, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d809433b-07c2-42ba-80e4-fbb01092be4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5632be18-4726-4059-b0e4-82912a321670",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample DataFrame for demonstration\n",
    "data = {\n",
    "    'Feature1': [0, 1, 0, 1],\n",
    "    'Feature2': ['A', 'B', 'A', 'B'],\n",
    "    'Feature3': [1, 1, 0, 0],\n",
    "    'Feature4': ['Yes', 'No', 'Yes', 'No'],\n",
    "    'Feature5': ['Yes', 'No', 'Yes', 'Unknown']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Function to find binary category features\n",
    "def find_binary_category_features(df):\n",
    "    binary_features = []\n",
    "    for column in df.columns:\n",
    "        if df[column].nunique() == 2:\n",
    "            binary_features.append(column)\n",
    "    return binary_features\n",
    "\n",
    "binary_features = find_binary_category_features(df)\n",
    "\n",
    "print(f\"Binary category features in the DataFrame: {binary_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f23b9c-d858-4c7d-9f4f-9d525d10984d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RFSurvival",
   "language": "python",
   "name": "survival_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
