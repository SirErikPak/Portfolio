{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8373c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import package\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from timeit import default_timer as timer \n",
    "# \n",
    "path = '../Data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c7cc818",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(path + 'df_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b299ec38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    800000\n",
       "1    800000\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b16de4ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target           0\n",
       "ids              0\n",
       "tweet_date       0\n",
       "flag             0\n",
       "user             0\n",
       "text             0\n",
       "text_clean    8258\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking for nulls\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7518cc13",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f518d228",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    796361\n",
       "1    795381\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Label ONLY has Positive(1) or Negative(0) on the target field so, this exercise is a binary classification problem.\n",
    "df.target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91171c6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "      <th>text_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37213</th>\n",
       "      <td>0</td>\n",
       "      <td>@liesforliars damn dude! Yeah its hard enough for me to keep up with everybody with only about 25 ppl to follow, workin 2 jobs.</td>\n",
       "      <td>damn dud yeah hard enough keep everybody ppl follow workin job</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1584432</th>\n",
       "      <td>1</td>\n",
       "      <td>i`m wondering if @trohman `s pic is really him. the kiddie pic. coz i think it`s really adorable</td>\n",
       "      <td>wond pic real kiddy pic coz think real ad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1521965</th>\n",
       "      <td>1</td>\n",
       "      <td>@Epigrammist haha i know! i am looking into it</td>\n",
       "      <td>hah know look</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302711</th>\n",
       "      <td>0</td>\n",
       "      <td>@jimmyxc16 Pfft. You're dog does NOT beat my dog. My dog loves everyone, you're dog hates me</td>\n",
       "      <td>pfft dog not beat dog dog lov everyon dog hat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437645</th>\n",
       "      <td>0</td>\n",
       "      <td>Leaving new york today  Really don't want to leave my friends behind.</td>\n",
       "      <td>leav new york today real not want leav friend behind</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         target  \\\n",
       "37213    0        \n",
       "1584432  1        \n",
       "1521965  1        \n",
       "302711   0        \n",
       "437645   0        \n",
       "\n",
       "                                                                                                                                     text  \\\n",
       "37213    @liesforliars damn dude! Yeah its hard enough for me to keep up with everybody with only about 25 ppl to follow, workin 2 jobs.    \n",
       "1584432  i`m wondering if @trohman `s pic is really him. the kiddie pic. coz i think it`s really adorable                                   \n",
       "1521965  @Epigrammist haha i know! i am looking into it                                                                                     \n",
       "302711   @jimmyxc16 Pfft. You're dog does NOT beat my dog. My dog loves everyone, you're dog hates me                                       \n",
       "437645   Leaving new york today  Really don't want to leave my friends behind.                                                              \n",
       "\n",
       "                                                             text_clean  \n",
       "37213    damn dud yeah hard enough keep everybody ppl follow workin job  \n",
       "1584432  wond pic real kiddy pic coz think real ad                       \n",
       "1521965  hah know look                                                   \n",
       "302711   pfft dog not beat dog dog lov everyon dog hat                   \n",
       "437645   leav new york today real not want leav friend behind            "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option(\"display.max_colwidth\", 0)\n",
    "df[['target','text', 'text_clean']].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2bbfc7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "not      292036\n",
       "get      110917\n",
       "day      108276\n",
       "good     92504 \n",
       "work     88161 \n",
       "lik      84000 \n",
       "lov      83818 \n",
       "go       74000 \n",
       "quot     73139 \n",
       "today    68686 \n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(' '.join(df.text_clean).split()).value_counts()[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed89adc",
   "metadata": {},
   "source": [
    "#### User functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "41dda3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scoring_model(model, X_train, X_test, y_train, y_test, y_pred):\n",
    "    # Import\n",
    "    from sklearn.metrics import accuracy_score, auc, roc_auc_score, roc_curve\n",
    "    #\n",
    "    false_positive_rate, true_positive_rate, thresholds = roc_curve(y_train, \n",
    "                                                                    model.predict_proba(X_train)[:,1])\n",
    "    #\n",
    "    tr_score = model.score(X_train, y_train)\n",
    "    ts_score = model.score(X_test, y_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    auc = auc(false_positive_rate, true_positive_rate)\n",
    "    roc_tr = roc_auc_score(y_train, model.predict(X_train))\n",
    "    roc_t = roc_auc_score(y_test, model.predict(X_test))\n",
    "    return tr_score,ts_score,acc,auc,roc_tr,roc_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "244a3f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create empty DataFrame\n",
    "log = pd.DataFrame()\n",
    "# initial cm value\n",
    "cm_ = np.array([[0,0], [0,0]])\n",
    "# \n",
    "def logging_metrics(m, c, v, cm, training_score, \\\n",
    "                    test_score, auc_score, roc_auc_train, roc_auc_test, start, end):\n",
    "    \n",
    "    log_dict = {'Model': [],\n",
    "                'Classifier': [],\n",
    "                'Vectorizer': [],\n",
    "                'TP': [],\n",
    "                'FN': [],\n",
    "                'FP': [],\n",
    "                'TN': [],\n",
    "                'Training_Score': [],\n",
    "                'Test_Score': [],\n",
    "                'AUC_Score': [],\n",
    "                'ROC_AUC_Training': [],\n",
    "                'ROC_AUC_Test': [],\n",
    "                'Duration_Mins': []\n",
    "                }\n",
    "\n",
    "    log_dict['Model'].append(m)\n",
    "    log_dict['Classifier'].append(c)\n",
    "    log_dict['Vectorizer'].append(v)\n",
    "    log_dict['TP'].append(cm[0,0])\n",
    "    log_dict['FN'].append(cm[0,1])\n",
    "    log_dict['FP'].append(cm[1,0])\n",
    "    log_dict['TN'].append(cm[1,1])\n",
    "    log_dict['Training_Score'].append(training_score)\n",
    "    log_dict['Test_Score'].append(test_score)\n",
    "    log_dict['AUC_Score'].append(auc_score)\n",
    "    log_dict['ROC_AUC_Training'].append(roc_auc_train)\n",
    "    log_dict['ROC_AUC_Test'].append(roc_auc_test)\n",
    "    log_dict['ROC_AUC_Test'].append(roc_auc_test)\n",
    "    log_dict['Duration_Mins'].append((end - start)/60)\n",
    "    return log_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb272c5",
   "metadata": {},
   "source": [
    "## Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c2cca33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import library\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Getting tokenization of tweet text\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# \n",
    "t_size = 0.20\n",
    "seed = 11\n",
    "# \n",
    "\n",
    "# TfidfVectorizer: unigrams and bigrams\n",
    "parms_t = {'max_df' : 0.995,\n",
    "           'min_df': 0.001,\n",
    "           'ngram_range' : (1,2),\n",
    "          }\n",
    "# CountVectorizer\n",
    "parms_c = {'max_df' : 0.995,\n",
    "           'min_df': 0.001,\n",
    "           'ngram_range': (1,2),\n",
    "          }\n",
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055163b7",
   "metadata": {},
   "source": [
    "### Count Vectorizer with unigrams and bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b9cf601c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count Vectorizer shape:  (1591742, 1163)\n"
     ]
    }
   ],
   "source": [
    "start = timer()\n",
    "m, c, v = 'cv', 'unigrams and bigrams', 'Count Vectorizer'\n",
    "# incode Count Vectorizer\n",
    "cv = CountVectorizer(**parms_c)\n",
    "# \n",
    "X = cv.fit_transform(df.text_clean).toarray()\n",
    "y = df.target\n",
    "# \n",
    "X_train_c, X_test_c, y_train_c, y_test_c = train_test_split(X, y, test_size=t_size, random_state=seed)\n",
    "# \n",
    "print('Count Vectorizer shape: ', X.shape)\n",
    "# \n",
    "end = timer()\n",
    "# Log matrics\n",
    "log = log.append(pd.DataFrame.from_dict(logging_metrics(m, c, v, cm_, 0, 0, 0, 0, 0, start, end), \n",
    "                                        orient='index').transpose())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2316d38d",
   "metadata": {},
   "source": [
    "### Tfidf Vectorizer with unigrams and bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6c805ee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tfidf Vectorizer shape:  (1591742, 1163)\n"
     ]
    }
   ],
   "source": [
    "start = timer()\n",
    "m, c, v = 'tv', 'unigrams and bigrams', 'Tfidf Vectorizer'\n",
    "# incode Tfidf Vectorizer\n",
    "tv = TfidfVectorizer(**parms_t)\n",
    "# \n",
    "X_ = tv.fit_transform(df.text_clean).toarray()\n",
    "y_ = df.target\n",
    "# \n",
    "X_train_t, X_test_t, y_train_t, y_test_t = train_test_split(X_, y_, test_size=t_size, random_state=seed)\n",
    "# \n",
    "print('Tfidf Vectorizer shape: ', X_.shape, )\n",
    "# \n",
    "end = timer()\n",
    "# Log matrics\n",
    "log = log.append(pd.DataFrame.from_dict(logging_metrics(m, c, v, cm_, 0, 0, 0, 0, 0, start, end), \n",
    "                                        orient='index').transpose())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92198973",
   "metadata": {},
   "source": [
    "### Base Model Performance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fdcf8718",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count Base Score:  0.49988220475013273\n",
      "Tfidf Base Score:  0.5013240186085083\n"
     ]
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "# Count\n",
    "dummy_clf_c = DummyClassifier(strategy=\"stratified\")\n",
    "# \n",
    "dummy_clf_c.fit(X_train_c, y_train_c)\n",
    "# \n",
    "dummy_clf_c.predict(X_test_c)\n",
    "# Tfidf\n",
    "dummy_clf_f = DummyClassifier(strategy=\"stratified\")\n",
    "# \n",
    "dummy_clf_f.fit(X_train_t, y_train_t)\n",
    "# \n",
    "dummy_clf_f.predict(X_test_t)\n",
    "# \n",
    "print('Count Base Score: ', dummy_clf_c.score(X_test_c, y_test_c))\n",
    "print('Tfidf Base Score: ' ,dummy_clf_c.score(X_test_t, y_test_t))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db81d70b",
   "metadata": {},
   "source": [
    "### Binary Classification Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7a4982a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "# \n",
    "params_lrc = {'random_state' : seed,\n",
    "              'n_jobs' : (-1),\n",
    "              'multi_class' : 'ovr',\n",
    "             }\n",
    "# \n",
    "params_lgbm = {'objective': 'binary',\n",
    "               'metric': 'auc',\n",
    "               'n_jobs' : (-1),\n",
    "               'random_state' : seed,\n",
    "              }\n",
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b55681f",
   "metadata": {},
   "source": [
    "#### Logistic Regression with Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "71d8c946",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.6 s, sys: 22.2 s, total: 33.8 s\n",
      "Wall time: 4h 7min 53s\n",
      "\n",
      "\n",
      "[[115709  43692]\n",
      " [ 31126 127822]]\n",
      "\n",
      "\n",
      "Training set score:         0.7637846289\n",
      "Test set score:             0.7649811999\n",
      "Accuracy Test set Score:    0.7649811999\n",
      "AUC Score:                  0.8394390391\n",
      "ROC AUC Training set Score: 0.7638005041\n",
      "ROC AUC Test set Score:     0.7650368920\n"
     ]
    }
   ],
   "source": [
    "start = timer()\n",
    "m, c, v = 'lrc_c', 'Logistic Regression', 'Count Vectorizer'\n",
    "filename = model_path + 'LogisticRegression_counter.pkl'\n",
    "# \n",
    "# Logistic Regression\n",
    "lrc_c = LogisticRegression(**params_lrc)\n",
    "# \n",
    "%time lrc_c.fit(X_train_c, y_train_c)\n",
    "# Predict test results\n",
    "y_pred_ = lrc_c.predict(X_test_c)\n",
    "# \n",
    "print('\\n')\n",
    "cm = confusion_matrix(y_test_c, y_pred_)\n",
    "print(cm)\n",
    "print('\\n')\n",
    "# \n",
    "training_score,test_score,accuracy_score,auc_score,roc_auc_train,roc_auc_test = \\\n",
    "                    scoring_model(lrc_c, X_train_c, X_test_c, y_train_c, y_test_c, y_pred_)\n",
    "# print the scores on training and test set\n",
    "print('Training set score:         {:.10f}'.format(training_score))\n",
    "print('Test set score:             {:.10f}'.format(test_score))\n",
    "print('Accuracy Test set Score:    {:.10f}'.format(accuracy_score))\n",
    "print('AUC Score:                  {:.10f}'.format(auc_score))\n",
    "print('ROC AUC Training set Score: {:.10f}'.format(roc_auc_train))\n",
    "print('ROC AUC Test set Score:     {:.10f}'.format(roc_auc_test))\n",
    "# \n",
    "# save the model to disk\n",
    "pickle.dump(lrc_c, open(filename, 'wb'))\n",
    "# \n",
    "# load the model from disk\n",
    "# loaded_model = pickle.load(open(filename, 'rb'))\n",
    "# \n",
    "end = timer()\n",
    "# Log matrics \n",
    "log = log.append(pd.DataFrame.from_dict(logging_metrics(m, c, v, cm, training_score, test_score, \n",
    "                                            auc_score, roc_auc_train, roc_auc_test, start, end), \n",
    "                                        orient='index').transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1ab23c50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16.4 s, sys: 41.3 s, total: 57.8 s\n",
      "Wall time: 2h 30min 31s\n",
      "\n",
      "\n",
      "[[117805  41596]\n",
      " [ 33141 125807]]\n",
      "\n",
      "\n",
      "Training set score:         0.7646084123\n",
      "Test set score:             0.7652356376\n",
      "Accuracy Test set Score:    0.7652356376\n",
      "AUC Score:                  0.8447820997\n",
      "ROC AUC Training set Score: 0.7646191458\n",
      "ROC AUC Test set Score:     0.7652729548\n"
     ]
    }
   ],
   "source": [
    "start = timer()\n",
    "m, c, v = 'lrc_t', 'Logistic Regression', 'Tfidf Vectorizer'\n",
    "filename = model_path + 'LogisticRegression_Tfidf.pkl'\n",
    "# \n",
    "# Logistic Regression\n",
    "lrc_t = LogisticRegression(**params_lrc)\n",
    "# \n",
    "%time lrc_t.fit(X_train_t, y_train_t)\n",
    "# Predict test results\n",
    "y_pred_ = lrc_t.predict(X_test_t)\n",
    "# \n",
    "print('\\n')\n",
    "cm = confusion_matrix(y_test_t, y_pred_)\n",
    "print(cm)\n",
    "print('\\n')\n",
    "# \n",
    "training_score,test_score,accuracy_score,auc_score,roc_auc_train,roc_auc_test = \\\n",
    "                    scoring_model(lrc_t, X_train_t, X_test_t, y_train_t, y_test_t, y_pred_)\n",
    "# print the scores on training and test set\n",
    "print('Training set score:         {:.10f}'.format(training_score))\n",
    "print('Test set score:             {:.10f}'.format(test_score))\n",
    "print('Accuracy Test set Score:    {:.10f}'.format(accuracy_score))\n",
    "print('AUC Score:                  {:.10f}'.format(auc_score))\n",
    "print('ROC AUC Training set Score: {:.10f}'.format(roc_auc_train))\n",
    "print('ROC AUC Test set Score:     {:.10f}'.format(roc_auc_test))\n",
    "# \n",
    "# save the model to disk\n",
    "pickle.dump(lrc_c, open(filename, 'wb'))\n",
    "# \n",
    "# load the model from disk\n",
    "# loaded_model = pickle.load(open(filename, 'rb'))\n",
    "# \n",
    "end = timer()\n",
    "# Log matrics \n",
    "log = log.append(pd.DataFrame.from_dict(logging_metrics(m, c, v, cm, training_score, test_score, \n",
    "                                            auc_score, roc_auc_train, roc_auc_test, start, end), \n",
    "                                        orient='index').transpose())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950a15ca",
   "metadata": {},
   "source": [
    "#### Light GBM Classifier with Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5281e0e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 45s, sys: 9.13 s, total: 1min 54s\n",
      "Wall time: 19.9 s\n",
      "\n",
      "\n",
      "[[112406  46995]\n",
      " [ 32518 126430]]\n",
      "\n",
      "\n",
      "Training set score:         0.7494371337\n",
      "Test set score:             0.7502332346\n",
      "Accuracy Test set Score:    0.7502332346\n",
      "AUC Score:                  0.8298985699\n",
      "ROC AUC Training set Score: 0.7494558184\n",
      "ROC AUC Test set Score:     0.7502974387\n"
     ]
    }
   ],
   "source": [
    "start = timer()\n",
    "m, c, v = 'lgbm_c', 'LGBM Classifier', 'Count Vectorizer'\n",
    "filename = model_path + 'LGBMClassifier_counter.pkl'\n",
    "# \n",
    "# Light GBM Classifier \n",
    "lgbm_c = LGBMClassifier(**params_lgbm)\n",
    "# Train LGBM Classifier\n",
    "%time lgbm_c.fit(X_train_c, y_train_c)\n",
    "# Predict the response for test dataset\n",
    "y_pred_ = lgbm_c.predict(X_test_c)\n",
    "# \n",
    "print('\\n')\n",
    "cm = confusion_matrix(y_test_c, y_pred_)\n",
    "print(cm)\n",
    "print('\\n')\n",
    "# \n",
    "training_score,test_score,accuracy_score,auc_score,roc_auc_train,roc_auc_test = \\\n",
    "                    scoring_model(lgbm_c, X_train_c, X_test_c, y_train_c, y_test_c, y_pred_)\n",
    "# print the scores on training and test set\n",
    "print('Training set score:         {:.10f}'.format(training_score))\n",
    "print('Test set score:             {:.10f}'.format(test_score))\n",
    "print('Accuracy Test set Score:    {:.10f}'.format(accuracy_score))\n",
    "print('AUC Score:                  {:.10f}'.format(auc_score))\n",
    "print('ROC AUC Training set Score: {:.10f}'.format(roc_auc_train))\n",
    "print('ROC AUC Test set Score:     {:.10f}'.format(roc_auc_test))\n",
    "# \n",
    "# save model\n",
    "joblib.dump(lgbm_c, filename)\n",
    "# load model\n",
    "# gbm_pickle = joblib.load(filename)\n",
    "# \n",
    "end = timer()\n",
    "# Log matrics \n",
    "log = log.append(pd.DataFrame.from_dict(logging_metrics(m, c, v, cm, training_score, test_score, \n",
    "                                            auc_score, roc_auc_train, roc_auc_test, start, end), \n",
    "                                        orient='index').transpose())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ecf571",
   "metadata": {},
   "source": [
    "#### Light GBM Classifier with Tfidf Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "43ddd5b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5min 4s, sys: 10.7 s, total: 5min 15s\n",
      "Wall time: 22.8 s\n",
      "\n",
      "\n",
      "[[112899  46502]\n",
      " [ 32720 126228]]\n",
      "\n",
      "\n",
      "Training set score:         0.7510909829\n",
      "Test set score:             0.7511473257\n",
      "Accuracy Test set Score:    0.7511473257\n",
      "AUC Score:                  0.8319207025\n",
      "ROC AUC Training set Score: 0.7511088300\n",
      "ROC AUC Test set Score:     0.7512084252\n"
     ]
    }
   ],
   "source": [
    "start = timer()\n",
    "m, c, v = 'lgbm_t', 'LGBM Classifier', 'Tfidf Vectorizer'\n",
    "filename = model_path + 'LGBMClassifier_tfidf.pkl'\n",
    "# \n",
    "# LGBM Classifier\n",
    "lgbm_t = LGBMClassifier(**params_lgbm)\n",
    "# Train LGBM Classifier\n",
    "%time lgbm_t.fit(X_train_t, y_train_t)\n",
    "# Predict the response for test dataset\n",
    "y_pred_ = lgbm_t.predict(X_test_t)\n",
    "# \n",
    "print('\\n')\n",
    "cm = confusion_matrix(y_test_t, y_pred_)\n",
    "print(cm)\n",
    "print('\\n')\n",
    "# \n",
    "training_score,test_score,accuracy_score,auc_score,roc_auc_train,roc_auc_test = \\\n",
    "                    scoring_model(lgbm_t, X_train_t, X_test_t, y_train_t, y_test_t, y_pred_)\n",
    "# print the scores on training and test set\n",
    "print('Training set score:         {:.10f}'.format(training_score))\n",
    "print('Test set score:             {:.10f}'.format(test_score))\n",
    "print('Accuracy Test set Score:    {:.10f}'.format(accuracy_score))\n",
    "print('AUC Score:                  {:.10f}'.format(auc_score))\n",
    "print('ROC AUC Training set Score: {:.10f}'.format(roc_auc_train))\n",
    "print('ROC AUC Test set Score:     {:.10f}'.format(roc_auc_test))\n",
    "# \n",
    "# save model\n",
    "joblib.dump(lgbm_t, filename)\n",
    "# load model\n",
    "# gbm_pickle = joblib.load(model_path + 'LGBMClassifier_tfidf.pkl')\n",
    "# \n",
    "end = timer()\n",
    "# Log matrics \n",
    "log = log.append(pd.DataFrame.from_dict(logging_metrics(m, c, v, cm, training_score, test_score, \n",
    "                                            auc_score, roc_auc_train, roc_auc_test, start, end), \n",
    "                                        orient='index').transpose())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bda5519",
   "metadata": {},
   "source": [
    "## Bayesian Optimization:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4f4abf",
   "metadata": {},
   "source": [
    "#### Bayesian Optimization Tfidf Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2a6736be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | lambda_l1 | lambda_l2 | learni... | max_depth | min_ch... | min_da... | num_le... | subsam... |\n",
      "-------------------------------------------------------------------------------------------------------------------------\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=834, min_child_samples=2326 will be ignored. Current value: min_data_in_leaf=834\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.8487  \u001b[0m | \u001b[0m 0.02615 \u001b[0m | \u001b[0m 0.03264 \u001b[0m | \u001b[0m 0.5577  \u001b[0m | \u001b[0m 40.94   \u001b[0m | \u001b[0m 2.327e+0\u001b[0m | \u001b[0m 834.8   \u001b[0m | \u001b[0m 3.034e+0\u001b[0m | \u001b[0m 6.38    \u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m 0.8372  \u001b[0m | \u001b[0m 0.03934 \u001b[0m | \u001b[0m 0.04851 \u001b[0m | \u001b[0m 1.04    \u001b[0m | \u001b[0m 47.17   \u001b[0m | \u001b[0m 4.113e+0\u001b[0m | \u001b[0m 1.628e+0\u001b[0m | \u001b[0m 1.833e+0\u001b[0m | \u001b[0m 9.224   \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m 0.8348  \u001b[0m | \u001b[0m 0.01977 \u001b[0m | \u001b[0m 0.01642 \u001b[0m | \u001b[0m 1.284   \u001b[0m | \u001b[0m 57.26   \u001b[0m | \u001b[0m 8.875e+0\u001b[0m | \u001b[0m 1.376e+0\u001b[0m | \u001b[0m 3.64e+03\u001b[0m | \u001b[0m 9.401   \u001b[0m |\n",
      "| \u001b[95m 4       \u001b[0m | \u001b[95m 0.8526  \u001b[0m | \u001b[95m 0.01326 \u001b[0m | \u001b[95m 0.04848 \u001b[0m | \u001b[95m 0.1248  \u001b[0m | \u001b[95m 40.8    \u001b[0m | \u001b[95m 2.824e+0\u001b[0m | \u001b[95m 301.0   \u001b[0m | \u001b[95m 2.477e+0\u001b[0m | \u001b[95m 4.174   \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.8495  \u001b[0m | \u001b[0m 0.03335 \u001b[0m | \u001b[0m 0.04951 \u001b[0m | \u001b[0m 0.5412  \u001b[0m | \u001b[0m 34.38   \u001b[0m | \u001b[0m 763.5   \u001b[0m | \u001b[0m 107.1   \u001b[0m | \u001b[0m 2.634e+0\u001b[0m | \u001b[0m 9.261   \u001b[0m |\n",
      "| \u001b[95m 6       \u001b[0m | \u001b[95m 0.8541  \u001b[0m | \u001b[95m 0.04063 \u001b[0m | \u001b[95m 0.01571 \u001b[0m | \u001b[95m 0.1224  \u001b[0m | \u001b[95m 14.94   \u001b[0m | \u001b[95m 1.971e+0\u001b[0m | \u001b[95m 128.7   \u001b[0m | \u001b[95m 1.614e+0\u001b[0m | \u001b[95m 3.523   \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.8526  \u001b[0m | \u001b[0m 0.04998 \u001b[0m | \u001b[0m 0.02684 \u001b[0m | \u001b[0m 0.3057  \u001b[0m | \u001b[0m 34.93   \u001b[0m | \u001b[0m 150.9   \u001b[0m | \u001b[0m 276.9   \u001b[0m | \u001b[0m 63.08   \u001b[0m | \u001b[0m 7.515   \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.8327  \u001b[0m | \u001b[0m 0.03549 \u001b[0m | \u001b[0m 0.04948 \u001b[0m | \u001b[0m 1.265   \u001b[0m | \u001b[0m 35.17   \u001b[0m | \u001b[0m 3.027e+0\u001b[0m | \u001b[0m 1.788e+0\u001b[0m | \u001b[0m 3.235e+0\u001b[0m | \u001b[0m 6.206   \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.8469  \u001b[0m | \u001b[0m 0.04974 \u001b[0m | \u001b[0m 0.002262\u001b[0m | \u001b[0m 0.6745  \u001b[0m | \u001b[0m 58.39   \u001b[0m | \u001b[0m 8.141e+0\u001b[0m | \u001b[0m 605.9   \u001b[0m | \u001b[0m 2.207e+0\u001b[0m | \u001b[0m 8.411   \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m 0.8491  \u001b[0m | \u001b[0m 0.0409  \u001b[0m | \u001b[0m 0.02935 \u001b[0m | \u001b[0m 0.7065  \u001b[0m | \u001b[0m 5.823   \u001b[0m | \u001b[0m 795.0   \u001b[0m | \u001b[0m 495.7   \u001b[0m | \u001b[0m 3.321e+0\u001b[0m | \u001b[0m 6.733   \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m 0.8448  \u001b[0m | \u001b[0m 0.008886\u001b[0m | \u001b[0m 0.02443 \u001b[0m | \u001b[0m 1.142   \u001b[0m | \u001b[0m 52.05   \u001b[0m | \u001b[0m 1.775e+0\u001b[0m | \u001b[0m 156.6   \u001b[0m | \u001b[0m 26.38   \u001b[0m | \u001b[0m 1.364   \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m 0.8285  \u001b[0m | \u001b[0m 0.01993 \u001b[0m | \u001b[0m 0.009751\u001b[0m | \u001b[0m 1.558   \u001b[0m | \u001b[0m 60.56   \u001b[0m | \u001b[0m 9.246e+0\u001b[0m | \u001b[0m 368.7   \u001b[0m | \u001b[0m 2.778e+0\u001b[0m | \u001b[0m 8.752   \u001b[0m |\n",
      "=========================================================================================================================\n",
      "CPU times: user 9h 44min 25s, sys: 9h 38min 21s, total: 19h 22min 46s\n",
      "Wall time: 1h 16min 52s\n"
     ]
    }
   ],
   "source": [
    "start = timer()\n",
    "m, c, v = 'lgbBO', 'Bayesian Optimization', 'Tfidf Vectorizer'\n",
    "# import\n",
    "from bayes_opt import BayesianOptimization\n",
    "import lightgbm\n",
    "# \n",
    "# categorical_features = ['text_clean']\n",
    "# \n",
    "def lgb_eval(num_leaves, max_depth, lambda_l2, lambda_l1, min_child_samples, min_data_in_leaf, \\\n",
    "             learning_rate,subsample_freq):\n",
    "    params = {\n",
    "        \"objective\" : \"binary\",\n",
    "        \"metric\" : \"auc\", \n",
    "        'is_unbalance': True,\n",
    "        \"num_leaves\" : int(num_leaves),\n",
    "        \"max_depth\" : int(max_depth),\n",
    "        \"lambda_l2\" : lambda_l2,\n",
    "        \"lambda_l1\" : lambda_l1,\n",
    "        \"num_threads\" : 20,\n",
    "        \"min_child_samples\" : int(min_child_samples),\n",
    "        'min_data_in_leaf': int(min_data_in_leaf),\n",
    "        \"learning_rate\" : learning_rate,\n",
    "        \"subsample_freq\" : int(subsample_freq),\n",
    "        \"bagging_seed\" : seed,\n",
    "        \"verbosity\" : -1\n",
    "    }\n",
    "    # lgtrain = lightgbm.Dataset(X_train, y_train,categorical_feature=categorical_features)\n",
    "    lgtrain = lightgbm.Dataset(X_train_t, y_train_t)\n",
    "    cv_result = lightgbm.cv(params,\n",
    "                       lgtrain,\n",
    "                       1000,\n",
    "                       early_stopping_rounds=100,\n",
    "                       stratified=True,\n",
    "                       nfold=5)\n",
    "    return cv_result['auc-mean'][-1]\n",
    "# \n",
    "lgbBO = BayesianOptimization(lgb_eval, {'num_leaves': (25, 4000),\n",
    "                                        'max_depth': (5, 63),\n",
    "                                        'lambda_l2': (0.0, 0.05),\n",
    "                                        'lambda_l1': (0.0, 0.05),\n",
    "                                        'min_child_samples': (50, 10000),\n",
    "                                        'min_data_in_leaf': (100, 2000),\n",
    "                                        'learning_rate': (0.001, 2.0),\n",
    "                                        'subsample_freq': (1, 10),\n",
    "                                        })\n",
    "\n",
    "%time lgbBO.maximize(n_iter=10, init_points=2)\n",
    "# \n",
    "end = timer()\n",
    "# Log matrics\n",
    "log = log.append(pd.DataFrame.from_dict(logging_metrics(m, c, v, cm_, 0, 0, 0, 0, 0, start, end), \n",
    "                                        orient='index').transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d7f37ff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 25s, sys: 2min 58s, total: 7min 23s\n",
      "Wall time: 29.4 s\n",
      "\n",
      "\n",
      "[[110369  49032]\n",
      " [ 29867 129081]]\n",
      "\n",
      "\n",
      "Training set score:         0.7554337114\n",
      "Test set score:             0.7521619355\n",
      "Accuracy Test set Score:    0.7521619355\n",
      "AUC Score:                  0.8377152912\n",
      "ROC AUC Training set Score: 0.7554585357\n",
      "ROC AUC Test set Score:     0.7522470982\n"
     ]
    }
   ],
   "source": [
    "start = timer()\n",
    "m, c, v = 'lgbm_BO_t', 'LGBM Classifier - Bayesian Optimization', 'Tfidf Vectorizer'\n",
    "filename = model_path + 'LGBMClassifier_BO_tfidf.pkl'\n",
    "# \n",
    "# Capture Best Bayesian Optimization Values\n",
    "params_BO = lgbBO.max\n",
    "params_BO = params_BO['params']\n",
    "# Round to INT keys\n",
    "info = ['max_depth','min_child_samples', 'min_data_in_leaf', 'num_leaves', 'subsample_freq']\n",
    "# \n",
    "params_ = {'objective': 'binary',\n",
    "           'metric': 'auc',\n",
    "           'n_jobs' : (-1),\n",
    "           'random_state' : seed,\n",
    "           'verbosity': (-1),\n",
    "          }\n",
    "# merge dictionaries in one line by simply using the unpacking operator (**)\n",
    "params_BO = {**params_, **params_BO,}\n",
    "# \n",
    "for k, v in params_BO.items():\n",
    "    if k in info:\n",
    "        params_BO[k] = int(v) \n",
    "# \n",
    "# LGBM Classifier\n",
    "lgbm_BO_t = LGBMClassifier(**params_BO)\n",
    "# Train LGBM Classifier\n",
    "%time lgbm_BO_t.fit(X_train_t, y_train_t)\n",
    "# Predict the response for test dataset\n",
    "y_pred_ = lgbm_BO_t.predict(X_test_t)\n",
    "# \n",
    "print('\\n')\n",
    "cm = confusion_matrix(y_test_t, y_pred_)\n",
    "print(cm)\n",
    "print('\\n')\n",
    "# \n",
    "training_score,test_score,accuracy_score,auc_score,roc_auc_train,roc_auc_test = \\\n",
    "                    scoring_model(lgbm_BO_t, X_train_t, X_test_t, y_train_t, y_test_t, y_pred_)\n",
    "# print the scores on training and test set\n",
    "print('Training set score:         {:.10f}'.format(training_score))\n",
    "print('Test set score:             {:.10f}'.format(test_score))\n",
    "print('Accuracy Test set Score:    {:.10f}'.format(accuracy_score))\n",
    "print('AUC Score:                  {:.10f}'.format(auc_score))\n",
    "print('ROC AUC Training set Score: {:.10f}'.format(roc_auc_train))\n",
    "print('ROC AUC Test set Score:     {:.10f}'.format(roc_auc_test))\n",
    "# \n",
    "# save model\n",
    "joblib.dump(lgbm_BO_t, filename)\n",
    "# load model\n",
    "# gbm_pickle = joblib.load(filename)\n",
    "# \n",
    "end = timer()\n",
    "# Log matrics \n",
    "log = log.append(pd.DataFrame.from_dict(logging_metrics(m, c, v, cm, training_score, test_score, \n",
    "                                            auc_score, roc_auc_train, roc_auc_test, start, end), \n",
    "                                        orient='index').transpose())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8e3f46",
   "metadata": {},
   "source": [
    "#### Bayesian Optimization Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f208bded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | lambda_l1 | lambda_l2 | learni... | max_depth | min_ch... | min_da... | num_le... | subsam... |\n",
      "-------------------------------------------------------------------------------------------------------------------------\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=301, min_child_samples=6017 will be ignored. Current value: min_data_in_leaf=301\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.8349  \u001b[0m | \u001b[0m 0.03221 \u001b[0m | \u001b[0m 0.04983 \u001b[0m | \u001b[0m 1.532   \u001b[0m | \u001b[0m 61.43   \u001b[0m | \u001b[0m 6.017e+0\u001b[0m | \u001b[0m 301.5   \u001b[0m | \u001b[0m 2.219e+0\u001b[0m | \u001b[0m 9.812   \u001b[0m |\n",
      "| \u001b[95m 2       \u001b[0m | \u001b[95m 0.8443  \u001b[0m | \u001b[95m 0.01106 \u001b[0m | \u001b[95m 0.04557 \u001b[0m | \u001b[95m 1.349   \u001b[0m | \u001b[95m 34.5    \u001b[0m | \u001b[95m 8.324e+0\u001b[0m | \u001b[95m 489.5   \u001b[0m | \u001b[95m 1.768e+0\u001b[0m | \u001b[95m 5.909   \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m 0.8277  \u001b[0m | \u001b[0m 0.02556 \u001b[0m | \u001b[0m 0.000415\u001b[0m | \u001b[0m 1.719   \u001b[0m | \u001b[0m 16.4    \u001b[0m | \u001b[0m 78.76   \u001b[0m | \u001b[0m 1.437e+0\u001b[0m | \u001b[0m 430.7   \u001b[0m | \u001b[0m 4.749   \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.8429  \u001b[0m | \u001b[0m 0.03596 \u001b[0m | \u001b[0m 0.02712 \u001b[0m | \u001b[0m 0.02196 \u001b[0m | \u001b[0m 28.45   \u001b[0m | \u001b[0m 2.76e+03\u001b[0m | \u001b[0m 802.6   \u001b[0m | \u001b[0m 3.746e+0\u001b[0m | \u001b[0m 3.483   \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.7784  \u001b[0m | \u001b[0m 0.04171 \u001b[0m | \u001b[0m 0.03641 \u001b[0m | \u001b[0m 1.884   \u001b[0m | \u001b[0m 44.77   \u001b[0m | \u001b[0m 6.816e+0\u001b[0m | \u001b[0m 184.5   \u001b[0m | \u001b[0m 3.744e+0\u001b[0m | \u001b[0m 7.989   \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.8422  \u001b[0m | \u001b[0m 0.002113\u001b[0m | \u001b[0m 0.04431 \u001b[0m | \u001b[0m 0.0476  \u001b[0m | \u001b[0m 13.45   \u001b[0m | \u001b[0m 7.369e+0\u001b[0m | \u001b[0m 900.4   \u001b[0m | \u001b[0m 1.379e+0\u001b[0m | \u001b[0m 8.229   \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.7604  \u001b[0m | \u001b[0m 0.01824 \u001b[0m | \u001b[0m 0.03246 \u001b[0m | \u001b[0m 1.833   \u001b[0m | \u001b[0m 13.04   \u001b[0m | \u001b[0m 8.293e+0\u001b[0m | \u001b[0m 518.6   \u001b[0m | \u001b[0m 1.693e+0\u001b[0m | \u001b[0m 3.884   \u001b[0m |\n",
      "| \u001b[95m 8       \u001b[0m | \u001b[95m 0.8461  \u001b[0m | \u001b[95m 0.0138  \u001b[0m | \u001b[95m 0.03565 \u001b[0m | \u001b[95m 1.37    \u001b[0m | \u001b[95m 6.151   \u001b[0m | \u001b[95m 2.354e+0\u001b[0m | \u001b[95m 647.0   \u001b[0m | \u001b[95m 3.787e+0\u001b[0m | \u001b[95m 5.777   \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.8455  \u001b[0m | \u001b[0m 0.03203 \u001b[0m | \u001b[0m 0.01086 \u001b[0m | \u001b[0m 1.459   \u001b[0m | \u001b[0m 12.84   \u001b[0m | \u001b[0m 8.032e+0\u001b[0m | \u001b[0m 972.2   \u001b[0m | \u001b[0m 3.664e+0\u001b[0m | \u001b[0m 3.979   \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m 0.8407  \u001b[0m | \u001b[0m 0.004426\u001b[0m | \u001b[0m 0.0349  \u001b[0m | \u001b[0m 0.4312  \u001b[0m | \u001b[0m 25.44   \u001b[0m | \u001b[0m 7.458e+0\u001b[0m | \u001b[0m 1.75e+03\u001b[0m | \u001b[0m 3.6e+03 \u001b[0m | \u001b[0m 3.852   \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m 0.8453  \u001b[0m | \u001b[0m 0.02835 \u001b[0m | \u001b[0m 0.02099 \u001b[0m | \u001b[0m 0.1527  \u001b[0m | \u001b[0m 26.24   \u001b[0m | \u001b[0m 9.445e+0\u001b[0m | \u001b[0m 1.234e+0\u001b[0m | \u001b[0m 2.429e+0\u001b[0m | \u001b[0m 9.232   \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m 0.8316  \u001b[0m | \u001b[0m 0.03442 \u001b[0m | \u001b[0m 0.04381 \u001b[0m | \u001b[0m 1.583   \u001b[0m | \u001b[0m 12.18   \u001b[0m | \u001b[0m 8.495e+0\u001b[0m | \u001b[0m 1.961e+0\u001b[0m | \u001b[0m 3.332e+0\u001b[0m | \u001b[0m 3.722   \u001b[0m |\n",
      "=========================================================================================================================\n",
      "CPU times: user 5h 16min 10s, sys: 5h 42min 3s, total: 10h 58min 14s\n",
      "Wall time: 1h 30min 25s\n"
     ]
    }
   ],
   "source": [
    "start = timer()\n",
    "m, c, v = 'lgbBO_c', 'Bayesian Optimization', 'Count Vectorizer'\n",
    "# \n",
    "def lgb_eval_c(num_leaves, max_depth, lambda_l2, lambda_l1, min_child_samples, min_data_in_leaf, \\\n",
    "               learning_rate, subsample_freq):\n",
    "    params = {\n",
    "        \"objective\" : \"binary\",\n",
    "        \"metric\" : \"auc\", \n",
    "        'is_unbalance': True,\n",
    "        \"num_leaves\" : int(num_leaves),\n",
    "        \"max_depth\" : int(max_depth),\n",
    "        \"lambda_l2\" : lambda_l2,\n",
    "        \"lambda_l1\" : lambda_l1,\n",
    "        \"num_threads\" : 20,\n",
    "        \"min_child_samples\" : int(min_child_samples),\n",
    "        'min_data_in_leaf': int(min_data_in_leaf),\n",
    "        \"learning_rate\" : learning_rate,\n",
    "        \"subsample_freq\" : int(subsample_freq),\n",
    "        \"bagging_seed\" : seed,\n",
    "        \"verbosity\" : -1\n",
    "    }\n",
    "#     lgtrain = lightgbm.Dataset(X_train, y_train,categorical_feature=categorical_features)\n",
    "    lgtrain_c = lightgbm.Dataset(X_train_c, y_train_c)\n",
    "    cv_result = lightgbm.cv(params,\n",
    "                       lgtrain_c,\n",
    "                       1000,\n",
    "                       early_stopping_rounds=100,\n",
    "                       stratified=True,\n",
    "                       nfold=5)\n",
    "    return cv_result['auc-mean'][-1]\n",
    "# \n",
    "lgbBO_c = BayesianOptimization(lgb_eval_c, {'num_leaves': (25, 4000),\n",
    "                                        'max_depth': (5, 63),\n",
    "                                        'lambda_l2': (0.0, 0.05),\n",
    "                                        'lambda_l1': (0.0, 0.05),\n",
    "                                        'min_child_samples': (50, 10000),\n",
    "                                        'min_data_in_leaf': (100, 2000),\n",
    "                                        'learning_rate': (0.001, 2.0),\n",
    "                                        'subsample_freq': (1, 10),\n",
    "                                        })\n",
    "\n",
    "%time lgbBO_c.maximize(n_iter=10, init_points=2)\n",
    "# \n",
    "end = timer()\n",
    "# Log matrics\n",
    "log = log.append(pd.DataFrame.from_dict(logging_metrics(m, c, v, cm_, 0, 0, 0, 0, 0, start, end), \n",
    "                                        orient='index').transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b3d96208",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 31s, sys: 22.2 s, total: 1min 53s\n",
      "Wall time: 11.1 s\n",
      "\n",
      "\n",
      "[[117188  42213]\n",
      " [ 32999 125949]]\n",
      "\n",
      "\n",
      "Training set score:         0.7632655433\n",
      "Test set score:             0.7637435645\n",
      "Accuracy Test set Score:    0.7637435645\n",
      "AUC Score:                  0.8393701921\n",
      "ROC AUC Training set Score: 0.7632774680\n",
      "ROC AUC Test set Score:     0.7637842712\n"
     ]
    }
   ],
   "source": [
    "start = timer()\n",
    "m, c, v = 'lgbm_BO_c', 'LGBM Classifier - Bayesian Optimization', 'Count Vectorizer'\n",
    "filename = model_path + 'LGBMClassifier_BO_counter.pkl'\n",
    "# \n",
    "# Capture Best Bayesian Optimization Values\n",
    "params_BO_c = lgbBO_c.max\n",
    "params_BO_c = params_BO_c['params']\n",
    "# Round to INT keys\n",
    "info = ['max_depth','min_child_samples', 'min_data_in_leaf', 'num_leaves', 'subsample_freq']\n",
    "# \n",
    "params_ = {'objective': 'binary',\n",
    "           'metric': 'auc',\n",
    "           'n_jobs' : (-1),\n",
    "           'random_state' : seed,\n",
    "           'verbosity': (-1),\n",
    "          }\n",
    "# merge dictionaries in one line by simply using the unpacking operator (**)\n",
    "params_BO_c = {**params_, **params_BO_c,}\n",
    "# \n",
    "for k, v in params_BO_c.items():\n",
    "    if k in info:\n",
    "        params_BO_c[k] = int(v) \n",
    "# \n",
    "# LGBM Classifier\n",
    "lgbm_BO_c = LGBMClassifier(**params_BO_c)\n",
    "# Train LGBM Classifier\n",
    "%time lgbm_BO_c.fit(X_train_c, y_train_c)\n",
    "# Predict the response for test dataset\n",
    "y_pred_ = lgbm_BO_c.predict(X_test_c)\n",
    "# \n",
    "print('\\n')\n",
    "cm = confusion_matrix(y_test_c, y_pred_)\n",
    "print(cm)\n",
    "print('\\n')\n",
    "# \n",
    "training_score,test_score,accuracy_score,auc_score,roc_auc_train,roc_auc_test = \\\n",
    "                    scoring_model(lgbm_BO_c, X_train_c, X_test_c, y_train_c, y_test_c, y_pred_)\n",
    "# print the scores on training and test set\n",
    "print('Training set score:         {:.10f}'.format(training_score))\n",
    "print('Test set score:             {:.10f}'.format(test_score))\n",
    "print('Accuracy Test set Score:    {:.10f}'.format(accuracy_score))\n",
    "print('AUC Score:                  {:.10f}'.format(auc_score))\n",
    "print('ROC AUC Training set Score: {:.10f}'.format(roc_auc_train))\n",
    "print('ROC AUC Test set Score:     {:.10f}'.format(roc_auc_test))\n",
    "# \n",
    "# save model\n",
    "joblib.dump(lgbm_BO_c,filename)\n",
    "# load model\n",
    "# gbm_pickle = joblib.load(filename)\n",
    "# \n",
    "end = timer()\n",
    "# Log matrics \n",
    "log = log.append(pd.DataFrame.from_dict(logging_metrics(m, c, v, cm, training_score, test_score, \n",
    "                                            auc_score, roc_auc_train, roc_auc_test, start, end), \n",
    "                                        orient='index').transpose())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd0497c",
   "metadata": {},
   "source": [
    "### Neural Network with Tfidf Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "28cb2049",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "# \n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import keras_tuner as kt\n",
    "# \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac25cec7",
   "metadata": {},
   "source": [
    "#### Tuning hidden layer & learning rate for keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c11e0d2f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 30 Complete [00h 05m 22s]\n",
      "val_accuracy: 0.7528928518295288\n",
      "\n",
      "Best val_accuracy So Far: 0.7759571671485901\n",
      "Total elapsed time: 01h 08m 27s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "start = timer()\n",
    "m, c, v = 'lgbBO', 'Keras Tuning', 'Tfidf Vectorizer'\n",
    "features = X_train_t.shape[1]\n",
    "# \n",
    "def model_builder(hp):\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Flatten(input_shape=(features,1)))\n",
    "\n",
    "    # Tune the number of units in the first Dense layer\n",
    "    # Choose an optimal value between 32-512\n",
    "    hp_units = hp.Int('units', min_value=32, max_value=512, step=32)\n",
    "    model.add(keras.layers.Dense(units=hp_units, activation='relu'))\n",
    "    model.add(keras.layers.Dense(10))\n",
    "\n",
    "    # Tune the learning rate for the optimizer\n",
    "    # Choose an optimal value from 0.5, 0.1, 0.01, 0.001, or 0.00011\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[5e-1, 1e-1, 1e-2, 1e-3, 1e-4])\n",
    "\n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
    "                loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True), \n",
    "                metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "# \n",
    "tuner = kt.Hyperband(model_builder,\n",
    "                     objective='val_accuracy',\n",
    "                     max_epochs=10,\n",
    "                     factor=3,\n",
    "                     directory='tmp',\n",
    "                     project_name='keras_tuning')\n",
    "# \n",
    "# Create a callback to stop training early after reaching a certain value for the validation loss.\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "# \n",
    "tuner.search(X_train_t, y_train_t, epochs=50, validation_split=0.2, callbacks=[stop_early])\n",
    "\n",
    "# Get the optimal hyperparameters\n",
    "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "# \n",
    "layer = (best_hps.get('units'))\n",
    "learning_rate = (best_hps.get('learning_rate'))\n",
    "# \n",
    "end = timer()\n",
    "# Log matrics\n",
    "log = log.append(pd.DataFrame.from_dict(logging_metrics(m, c, v, cm_, 0, 0, 0, 0, 0, start, end), \n",
    "                                        orient='index').transpose())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747c8033",
   "metadata": {},
   "source": [
    "#### Keras Classifier with Tfidf (_k_) & Counter (_c_) Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9d4e4518",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "101872/101872 [==============================] - 112s 1ms/step - loss: 0.4900 - accuracy: 0.7627 - val_loss: 0.4815 - val_accuracy: 0.7665\n",
      "Epoch 2/15\n",
      "101872/101872 [==============================] - 111s 1ms/step - loss: 0.4774 - accuracy: 0.7703 - val_loss: 0.4778 - val_accuracy: 0.7695\n",
      "Epoch 3/15\n",
      "101872/101872 [==============================] - 112s 1ms/step - loss: 0.4730 - accuracy: 0.7741 - val_loss: 0.4756 - val_accuracy: 0.7715\n",
      "Epoch 4/15\n",
      "101872/101872 [==============================] - 112s 1ms/step - loss: 0.4689 - accuracy: 0.7772 - val_loss: 0.4733 - val_accuracy: 0.7731\n",
      "Epoch 5/15\n",
      "101872/101872 [==============================] - 112s 1ms/step - loss: 0.4653 - accuracy: 0.7797 - val_loss: 0.4717 - val_accuracy: 0.7741\n",
      "Epoch 6/15\n",
      "101872/101872 [==============================] - 112s 1ms/step - loss: 0.4621 - accuracy: 0.7819 - val_loss: 0.4711 - val_accuracy: 0.7746\n",
      "Epoch 7/15\n",
      "101872/101872 [==============================] - 111s 1ms/step - loss: 0.4591 - accuracy: 0.7839 - val_loss: 0.4702 - val_accuracy: 0.7753\n",
      "Epoch 8/15\n",
      "101872/101872 [==============================] - 112s 1ms/step - loss: 0.4564 - accuracy: 0.7860 - val_loss: 0.4699 - val_accuracy: 0.7759\n",
      "Epoch 9/15\n",
      "101872/101872 [==============================] - 112s 1ms/step - loss: 0.4539 - accuracy: 0.7879 - val_loss: 0.4696 - val_accuracy: 0.7763\n",
      "Epoch 10/15\n",
      "101872/101872 [==============================] - 111s 1ms/step - loss: 0.4515 - accuracy: 0.7894 - val_loss: 0.4695 - val_accuracy: 0.7767\n",
      "Epoch 11/15\n",
      "101872/101872 [==============================] - 112s 1ms/step - loss: 0.4492 - accuracy: 0.7912 - val_loss: 0.4696 - val_accuracy: 0.7771\n",
      "Epoch 12/15\n",
      "101872/101872 [==============================] - 112s 1ms/step - loss: 0.4467 - accuracy: 0.7927 - val_loss: 0.4698 - val_accuracy: 0.7777\n",
      "Epoch 13/15\n",
      "101872/101872 [==============================] - 112s 1ms/step - loss: 0.4440 - accuracy: 0.7947 - val_loss: 0.4706 - val_accuracy: 0.7775\n",
      "Epoch 14/15\n",
      "101872/101872 [==============================] - 112s 1ms/step - loss: 0.4414 - accuracy: 0.7965 - val_loss: 0.4709 - val_accuracy: 0.7776\n",
      "Epoch 15/15\n",
      "101872/101872 [==============================] - 112s 1ms/step - loss: 0.4387 - accuracy: 0.7981 - val_loss: 0.4713 - val_accuracy: 0.7776\n",
      "CPU times: user 1h 31min 46s, sys: 17min 19s, total: 1h 49min 5s\n",
      "Wall time: 27min 58s\n",
      "[[122055  37346]\n",
      " [ 32828 126120]]\n",
      "\n",
      "\n",
      "39794/39794 [==============================] - 24s 593us/step - loss: 0.4403 - accuracy: 0.7971\n",
      "9949/9949 [==============================] - 6s 590us/step - loss: 0.4693 - accuracy: 0.7796\n",
      "Training set score:         0.7971372604\n",
      "Test set score:             0.7795689702\n",
      "Accuracy Test set Score:    0.7795689636\n",
      "AUC Score:                  0.8779329158\n",
      "ROC AUC Training set Score: 0.7971425082\n",
      "ROC AUC Test set Score:     0.7795887120\n"
     ]
    }
   ],
   "source": [
    "start = timer()\n",
    "m, c, v = 'model_k_', 'Keras Classifier Layer: ' + str(layer), 'Tfidf Vectorizer'\n",
    "# \n",
    "filename = model_path + 'KerasClassifier_tfidf_model_k_.h5'\n",
    "# Function to create model, required for KerasClassifier\n",
    "def create_model_(optimizer='adam', init='glorot_uniform'):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(layer, input_dim=features, activation='relu', kernel_initializer=init))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    opt = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "    return model\n",
    "# \n",
    "# create model\n",
    "model_k_ = KerasClassifier(build_fn=create_model_, verbose=1)\n",
    "\n",
    "%time model_k_.fit(X_train_t, y_train_t, validation_split=0.20, epochs=15, batch_size=10)\n",
    "# %time model_k_.fit(X_train_t, y_train_t)\n",
    "# \n",
    "y_pred_ = model_k_.predict(X_test_t)\n",
    "# \n",
    "cm = confusion_matrix(y_test_t, y_pred_)\n",
    "print(cm)\n",
    "print('\\n')\n",
    "# \n",
    "training_score,test_score,accuracy_score,auc_score,roc_auc_train,roc_auc_test = \\\n",
    "                    scoring_model(model_k_, X_train_t, X_test_t, y_train_t, y_test_t, y_pred_)\n",
    "# print the scores on training and test set\n",
    "print('Training set score:         {:.10f}'.format(training_score))\n",
    "print('Test set score:             {:.10f}'.format(test_score))\n",
    "print('Accuracy Test set Score:    {:.10f}'.format(accuracy_score))\n",
    "print('AUC Score:                  {:.10f}'.format(auc_score))\n",
    "print('ROC AUC Training set Score: {:.10f}'.format(roc_auc_train))\n",
    "print('ROC AUC Test set Score:     {:.10f}'.format(roc_auc_test))\n",
    "# \n",
    "model_k_.model.save(filename)\n",
    "# \n",
    "# new_model = keras.models.load_model(filename)\n",
    "# \n",
    "end = timer()\n",
    "# Log matrics \n",
    "log = log.append(pd.DataFrame.from_dict(logging_metrics(m, c, v, cm, training_score, test_score, \n",
    "                                            auc_score, roc_auc_train, roc_auc_test, start, end), \n",
    "                                        orient='index').transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e033f8ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "101872/101872 [==============================] - 151s 1ms/step - loss: 0.4913 - accuracy: 0.7642 - val_loss: 0.4809 - val_accuracy: 0.7689\n",
      "Epoch 2/15\n",
      "101872/101872 [==============================] - 126s 1ms/step - loss: 0.4745 - accuracy: 0.7744 - val_loss: 0.4773 - val_accuracy: 0.7721\n",
      "Epoch 3/15\n",
      "101872/101872 [==============================] - 110s 1ms/step - loss: 0.4680 - accuracy: 0.7790 - val_loss: 0.4753 - val_accuracy: 0.7734\n",
      "Epoch 4/15\n",
      "101872/101872 [==============================] - 142s 1ms/step - loss: 0.4626 - accuracy: 0.7830 - val_loss: 0.4736 - val_accuracy: 0.7749\n",
      "Epoch 5/15\n",
      "101872/101872 [==============================] - 107s 1ms/step - loss: 0.4576 - accuracy: 0.7860 - val_loss: 0.4728 - val_accuracy: 0.7762\n",
      "Epoch 6/15\n",
      "101872/101872 [==============================] - 107s 1ms/step - loss: 0.4531 - accuracy: 0.7892 - val_loss: 0.4723 - val_accuracy: 0.7764\n",
      "Epoch 7/15\n",
      "101872/101872 [==============================] - 107s 1ms/step - loss: 0.4486 - accuracy: 0.7921 - val_loss: 0.4731 - val_accuracy: 0.7766\n",
      "Epoch 8/15\n",
      "101872/101872 [==============================] - 141s 1ms/step - loss: 0.4443 - accuracy: 0.7949 - val_loss: 0.4738 - val_accuracy: 0.7766\n",
      "Epoch 9/15\n",
      "101872/101872 [==============================] - 141s 1ms/step - loss: 0.4401 - accuracy: 0.7977 - val_loss: 0.4747 - val_accuracy: 0.7775\n",
      "Epoch 10/15\n",
      "101872/101872 [==============================] - 143s 1ms/step - loss: 0.4361 - accuracy: 0.8000 - val_loss: 0.4756 - val_accuracy: 0.7774\n",
      "Epoch 11/15\n",
      "101872/101872 [==============================] - 107s 1ms/step - loss: 0.4323 - accuracy: 0.8024 - val_loss: 0.4782 - val_accuracy: 0.7768\n",
      "Epoch 12/15\n",
      "101872/101872 [==============================] - 107s 1ms/step - loss: 0.4288 - accuracy: 0.8046 - val_loss: 0.4791 - val_accuracy: 0.7761\n",
      "Epoch 13/15\n",
      "101872/101872 [==============================] - 142s 1ms/step - loss: 0.4252 - accuracy: 0.8068 - val_loss: 0.4823 - val_accuracy: 0.7753\n",
      "Epoch 14/15\n",
      "101872/101872 [==============================] - 142s 1ms/step - loss: 0.4219 - accuracy: 0.8090 - val_loss: 0.4842 - val_accuracy: 0.7744\n",
      "Epoch 15/15\n",
      "101872/101872 [==============================] - 107s 1ms/step - loss: 0.4184 - accuracy: 0.8111 - val_loss: 0.4873 - val_accuracy: 0.7734\n",
      "CPU times: user 1h 33min 3s, sys: 20min 5s, total: 1h 53min 8s\n",
      "Wall time: 31min 21s\n",
      "[[122294  37107]\n",
      " [ 34479 124469]]\n",
      "\n",
      "\n",
      "39794/39794 [==============================] - 26s 656us/step - loss: 0.4244 - accuracy: 0.8082\n",
      "9949/9949 [==============================] - 7s 663us/step - loss: 0.4858 - accuracy: 0.7751\n",
      "Training set score:         0.8081558347\n",
      "Test set score:             0.7751335502\n",
      "Accuracy Test set Score:    0.7751335798\n",
      "AUC Score:                  0.8882740422\n",
      "ROC AUC Training set Score: 0.8081591827\n",
      "ROC AUC Test set Score:     0.7751448712\n"
     ]
    }
   ],
   "source": [
    "start = timer()\n",
    "m, c, v = 'model_c_', 'Keras Classifier Layer: ' + str(layer), 'Count Vectorizer'\n",
    "# \n",
    "filename = model_path + 'KerasClassifier_count_model_c_.h5'\n",
    "# \n",
    "# create model\n",
    "model_c_ = KerasClassifier(build_fn=create_model_, verbose=1)\n",
    "\n",
    "%time model_c_.fit(X_train_c, y_train_c, validation_split=0.20, epochs=15, batch_size=10)\n",
    "# %time model_c_.fit(X_train_c, y_train_c)\n",
    "# \n",
    "y_pred_ = model_c_.predict(X_test_c)\n",
    "# \n",
    "cm = confusion_matrix(y_test_c, y_pred_)\n",
    "print(cm)\n",
    "print('\\n')\n",
    "# \n",
    "training_score,test_score,accuracy_score,auc_score,roc_auc_train,roc_auc_test = \\\n",
    "                    scoring_model(model_c_, X_train_c, X_test_c, y_train_c, y_test_c, y_pred_)\n",
    "# print the scores on training and test set\n",
    "print('Training set score:         {:.10f}'.format(training_score))\n",
    "print('Test set score:             {:.10f}'.format(test_score))\n",
    "print('Accuracy Test set Score:    {:.10f}'.format(accuracy_score))\n",
    "print('AUC Score:                  {:.10f}'.format(auc_score))\n",
    "print('ROC AUC Training set Score: {:.10f}'.format(roc_auc_train))\n",
    "print('ROC AUC Test set Score:     {:.10f}'.format(roc_auc_test))\n",
    "# \n",
    "model_c_.model.save(filename)\n",
    "# \n",
    "# new_model = keras.models.load_model(filename)\n",
    "# \n",
    "end = timer()\n",
    "# Log matrics \n",
    "log = log.append(pd.DataFrame.from_dict(logging_metrics(m, c, v, cm, training_score, test_score, \n",
    "                                            auc_score, roc_auc_train, roc_auc_test, start, end), \n",
    "                                        orient='index').transpose())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df39edb",
   "metadata": {},
   "source": [
    "#### MLP Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6f036ba1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1d 1h 38min 18s, sys: 5h 15min 20s, total: 1d 6h 53min 39s\n",
      "Wall time: 1d 7h 28min 7s\n",
      "\n",
      "\n",
      "[[122958  36443]\n",
      " [ 34732 124216]]\n",
      "\n",
      "\n",
      "Training set score:         0.7908579677\n",
      "Test set score:             0.7764246158\n",
      "Accuracy Test set Score:    0.7764246158\n",
      "AUC Score:                  0.8753059930\n",
      "ROC AUC Training set Score: 0.7908597772\n",
      "ROC AUC Test set Score:     0.7764318109\n"
     ]
    }
   ],
   "source": [
    "# import sklearn.neural_network\n",
    "# \n",
    "parms = {'hidden_layer_sizes': (100,),\n",
    "         'activation': 'logistic',    # {‘identity’, ‘logistic’, ‘tanh’, ‘relu’}, default=’relu’\n",
    "         'solver': 'sgd',             # {‘lbfgs’, ‘sgd’, ‘adam’}\n",
    "         'alpha': 0.0001,             # L2 penalty (regularization term) parameter\n",
    "         'batch_size': 'auto',\n",
    "         'learning_rate': 'constant', # ‘constant’ is a constant learning rate given by ‘learning_rate_init’.\n",
    "                                      # {‘constant’, ‘invscaling’, ‘adaptive’}\n",
    "         'learning_rate_init': 0.001, # The initial learning rate used. It controls the step-size in updating the \n",
    "                                      # weights. \n",
    "                                      # Only used when solver=’sgd’ or ‘adam’.\n",
    "         'power_t': 0.5,              # The exponent for inverse scaling learning rate. It is used in updating  \n",
    "                                      # effective learning rate when the learning_rate is set to ‘invscaling’. \n",
    "                                      # Only used when solver=’sgd’.\n",
    "         'max_iter': 1000,\n",
    "         'shuffle': True,\n",
    "         'random_state': seed,\n",
    "         'tol': 0.0001,\n",
    "         'verbose': False,\n",
    "         'warm_start': False,\n",
    "         'momentum': 0.9,             # Momentum for gradient descent update. Should be between 0 and 1. \n",
    "                                      # Only used when solver=’sgd’.\n",
    "         'nesterovs_momentum': True,\n",
    "         'early_stopping': False,\n",
    "         'validation_fraction': 0.1,  # The proportion of training data to set aside as \n",
    "                                      # validation set for early stopping. Must be between 0 and 1. \n",
    "                                      # Only used if early_stopping is True.\n",
    "         'beta_1': 0.9,               # Exponential decay rate for estimates of first moment vector in adam, should \n",
    "                                      # be in [0, 1). Only used when solver=’adam’.\n",
    "         'beta_2': 0.999,             # Exponential decay rate for estimates of second moment vector in adam, should \n",
    "                                      # be in [0, 1). Only used when solver=’adam’.\n",
    "         'epsilon': 1e-08,            # Value for numerical stability in adam. Only used when solver=’adam’.\n",
    "         'n_iter_no_change': 10,      # Maximum number of epochs to not meet tol improvement. Only effective \n",
    "                                      # when solver=’sgd’ or ‘adam’.\n",
    "        }\n",
    "####################################### \n",
    "start = timer()\n",
    "m, c, v = 'mlp_tfidf_', 'MLP Classifier Layer: ' +  str(layer), 'Tfidf Vectorizer'\n",
    "# \n",
    "filename = model_path + 'MLPClassifier_tfidf_.h5'\n",
    "# \n",
    "parms = {'hidden_layer_sizes': (layer,),\n",
    "         'activation': 'logistic',\n",
    "         'solver': 'adam',\n",
    "         'random_state': seed,\n",
    "        }\n",
    "# Create a model Tfidf \n",
    "mlp_tfidf_ = MLPClassifier(**parms)\n",
    "# Train the model on the train data set\n",
    "%time mlp_tfidf_.fit(X_train_t, y_train_t)\n",
    "# Evaluate on test data\n",
    "y_pred_ = mlp_tfidf_.predict(X_test_t)\n",
    "# \n",
    "print('\\n')\n",
    "cm = confusion_matrix(y_test_t, y_pred_)\n",
    "print(cm)\n",
    "print('\\n')\n",
    "# \n",
    "training_score,test_score,accuracy_score,auc_score,roc_auc_train,roc_auc_test = \\\n",
    "                    scoring_model(mlp_tfidf_, X_train_t, X_test_t, y_train_t, y_test_t, y_pred_)\n",
    "# print the scores on training and test set\n",
    "print('Training set score:         {:.10f}'.format(training_score))\n",
    "print('Test set score:             {:.10f}'.format(test_score))\n",
    "print('Accuracy Test set Score:    {:.10f}'.format(accuracy_score))\n",
    "print('AUC Score:                  {:.10f}'.format(auc_score))\n",
    "print('ROC AUC Training set Score: {:.10f}'.format(roc_auc_train))\n",
    "print('ROC AUC Test set Score:     {:.10f}'.format(roc_auc_test))\n",
    "# \n",
    "# save model\n",
    "joblib.dump(mlp_tfidf_, filename)\n",
    "# load model\n",
    "# gbm_pickle = joblib.load(filename)\n",
    "# \n",
    "end = timer()\n",
    "# Log matrics \n",
    "log = log.append(pd.DataFrame.from_dict(logging_metrics(m, c, v, cm, training_score, test_score, \n",
    "                                            auc_score, roc_auc_train, roc_auc_test, start, end), \n",
    "                                        orient='index').transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ad68d45e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 18h 13min 51s, sys: 3h 30min 40s, total: 21h 44min 31s\n",
      "Wall time: 21h 25min 11s\n",
      "\n",
      "\n",
      "[[120470  38931]\n",
      " [ 34737 124211]]\n",
      "\n",
      "\n",
      "Training set score:         0.8032021536\n",
      "Test set score:             0.7685935875\n",
      "Accuracy Test set Score:    0.7685935875\n",
      "AUC Score:                  0.8875247872\n",
      "ROC AUC Training set Score: 0.8032074945\n",
      "ROC AUC Test set Score:     0.7686118655\n"
     ]
    }
   ],
   "source": [
    "start = timer()\n",
    "m, c, v = 'mlp_count_', 'MLP Classifier Layer: ' +  str(layer), 'Count Vectorizer'\n",
    "# \n",
    "filename = model_path + 'MLPClassifier_count_.h5'\n",
    "# \n",
    "parms = {'hidden_layer_sizes': (layer,),\n",
    "         'activation': 'logistic',\n",
    "         'solver': 'adam',\n",
    "         'random_state': seed,\n",
    "        }\n",
    "# Create a model Tfidf \n",
    "mlp_count_ = MLPClassifier(**parms)\n",
    "# Train the model on the train data set\n",
    "%time mlp_count_.fit(X_train_c, y_train_c)\n",
    "# Evaluate on test data\n",
    "y_pred_ = mlp_count_.predict(X_test_c)\n",
    "# \n",
    "print('\\n')\n",
    "cm = confusion_matrix(y_test_c, y_pred_)\n",
    "print(cm)\n",
    "print('\\n')\n",
    "# \n",
    "training_score,test_score,accuracy_score,auc_score,roc_auc_train,roc_auc_test = \\\n",
    "                    scoring_model(mlp_count_, X_train_c, X_test_c, y_train_c, y_test_c, y_pred_)\n",
    "# print the scores on training and test set\n",
    "print('Training set score:         {:.10f}'.format(training_score))\n",
    "print('Test set score:             {:.10f}'.format(test_score))\n",
    "print('Accuracy Test set Score:    {:.10f}'.format(accuracy_score))\n",
    "print('AUC Score:                  {:.10f}'.format(auc_score))\n",
    "print('ROC AUC Training set Score: {:.10f}'.format(roc_auc_train))\n",
    "print('ROC AUC Test set Score:     {:.10f}'.format(roc_auc_test))\n",
    "# \n",
    "# save model\n",
    "joblib.dump(mlp_count_, filename)\n",
    "# load model\n",
    "# gbm_pickle = joblib.load(filename)\n",
    "# \n",
    "end = timer()\n",
    "# Log matrics \n",
    "log = log.append(pd.DataFrame.from_dict(logging_metrics(m, c, v, cm, training_score, test_score, \n",
    "                                            auc_score, roc_auc_train, roc_auc_test, start, end), \n",
    "                                        orient='index').transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6bf306a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Vectorizer</th>\n",
       "      <th>TP</th>\n",
       "      <th>FN</th>\n",
       "      <th>FP</th>\n",
       "      <th>TN</th>\n",
       "      <th>Training_Score</th>\n",
       "      <th>Test_Score</th>\n",
       "      <th>AUC_Score</th>\n",
       "      <th>ROC_AUC_Training</th>\n",
       "      <th>ROC_AUC_Test</th>\n",
       "      <th>Duration_Mins</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cv</td>\n",
       "      <td>unigrams and bigrams</td>\n",
       "      <td>Count Vectorizer</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.669744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tv</td>\n",
       "      <td>unigrams and bigrams</td>\n",
       "      <td>Tfidf Vectorizer</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.045181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lrc_c</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>Count Vectorizer</td>\n",
       "      <td>115709</td>\n",
       "      <td>43692</td>\n",
       "      <td>31126</td>\n",
       "      <td>127822</td>\n",
       "      <td>0.763785</td>\n",
       "      <td>0.764981</td>\n",
       "      <td>0.839439</td>\n",
       "      <td>0.763801</td>\n",
       "      <td>0.765037</td>\n",
       "      <td>221.821038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lrc_t</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>Tfidf Vectorizer</td>\n",
       "      <td>117805</td>\n",
       "      <td>41596</td>\n",
       "      <td>33141</td>\n",
       "      <td>125807</td>\n",
       "      <td>0.764608</td>\n",
       "      <td>0.765236</td>\n",
       "      <td>0.844782</td>\n",
       "      <td>0.764619</td>\n",
       "      <td>0.765273</td>\n",
       "      <td>150.749775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lgbm_c</td>\n",
       "      <td>LGBM Classifier</td>\n",
       "      <td>Count Vectorizer</td>\n",
       "      <td>112406</td>\n",
       "      <td>46995</td>\n",
       "      <td>32518</td>\n",
       "      <td>126430</td>\n",
       "      <td>0.749437</td>\n",
       "      <td>0.750233</td>\n",
       "      <td>0.829899</td>\n",
       "      <td>0.749456</td>\n",
       "      <td>0.750297</td>\n",
       "      <td>0.782862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lgbm_t</td>\n",
       "      <td>LGBM Classifier</td>\n",
       "      <td>Tfidf Vectorizer</td>\n",
       "      <td>112899</td>\n",
       "      <td>46502</td>\n",
       "      <td>32720</td>\n",
       "      <td>126228</td>\n",
       "      <td>0.751091</td>\n",
       "      <td>0.751147</td>\n",
       "      <td>0.831921</td>\n",
       "      <td>0.751109</td>\n",
       "      <td>0.751208</td>\n",
       "      <td>0.589967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lgbBO</td>\n",
       "      <td>Bayesian Optimization</td>\n",
       "      <td>Tfidf Vectorizer</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>76.871454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lgbm_BO_t</td>\n",
       "      <td>LGBM Classifier - Bayesian Optimization</td>\n",
       "      <td>3.523413</td>\n",
       "      <td>110369</td>\n",
       "      <td>49032</td>\n",
       "      <td>29867</td>\n",
       "      <td>129081</td>\n",
       "      <td>0.755434</td>\n",
       "      <td>0.752162</td>\n",
       "      <td>0.837715</td>\n",
       "      <td>0.755459</td>\n",
       "      <td>0.752247</td>\n",
       "      <td>0.626383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lgbBO_c</td>\n",
       "      <td>Bayesian Optimization</td>\n",
       "      <td>Count Vectorizer</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>90.425354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lgbm_BO_c</td>\n",
       "      <td>LGBM Classifier - Bayesian Optimization</td>\n",
       "      <td>5.776941</td>\n",
       "      <td>117188</td>\n",
       "      <td>42213</td>\n",
       "      <td>32999</td>\n",
       "      <td>125949</td>\n",
       "      <td>0.763266</td>\n",
       "      <td>0.763744</td>\n",
       "      <td>0.83937</td>\n",
       "      <td>0.763277</td>\n",
       "      <td>0.763784</td>\n",
       "      <td>0.533199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lgbBO</td>\n",
       "      <td>Keras Tuning</td>\n",
       "      <td>Tfidf Vectorizer</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>68.465076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>model_k_</td>\n",
       "      <td>Keras Classifier Layer: 384</td>\n",
       "      <td>Tfidf Vectorizer</td>\n",
       "      <td>122055</td>\n",
       "      <td>37346</td>\n",
       "      <td>32828</td>\n",
       "      <td>126120</td>\n",
       "      <td>0.797137</td>\n",
       "      <td>0.779569</td>\n",
       "      <td>0.877933</td>\n",
       "      <td>0.797143</td>\n",
       "      <td>0.779589</td>\n",
       "      <td>29.777736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>model_c_</td>\n",
       "      <td>Keras Classifier Layer: 384</td>\n",
       "      <td>Count Vectorizer</td>\n",
       "      <td>122294</td>\n",
       "      <td>37107</td>\n",
       "      <td>34479</td>\n",
       "      <td>124469</td>\n",
       "      <td>0.808156</td>\n",
       "      <td>0.775134</td>\n",
       "      <td>0.888274</td>\n",
       "      <td>0.808159</td>\n",
       "      <td>0.775145</td>\n",
       "      <td>32.754195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mlp_tfidf_</td>\n",
       "      <td>MLP Classifier Layer: 384</td>\n",
       "      <td>Tfidf Vectorizer</td>\n",
       "      <td>122958</td>\n",
       "      <td>36443</td>\n",
       "      <td>34732</td>\n",
       "      <td>124216</td>\n",
       "      <td>0.790858</td>\n",
       "      <td>0.776425</td>\n",
       "      <td>0.875306</td>\n",
       "      <td>0.79086</td>\n",
       "      <td>0.776432</td>\n",
       "      <td>1781.875342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mlp_count_</td>\n",
       "      <td>MLP Classifier Layer: 384</td>\n",
       "      <td>Count Vectorizer</td>\n",
       "      <td>120470</td>\n",
       "      <td>38931</td>\n",
       "      <td>34737</td>\n",
       "      <td>124211</td>\n",
       "      <td>0.803202</td>\n",
       "      <td>0.768594</td>\n",
       "      <td>0.887525</td>\n",
       "      <td>0.803207</td>\n",
       "      <td>0.768612</td>\n",
       "      <td>1293.672127</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Model                               Classifier        Vectorizer  \\\n",
       "0  cv          unigrams and bigrams                     Count Vectorizer   \n",
       "0  tv          unigrams and bigrams                     Tfidf Vectorizer   \n",
       "0  lrc_c       Logistic Regression                      Count Vectorizer   \n",
       "0  lrc_t       Logistic Regression                      Tfidf Vectorizer   \n",
       "0  lgbm_c      LGBM Classifier                          Count Vectorizer   \n",
       "0  lgbm_t      LGBM Classifier                          Tfidf Vectorizer   \n",
       "0  lgbBO       Bayesian Optimization                    Tfidf Vectorizer   \n",
       "0  lgbm_BO_t   LGBM Classifier - Bayesian Optimization  3.523413           \n",
       "0  lgbBO_c     Bayesian Optimization                    Count Vectorizer   \n",
       "0  lgbm_BO_c   LGBM Classifier - Bayesian Optimization  5.776941           \n",
       "0  lgbBO       Keras Tuning                             Tfidf Vectorizer   \n",
       "0  model_k_    Keras Classifier Layer: 384              Tfidf Vectorizer   \n",
       "0  model_c_    Keras Classifier Layer: 384              Count Vectorizer   \n",
       "0  mlp_tfidf_  MLP Classifier Layer: 384                Tfidf Vectorizer   \n",
       "0  mlp_count_  MLP Classifier Layer: 384                Count Vectorizer   \n",
       "\n",
       "       TP     FN     FP      TN Training_Score Test_Score AUC_Score  \\\n",
       "0  0       0      0      0       0              0          0          \n",
       "0  0       0      0      0       0              0          0          \n",
       "0  115709  43692  31126  127822  0.763785       0.764981   0.839439   \n",
       "0  117805  41596  33141  125807  0.764608       0.765236   0.844782   \n",
       "0  112406  46995  32518  126430  0.749437       0.750233   0.829899   \n",
       "0  112899  46502  32720  126228  0.751091       0.751147   0.831921   \n",
       "0  0       0      0      0       0              0          0          \n",
       "0  110369  49032  29867  129081  0.755434       0.752162   0.837715   \n",
       "0  0       0      0      0       0              0          0          \n",
       "0  117188  42213  32999  125949  0.763266       0.763744   0.83937    \n",
       "0  0       0      0      0       0              0          0          \n",
       "0  122055  37346  32828  126120  0.797137       0.779569   0.877933   \n",
       "0  122294  37107  34479  124469  0.808156       0.775134   0.888274   \n",
       "0  122958  36443  34732  124216  0.790858       0.776425   0.875306   \n",
       "0  120470  38931  34737  124211  0.803202       0.768594   0.887525   \n",
       "\n",
       "  ROC_AUC_Training ROC_AUC_Test Duration_Mins  \n",
       "0  0                0            0.669744      \n",
       "0  0                0            1.045181      \n",
       "0  0.763801         0.765037     221.821038    \n",
       "0  0.764619         0.765273     150.749775    \n",
       "0  0.749456         0.750297     0.782862      \n",
       "0  0.751109         0.751208     0.589967      \n",
       "0  0                0            76.871454     \n",
       "0  0.755459         0.752247     0.626383      \n",
       "0  0                0            90.425354     \n",
       "0  0.763277         0.763784     0.533199      \n",
       "0  0                0            68.465076     \n",
       "0  0.797143         0.779589     29.777736     \n",
       "0  0.808159         0.775145     32.754195     \n",
       "0  0.79086          0.776432     1781.875342   \n",
       "0  0.803207         0.768612     1293.672127   "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log.dropna(inplace=True)\n",
    "log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f835b103",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
